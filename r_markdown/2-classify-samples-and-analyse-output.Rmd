---
title: "Kraken2 and MetaPhlAn3 confidence and database testing - getting and running the samples"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
  pdf_document:
    toc: yes
---

```{R, results='hide', fig.keep='all', message=FALSE}
library(reticulate)
library(knitr)
conda_python(envname = 'r-reticulate', conda = "auto")
```

```{python, results='hide', fig.keep='all', message=FALSE, eval=FALSE}
import os
import pandas as pd
import pickle
from ete3 import Tree

direc = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/'
direc_db = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/database_classifications/'
direc_truth = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/'
```

# Get test datasets

## Simulated and mock samples

CAMI (https://edwards.sdsu.edu/research/cami-challenge-datasets/):
```{bash, eval=FALSE}
wget https://edwards.sdsu.edu/CAMI/CAMI_low/RL_S001__insert_270.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_medium/RM2_S001__insert_270.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_medium/RM1_S001__insert_5000.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_medium/RM2_S002__insert_270.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_medium/RM1_S002__insert_5000.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_high/RH_S001__insert_270.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_high/RH_S002__insert_270.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_high/RH_S003__insert_270.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_high/RH_S004__insert_270.fa.zip https://edwards.sdsu.edu/CAMI/CAMI_high/RH_S005__insert_270.fa.zip
```

Those used in [McIntyre et al. 2017](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1299-7#Sec15):
```{bash, eval=FALSE}
wget ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_1ng_Repli_g_08142015_GTCCGC_L001_R1_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_1ng_Repli_g_08142015_GTCCGC_L001_R2_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_5ng_Repli_g_08142015_CCGTCC_L001_R1_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_5ng_Repli_g_08142015_CCGTCC_L001_R2_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_10ng_Repli_g_08142015_ATGTCA_L001_R1_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_10ng_Repli_g_08142015_ATGTCA_L001_R2_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_Half_ng_Repli_g_08142015_GTGAAA_L001_R1_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_Half_ng_Repli_g_08142015_GTGAAA_L001_R2_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_Normal_08142015_CGTACG_L001_R1_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/ABRF_MGRG_Normal_08142015_CGTACG_L001_R2_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/BioPool_BioPool_1_Cycle_02042016_CTGAAGCT-TATAGCCT_L001_R1_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/BioPool_BioPool_1_Cycle_02042016_CTGAAGCT-TATAGCCT_L001_R2_001.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/BMI_bmi_reads.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Carma_eval_carma.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Dataset_descriptions.xlsx ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/HMP_even_454_SRR072233.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/HMP_even_illum_SRR172902.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_HC1.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_HC2.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC1.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC2.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC3.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC4.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC5.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC6.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC7.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Huttenhower_LC8.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/JGI_SRR033547.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/JGI_SRR033548.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/JGI_SRR033549.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Mavromatis_simHC.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Mavromatis_simLC.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Mavromatis_simMC.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b1.fail.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b1.pass.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b3.fail.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b3.pass.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b4.fail.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b4.pass.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b7.fail.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b7.pass.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b8.fail.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b8.pass.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b9.fail.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_b9.pass.2d.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_R6_2d_fail.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/MGRG_nanopore_R6_2d_pass.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/NA12878_NegControl_SL126486_0.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/NA12878_NegControl_SL126487_0.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/NA12878_NegControl_SL126488_0.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/NegControl_LM.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/NegControl_MH1.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/NegControl_MH2.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00134-R1.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00134-R2.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.5.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.10.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.15.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.20.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.30.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.40.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.50.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.75.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497_Deep.100.Mreads.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497-R1.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00497-R2.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00606-R1.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P00606-R2.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P01027-R1.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P01027-R2.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P01090-R1.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/P01090-R2.fastq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/Raiphy_eval_RAIphy.fasta.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/truth_sets.zip ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.7.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.buccal.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.cityparks.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.frankengenome.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.frankengenome.mix.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.gut.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.hous1.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa /IMMSA/UnAmbiguouslyMapped_ds.hous2.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.nycsm.fq.gz ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.soil.fq.gz
ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/UnAmbiguouslyMapped_ds.hous2.fq.gz
ftp://ftp-private.ncbi.nlm.nih.gov/nist-immsa/IMMSA/HMP_even_illum_SRR172902.fastq.gz
```

And the ZymoMock community (already run through Kneaddata) that was sequenced at the IMR.

Those used in [Parks et al. 2021](https://www.frontiersin.org/articles/10.3389/fmicb.2021.643682/full):
```{bash, eval=FALSE}
wget https://zenodo.org/record/4470159/files/ani100_stFalse_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stFalse_r9.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani100_stTrue_r9.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stFalse_r9.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani95_cLOW_stTrue_r9.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stFalse_r9.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani97_stTrue_r9.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stFalse_r9.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r0.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r1.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r2.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r3.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r4.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r5.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r6.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r7.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r8.tar.gz?download=1 https://zenodo.org/record/4470159/files/ani99_stTrue_r9.tar.gz?download=1 
```

Rename:
```{python, eval=FALSE}
import os
files = os.listdir('parks_mocks/')
files = [f for f in files if '?download=1' in f]

for f in files:
  os.system('mv parks_mocks/'+f+' parks_mocks/'+f.replace('?download=1', ''))
```

Unzip:
```{bash, eval=FALSE}
for i in parks_mocks/*.tar.gz ; do tar -xvf $i ; done
mv ani* inflated_parks/
for i in parks_mocks/*.tar.gz ; do mv $i parks_mocks/tar/ ; done
```

**All samples were put into a folder called ```samples_running/```**

## Files for real world validation

Copy files from Gavin's storage directory
```{bash, eval=FALSE}
sudo cp -r /home/storage/gavin/projects/picrust_folders/picrust2_backup/cameroon_cat_reads_fastqs.tar.gz . #done
sudo cp -r /home/storage/gavin/projects/picrust_folders/picrust2_backup/blueberry_mgs_intermediate_fastqs.tar.gz . #done
sudo cp -r /home/storage/gavin/projects/picrust_folders/picrust2_backup/hmp_mgs_cat_fastqs.tar.gz . #done
sudo cp -r /home/storage/gavin/projects/picrust_folders/picrust2_backup/indian_intermediate_fastqs.tar.gz . #done

#need kneaddata run
sudo cp -r /home/storage/gavin/fastq_storage/ocean_raw_mgs.tar.gz . #done - note that all reads were apparently unmatched so this is what I've used
sudo cp -r /home/storage/gavin/fastq_storage/mammal_raw_fastqs.tar.gz . #done
sudo cp -r /home/storage/gavin/fastq_storage/primate_PE_raw_fastqs.tar.gz . #done
```

Run kneaddata:
```{bash, eval=FALSE}
mkdir kneaddata_out_ocean
parallel -j 2 --link --progress 'kneaddata -i {1} -i {2} -o kneaddata_out_ocean/ -db /home/shared/bowtiedb/PhiX \
--trimmomatic /home/robyn/tools/Trimmomatic-0.39/ -t 12 --trimmomatic-options "SLIDINGWINDOW:4:20 MINLEN:50" \
--bowtie2-options "--very-sensitive --dovetail" --remove-intermediate-output' ::: ocean_raw_mgs/*_1.fastq.gz ::: ocean_raw_mgs/*_2.fastq.gz
 
mkdir kneaddata_out_mammal
parallel -j 2 --link --progress 'kneaddata -i {1} -i {2} -o kneaddata_out_mammal/ -db /home/shared/bowtiedb/PhiX \
--trimmomatic /home/robyn/tools/Trimmomatic-0.39/ -t 12 --trimmomatic-options "SLIDINGWINDOW:4:20 MINLEN:50" \
--bowtie2-options "--very-sensitive --dovetail" --remove-intermediate-output' ::: mammal_raw_fastqs/*_R1_001.fastq.gz ::: mammal_raw_fastqs/*_R2_001.fastq.gz
 
mkdir kneaddata_out_primate
parallel -j 2 --link --progress 'kneaddata -i {1} -i {2} -o kneaddata_out_primate/ -db /home/shared/bowtiedb/PhiX \
--trimmomatic /home/robyn/tools/Trimmomatic-0.39/ -t 12 --trimmomatic-options "SLIDINGWINDOW:4:20 MINLEN:50" \
--bowtie2-options "--very-sensitive --dovetail" --remove-intermediate-output' ::: primate_PE_raw_fastqs/*.R1.fastq.gz ::: primate_PE_raw_fastqs/*.R2.fastq.gz
```

Move the kneaddata files into their own folders now.

Concatenate paired end files:
```{bash, eval=FALSE}
mkdir blueberry_cat_reads_fastqs
concat_paired_end.pl -p 4 -o blueberry_cat_reads_fastqs/ blueberry_mgs_intermediate_fastqs/concat_data/*.fastq.gz

mkdir ocean_cat_reads_fastqs
concat_paired_end.pl -p 4 --no_R_match -o ocean_cat_reads_fastqs kneaddata_out_ocean/unmatched/*_unmatched_*.fastq 
gzip ocean_cat_reads_fastqs/*

mkdir mammal_cat_reads_fastqs
mkdir mammal_cat_lanes_fastqs
mkdir mammal_cat_lanes_fastqs/R1
mkdir mammal_cat_lanes_fastqs/R2
concat_lanes.pl kneaddata_out_mammal/paired/*paired_1.fastq -o mammal_cat_lanes_fastqs/R1/ -p 4
concat_lanes.pl kneaddata_out_mammal/paired/*paired_2.fastq -o mammal_cat_lanes_fastqs/R2/ -p 4
#then renamed the R2's using Python and moved them all to the main directory
concat_paired_end.pl -p 4 -o mammal_cat_reads_fastqs/ mammal_cat_lanes_fastqs/*.fastq 
mv mammal_cat_lanes_fastqs/ kneaddata_out_mammal/
gzip mammal_cat_reads_fastqs/*
tar -czvf kneaddata_out_mammal.tar.gz kneaddata_out_mammal

mkdir primate_cat_reads_fastqs
```

# Run all databases on all samples

MetaPhlAn:
```{bash, eval=FALSE}
#convert file names so they're easier to loop
for f in samples_running/*.fq; do 
    mv -- "$f" "${f%.fq}.fastq"
done

conda activate mpa
mkdir metaphlan_profiles
mkdir times

parallel -j 1 '(/usr/bin/time -v metaphlan {} --nproc 12 --input_type fastq --bowtie2db /home/robyn/databases_May2021/metaphlan/ --unknown_estimation -o metaphlan_profiles/{/.}.txt) 2> times/metaphlan_{/.}.txt' ::: samples_running/*.fastq

parallel -j 1 '(/usr/bin/time -v metaphlan {} --nproc 12 --input_type fasta --bowtie2db /home/robyn/databases_May2021/metaphlan/ -o metaphlan_profiles/{/.}.txt) 2> times/metaphlan_{/.}.txt' ::: samples_running/*.fasta
```

MetaPhlAn with read stats:
```{bash, eval=FALSE}
conda activate mpa
#or conda activate biobakery3
mkdir metaphlan_reads

parallel -j 1 '(/usr/bin/time -v metaphlan {} --nproc 12 --input_type fastq --bowtie2db /home/robyn/databases_May2021/metaphlan/ --unknown_estimation -o metaphlan_reads/{/.}.txt -t rel_ab_w_read_stats) 2> times/metaphlan_reads{/.}.txt' ::: samples_running/*.fastq.gz

parallel -j 1 '(/usr/bin/time -v metaphlan {} --nproc 12 --input_type fasta --bowtie2db /home/robyn/databases_May2021/metaphlan/ -o metaphlan_reads/{/.}.txt  -t rel_ab_w_read_stats) 2> times/metaphlan_reads{/.}.txt' ::: samples_running/*.fasta.gz

for f in metaphlan_reads/*.fastq.txt; do 
    mv -- "$f" "${f%.fastq.txt}.txt"
done

for f in metaphlan_reads/*.fasta.txt; do 
    mv -- "$f" "${f%.fasta.txt}.txt"
done
```

MetaPhlAn with read stats and different bowtie2 options:
```{bash, eval=FALSE}
conda activate mpa
#or conda activate biobakery3

parallel -j 3 '(/usr/bin/time -v metaphlan {1} --nproc 12 --input_type fastq --bowtie2db /home/robyn/databases_May2021/metaphlan/ --unknown_estimation -o metaphlan_reads/{1/.}_{2}.txt -t rel_ab_w_read_stats --bt2_ps {2} --no_map) 2> times/metaphlan_reads{1/.}_{2}.txt' ::: samples_running/*.fastq ::: sensitive sensitive-local very-sensitive-local

parallel -j 3 '(/usr/bin/time -v metaphlan {1} --nproc 12 --input_type fasta --bowtie2db /home/robyn/databases_May2021/metaphlan/ -o metaphlan_reads/{1/.}_{2}.txt  -t rel_ab_w_read_stats --bt2_ps {2} --no_map) 2> times/metaphlan_reads{1/.}_{2}.txt' ::: samples_running/*.fasta ::: sensitive sensitive-local very-sensitive-local
```

MetaPhlAn with read stats and different methods for estimating clade abundance:
```{bash, eval=FALSE}
parallel -j 4 --progress '(/usr/bin/time -v metaphlan {1} --nproc 12 --input_type fastq --bowtie2db /home/robyn/databases_May2021/metaphlan/ -o metaphlan_reads/{1/.}_{2}.txt  -t rel_ab_w_read_stats --stat {2}) 2> times/metaphlan_reads{1/.}_{2}.txt' ::: samples_running/*.fastq ::: avg_g

parallel -j 4 --progress '(/usr/bin/time -v metaphlan {1} --nproc 12 --input_type fasta --bowtie2db /home/robyn/databases_May2021/metaphlan/ -o metaphlan_reads/{1/.}_{2}.txt  -t rel_ab_w_read_stats --stat {2}) 2> times/metaphlan_reads{1/.}_{2}.txt' ::: samples_running/*.fasta ::: avg_g

parallel -j 4 --progress '(/usr/bin/time -v metaphlan {1} --nproc 12 --input_type bowtie2out --bowtie2db /home/robyn/databases_May2021/metaphlan/ --unknown_estimation -o metaphlan_reads/{1/.}_{2}.txt -t rel_ab_w_read_stats --stat {2}) 2> times/metaphlan_reads{1/.}_{2}.txt' ::: samples_running/*bowtie2out.txt ::: avg_g avg_l tavg_l wavg_g wavg_l med
```

Looking at MetaPhlAn mapping of reads to genomes with HUMANN.
Install:
```{bash, eval=FALSE}
conda activate biobakery3
conda install humann -c biobakery
humann_databases --download chocophlan full HUMANN/ --update-config yes
humann_databases --download uniref uniref90_diamond HUMANN/ --update-config yes
humann_databases --download uniref uniref50_diamond HUMANN/ --update-config yes
humann_databases --download utility_mapping full HUMANN/ --update-config yes
conda install -c bioconda diamond=0.9.36-0 #diamond version needs updating
```

Run on samples:
```{bash, eval=FALSE}
mkdir humann_out

parallel -j 1 --progress '(/usr/bin/time -v humann -i {1} -o humann_out/ --threads 24) 2> times/humann_{1/.}.txt' ::: samples_running/*.fast*
parallel -j 1 --progress '(/usr/bin/time -v humann -i {1} -o humann_out/ --threads 24) 2> times/humann_{1/.}.txt' ::: samples_running/ani97_cLOW_stTrue_r5.fastq
```

Delete intermediate unneeded files:
```{python, eval=FALSE}
import os

folder = 'humann_out/'
folders = os.listdir(folder)
folders = [f for f in folders if '_humann_temp' in f]

for f in folders:
  files = os.listdir(folder+f+'/')
  continuing = False
  for fi in files:
    if 'tmp' in fi:
      continuing = True
      print(f, fi)
  if continuing: 
    continue
  for fi in files:
    if 'aligned.tsv' not in fi:
      os.system('rm '+folder+f+'/'+fi)
```

GTDB r202 + NCBI RefSeq V205:
```{bash, eval=FALSE}
sudo cp -r /home/storage/robyn/kraken2_databases/kraken2_GTDBr202_RefSeqV205/ /scratch/ramdisk/ #done
mkdir kraken2_GTDBr202RefSeqV205
mkdir kraken2_outraw

parallel -j 2 '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_GTDBr202RefSeqV205/{1/.}.{2}.kreport --confidence {2}) 2> times/GTDBr202RefSeqV205_{1/.}_{2}.txt' ::: samples_running//*.fq ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/

parallel -j 10 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_GTDBr202RefSeqV205/*.kreport ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/

sudo rm -r /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/
```

MiniKraken V2 (done):
```{bash, eval=FALSE}
sudo cp -r /home/robyn/databases_May2021/minikraken2_v2_8GB_201904_UPDATE/ /scratch/ramdisk/
mkdir kraken2_minikraken

parallel -j 1 --progress '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_minikraken/{1/.}.{2}.kreport --confidence {2}) 2> times/minikrakenV2_{1/.}_{2}.txt' ::: samples_running//*.fq ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/

parallel -j 10 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_minikraken/*.kreport ::: /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/

sudo rm -r /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/
```

RefSeq Complete V93:
```{bash, eval=FALSE}
sudo cp -r /home/shared/Kraken2.0.8_Bracken150mer_RefSeqCompleteV93/ /scratch/ramdisk/
mkdir kraken2_refseqV93

parallel -j 1 --progress '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_refseqV93/{1/.}.{2}.kreport --confidence {2}) 2> times/RefSeqV93_{1/.}_{2}.txt' ::: samples_running//*.fq ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2.0.8_Bracken150mer_RefSeqCompleteV93/

parallel -j 1 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_refseqV93/*.kreport ::: /scratch/ramdisk/Kraken2.0.8_Bracken150mer_RefSeqCompleteV93/

sudo rm -r /scratch/ramdisk/Kraken2.0.8_Bracken150mer_RefSeqCompleteV93/
```

MetaPhlAn3 equivalent:
```{bash, eval=FALSE}
sudo cp -r /home/storage/robyn/kraken2_databases/kraken2_chocophlanV30-201901/ /scratch/ramdisk/
mkdir kraken2_chocophlanV30

parallel -j 1 --progress '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_chocophlanV30/{1/.}.{2}.kreport --confidence {2}) 2> times/kraken2_chocophlanV30_{1/.}_{2}.txt' ::: samples_running//*.fq ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/kraken2_chocophlanV30-201901/

parallel -j 1 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_chocophlanV30/*.kreport ::: /scratch/ramdisk/kraken2_chocophlanV30-201901/

sudo rm -r /scratch/ramdisk/kraken2_chocophlanV30-201901/
```

RefSeq Complete V205 100 GB:
```{bash, eval=FALSE}
sudo cp -r /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_100GB/ /scratch/ramdisk/
mkdir kraken2_refseqV205_100GB

parallel -j 1 '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_refseqV205_100GB/{1/.}.{2}.kreport --confidence {2}) 2> times/RefSeqV205_Complete_100GB_{1/.}_{2}.txt' ::: samples_running/* ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/

parallel -j 10 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_refseqV205_100GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/

sudo rm -r /scratch/ramdisk/RefSeqV205_Complete_100GB/
```

RefSeq Complete V205 500 GB:
```{bash, eval=FALSE}
sudo cp -r /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_500GB/ /scratch/ramdisk/
mkdir kraken2_refseqV205_500GB

parallel -j 2 '(/usr/bin/time -v kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_refseqV205_500GB/{1/.}.{2}.kreport --confidence {2}) 2> times/RefSeqV205_Complete_500GB_{1/.}_{2}.txt' ::: samples_running/* ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/

parallel -j 10 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_refseqV205_500GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/

sudo rm -r /scratch/ramdisk/RefSeqV205_Complete_500GB/
```

RefSeq Complete V205 complete:
```{bash, eval=FALSE}
sudo cp -r /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2/ /scratch/ramdisk/
mkdir kraken2_refseqV205

parallel -j 1 '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_refseqV205/{1/.}.{2}.kreport --confidence {2} --report-minimizer-data) 2> times/RefSeqV205_Complete_{1/.}_{2}.txt' ::: samples_running/* ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2/

parallel -j 10 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: /home/robyn/simulated_samples/kraken2_refseqV205/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2/

sudo rm -r /scratch/ramdisk/RefSeqV205_Complete/
```

RefSeq V208 nt:
```{bash, eval=FALSE}
sudo cp -r /home/storage/robyn/kraken2_databases/kraken2_RefSeqV208_nt/ /scratch/ramdisk/
mkdir kraken2_RefSeqV208_nt

parallel -j 1 --progress '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_RefSeqV208_nt/{1/.}.{2}.kreport --confidence {2}) 2> times/kraken2_RefSeqV208_nt_{1/.}_{2}.txt' ::: samples_running/* ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/

parallel -j 10 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_RefSeqV208_nt/*.kreport ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/

sudo rm -r /scratch/ramdisk/kraken2_RefSeqV208_nt/
```

Standard (05/2021 Langmead lab database):
```{bash, eval=FALSE}
sudo cp -r /home/storage/robyn/kraken2_databases/Kraken2_standard/ /scratch/ramdisk/
mkdir kraken2_standard
mkdir kraken2_outraw

parallel -j 1 --progress '(/usr/bin/time -v kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_standard/{1/.}.{2}.kreport --confidence {2}) 2> times/kraken2_standard_{1/.}_{2}.txt' ::: samples_running/* ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_standard/

parallel -j 10 '(/usr/bin/time -v bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150) 2> times/{1/.}_bracken.txt' ::: kraken2_standard/*.kreport ::: /scratch/ramdisk/Kraken2_standard/

sudo rm -r /scratch/ramdisk/kraken2_RefSeqV208_nt/
```

## Report minimizer counts 

New conda environment:
```{bash, eval=FALSE}
conda create --name kraken2-github
conda activate kraken2-github
mkdir kraken2-github
cd kraken2-github/
git clone https://github.com/DerrickWood/kraken2/
./install_kraken2.sh /home/robyn/anaconda3/envs/kraken2-github/
cp /home/robyn/anaconda3/envs/kraken2-github/kraken2 /home/robyn/anaconda3/envs/kraken2-github/bin/
cp /home/robyn/anaconda3/envs/kraken2-github/kraken2-build /home/robyn/anaconda3/envs/kraken2-github/bin/
cp /home/robyn/anaconda3/envs/kraken2-github/kraken2-inspect /home/robyn/anaconda3/envs/kraken2-github/bin/
```

Again with the V205 full database:
```{bash, eval=FALSE}
mkdir kraken2_RefSeqV205_minimizer
mkdir kraken2_RefSeqV205_minimizer/kreport/
mkdir kraken2_RefSeqV205_minimizer/outraw/
parallel -j 1 --progress 'kraken2 --use-names --threads 24 --db {2} --memory-mapping {1} --output kraken2_RefSeqV205_minimizer/outraw/{1/.}.kraken --report kraken2_RefSeqV205_minimizer/kreport/{1/.}.kreport --report-minimizer-data' ::: samples_running/* ::: /home/shared/Kraken2_RefSeqCompleteV205/
```

## Run validation datasets

### Kraken2

Kraken RefSeq Complete V205:
```{bash, eval=FALSE}
#done
sudo cp -r /home/shared/Kraken2_RefSeqCompleteV205/ /scratch/ramdisk/
mkdir kraken2_outraw
mkdir kraken2_kreport
mkdir kraken2_kreport/RefSeqCompleteV205

parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/RefSeqCompleteV205/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 0.15 0.50 0.65 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/

parallel -j 48 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205/*.kreport ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/
mkdir kraken2_bracken_species
mkdir kraken2_bracken_species/RefSeqCompleteV205/
mv kraken2_kreport/RefSeqCompleteV205/*bracken* kraken2_bracken_species/RefSeqCompleteV205/

parallel -j 48 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205/*.kreport ::: /home/shared/Kraken2_RefSeqCompleteV205/
mkdir kraken2_bracken_genus
mkdir kraken2_bracken_genus/RefSeqCompleteV205/
mv kraken2_kreport/RefSeqCompleteV205/*genus.bracken kraken2_bracken_genus/RefSeqCompleteV205/

sudo rm -r /scratch/ramdisk/Kraken2_RefSeqCompleteV205/
```

Kraken RefSeq Complete V205 100 GB:
```{bash, eval=FALSE}
#done
sudo cp -r /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_100GB/ /scratch/ramdisk/
mkdir kraken2_kreport/RefSeqCompleteV205_100GB/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/RefSeqCompleteV205_100GB/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 1.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_100GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/
mkdir kraken2_bracken_species/RefSeqCompleteV205_100GB/
mv kraken2_kreport/RefSeqCompleteV205_100GB/*bracken* kraken2_bracken_species/RefSeqCompleteV205_100GB/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_100GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/
mkdir kraken2_bracken_genus/RefSeqCompleteV205_100GB/
mv kraken2_kreport/RefSeqCompleteV205_100GB/*genus.bracken kraken2_bracken_genus/RefSeqCompleteV205_100GB/

sudo rm -r /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/
```

Kraken RefSeq Complete V205 500 GB:
```{bash, eval=FALSE}
#done
sudo cp -r /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_500GB/ /scratch/ramdisk/
mkdir kraken2_kreport/RefSeqCompleteV205_500GB/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/RefSeqCompleteV205_500GB/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 1.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_500GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/
mkdir kraken2_bracken_species/RefSeqCompleteV205_500GB/
mv kraken2_kreport/RefSeqCompleteV205_500GB/*bracken* kraken2_bracken_species/RefSeqCompleteV205_500GB/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_500GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/
mkdir kraken2_bracken_genus/RefSeqCompleteV205_500GB/
mv kraken2_kreport/RefSeqCompleteV205_500GB/*bracken* kraken2_bracken_genus/RefSeqCompleteV205_500GB/

sudo rm -r /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/
```

GTDB r202 + NCBI RefSeq V205:
```{bash, eval=FALSE}
#done
sudo cp -a /home/storage/robyn/kraken2_databases/kraken2_GTDBr202_RefSeqV205/ /scratch/ramdisk/
mkdir kraken2_kreport/GTDBr202RefSeqV205/

parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/GTDBr202RefSeqV205/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 1.00 ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/GTDBr202RefSeqV205/*.kreport ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/
mkdir kraken2_bracken_species/GTDBr202RefSeqV205/
mv kraken2_kreport/GTDBr202RefSeqV205/*bracken* kraken2_bracken_species/GTDBr202RefSeqV205/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/GTDBr202RefSeqV205/*.kreport ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/
mkdir kraken2_bracken_genus/GTDBr202RefSeqV205/
mv kraken2_kreport/GTDBr202RefSeqV205/*bracken* kraken2_bracken_genus/GTDBr202RefSeqV205/

sudo rm -r /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/
```

MiniKraken V2:
```{bash, eval=FALSE}
#done
sudo cp -a /home/storage/robyn/kraken2_databases/minikraken2_v2_8GB_201904_UPDATE/ /scratch/ramdisk/
mkdir kraken2_kreport/minikraken/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/minikraken/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 1.00 ::: /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/minikraken/*.kreport ::: /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/
mkdir kraken2_bracken_species/minikraken/
mv kraken2_kreport/minikraken/*bracken* kraken2_bracken_species/minikraken/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/minikraken/*.kreport ::: /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/
mkdir kraken2_bracken_genus/minikraken/
mv kraken2_kreport/minikraken/*bracken* kraken2_bracken_genus/minikraken/

sudo rm -r /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/
```

ChocoPhlAn:
```{bash, eval=FALSE}
#done
sudo cp -a /home/storage/robyn/kraken2_databases/kraken2_chocophlanV30-201901/ /scratch/ramdisk/
mkdir kraken2_kreport/chocophlan/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/chocophlan/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 1.00 ::: /scratch/ramdisk/kraken2_chocophlanV30-201901/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/chocophlan/*.kreport ::: /scratch/ramdisk/kraken2_chocophlanV30-201901/
mkdir kraken2_bracken_species/chocophlan/
mv kraken2_kreport/chocophlan/*bracken* kraken2_bracken_species/chocophlan/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/chocophlan/*.kreport ::: /scratch/ramdisk/kraken2_chocophlanV30-201901/
mkdir kraken2_bracken_genus/chocophlan/
mv kraken2_kreport/chocophlan/*bracken* kraken2_bracken_genus/chocophlan/

sudo rm -r /scratch/ramdisk/kraken2_chocophlanV30-201901/
```

RefSeq V208 nt:
```{bash, eval=FALSE}
#done
sudo cp -a /home/robyn/databases_May2021/kraken2_RefSeqV208_nt/ /scratch/ramdisk/
mkdir kraken2_kreport/RefSeqV208_nt/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/RefSeqV208_nt/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 1.00 ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqV208_nt/*.kreport ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/
mkdir kraken2_bracken_species/RefSeqV208_nt/
mv kraken2_kreport/RefSeqV208_nt/*bracken* kraken2_bracken_species/RefSeqV208_nt/

parallel -j 60 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqV208_nt/*.kreport ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/
mkdir kraken2_bracken_genus/RefSeqV208_nt/
mv kraken2_kreport/RefSeqV208_nt/*bracken* kraken2_bracken_genus/RefSeqV208_nt/

sudo rm -r /scratch/ramdisk/kraken2_RefSeqV208_nt/
```

Standard:
```{bash, eval=FALSE}
#done
sudo cp -a /home/robyn/databases_May2021/Kraken2_standard/ /scratch/ramdisk/
mkdir kraken2_kreport/standard/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/{1/.}.kraken --report kraken2_kreport/standard/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 1.00 ::: /scratch/ramdisk/Kraken2_standard/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/standard/*.kreport ::: /scratch/ramdisk/Kraken2_standard/
mkdir kraken2_bracken_species/standard/
mv kraken2_kreport/standard/*bracken* kraken2_bracken_species/standard/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/standard/*.kreport ::: /scratch/ramdisk/Kraken2_standard/
mkdir kraken2_bracken_genus/standard/
mv kraken2_kreport/standard/*bracken* kraken2_bracken_genus/standard/

sudo rm -r /scratch/ramdisk/Kraken2_standard/
```

### MetaPhlAn

```{bash, eval=FALSE}
parallel -j 4 --progress 'metaphlan {} --nproc 12 --input_type fastq --bowtie2db /home/robyn/databases_May2021/metaphlan/ --unknown_estimation -o metaphlan_out/{/.}.txt -t rel_ab_w_read_stats' ::: all_samples/*
```

# Combine output for all runs

## All RefSeq-based

### Kraken combine per sample

```{python, eval=FALSE}
clr_transform = False

direc = '/home/robyn/simulated_samples/'
folders = ['kraken2_standard/']#'kraken2_chocophlanV30/', 'kraken2_minikraken/', 'kraken2_refseqV205_100GB/', 'kraken2_refseqV205_500GB/', 'kraken2_refseqV205/', 'kraken2_refseqV93/', 'kraken2_RefSeqV208_nt/']
name = ['kraken2_standard_0521']#'kraken2_chocophlan', 'kraken2_minikraken', 'kraken2_refseqV205_100GB', 'kraken2_refseqV205_500GB', 'kraken2_refseqV205', 'kraken2_refseqV93', 'kraken2_refseqV208_nt']
save_folder = '/home/robyn/simulated_samples/kraken_combined/'

samples = os.listdir(direc+'metaphlan_profiles/')
samples = [sample.replace('.txt', '') for sample in samples if sample != 'merged_abundance_table.txt']

confidence = ['0.00', '0.05', '0.10', '0.15', '0.20', '0.25', '0.30', '0.35', '0.40', '0.45', '0.50', '0.55', '0.60', '0.65', '0.70', '0.75', '0.80', '0.85', '0.90', '0.95', '1.00']

taxid_dict = {}

for f in range(len(folders)):
  print(f)
  all_output = os.listdir(direc+folders[f])
  all_output = [out for out in all_output if out.split('.')[-1] == 'bracken']
  for sample in samples:
    print(sample)
    for conf in confidence:
      #if conf != '0.00': continue
      sn = sample+'.'+conf+'.bracken'
      new_sn = sample+'-'+name[f]+'-'+conf
      if sn not in all_output:
        this_sample[new_sn] = 0
        continue
      this_conf = pd.read_csv(direc+folders[f]+sn, sep='\t', header=0, index_col=1)
      for row in this_conf.index.values:
        taxid_dict[row] = this_conf.loc[row, 'name']
      this_conf = pd.DataFrame(this_conf.loc[:, 'new_est_reads']).rename(columns={'new_est_reads':new_sn})
      if conf == '0.00':
        this_sample = this_conf
      else:
        this_sample = pd.concat([this_sample, this_conf]).fillna(value=0)
        this_sample = this_sample.groupby(by=this_sample.index, axis=0).sum()
    if clr_transform:
      if len(this_sample.index.values) > 2:
        this_sample[this_sample == 0] = 1
        for col in this_sample.columns:
          this_sample.loc[:, col] = clr(this_sample.loc[:, col].values)
      this_sample.to_csv(save_folder+sample+'-'+name[f]+'-clr.csv')
    else:
      this_sample.to_csv(save_folder+sample+'-'+name[f]+'.csv')

# with open(direc+'refseq_taxid_dict.dict', 'wb') as f:
#     pickle.dump(taxid_dict, f)
```

### Combine all

```{python, eval=FALSE}
all_files = os.listdir('kraken_combined/')
all_files = [f for f in all_files if 'clr' not in f]

names = ['kraken2_standard_0521']#'kraken2_chocophlan', 'kraken2_minikraken', 'kraken2_refseqV205_100GB', 'kraken2_refseqV205_500GB', 'kraken2_refseqV205', 'kraken2_refseqV93', 'kraken2_refseqV208_nt']

all_dfs = []

for name in names:
  df_list = []
  these_dfs = []
  count = 0
  these_files = [f for f in all_files if name in f]
  if name == 'kraken2_refseqV205':
    these_files = [f for f in these_files if 'GB' not in f]
  for f in these_files:
    df_list.append(pd.read_csv('kraken_combined/'+f, index_col=0, header=0))
    if len(df_list) > 0:
      print(name, count)
      combined_df = pd.concat(df_list)
      combined_df = combined_df.fillna(value=0)
      combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
      if count%50 == 0:
        these_dfs.append(combined_df)
        df_list = []
      else:
        df_list = [combined_df]
    count += 1
  combined_df = pd.concat(these_dfs+df_list)
  combined_df = combined_df.fillna(value=0)
  combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
  combined_df.to_csv(name+'_combined.csv')
  all_dfs.append(combined_df)

for name in names:
  all_dfs.append(pd.read_csv(name+'_combined.csv', header=0, index_col=0))

new_df = []
for df in all_dfs:
  new_df.append(df)
  if len(new_df) > 1:
    combined_df = pd.concat(new_df)
    combined_df = combined_df.fillna(value=0)
    combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
    new_df = [combined_df]
  

combined_df.to_csv('kraken_combined_RefSeq.csv')
```

### MetaPhlAn

#### Default

```{python, eval=FALSE}
files = os.listdir('metaphlan_out/')
all_samples = []
for file in files:
  if file == '.DS_Store': continue
  profile = pd.read_csv('metaphlan_out/'+file, index_col=0, header=3, sep='\t')
  rows = []
  for row in profile.index.values:
    if 's__' in row:
      taxid = profile.loc[row, 'NCBI_tax_id']
      abundance = profile.loc[row, 'relative_abundance']
      taxid = taxid.split('|')[-1]
      rows.append([taxid, abundance])
  this_sample = pd.DataFrame(rows, columns=['Taxid', 'MetaPhlAn-'+file.replace('.txt', '')])
  all_samples.append(this_sample.set_index('Taxid'))
all_samples = pd.concat(all_samples).fillna(value=0)
all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum()
all_samples.to_csv('MetaPhlAn_combined.csv')
```

#### Estimated reads

```{python, eval=FALSE}
files = os.listdir(direc_db+'metaphlan_reads/')
all_samples = []
for file in files:
  if file == '.DS_Store': continue
  profile = pd.read_csv(direc_db+'metaphlan_reads/'+file, index_col=0, header=4, sep='\t')
  rows = []
  for row in profile.index.values:
    if 's__' in row:
      taxid = profile.loc[row, 'clade_taxid']
      abundance = profile.loc[row, 'estimated_number_of_reads_from_the_clade']
      taxid = taxid.split('|')[-1]
      rows.append([taxid, abundance])
  this_sample = pd.DataFrame(rows, columns=['Taxid', 'MetaPhlAn-'+file.replace('.txt', '')])
  all_samples.append(this_sample.set_index('Taxid'))
all_samples = pd.concat(all_samples).fillna(value=0)
all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum()
all_samples.to_csv(direc_db+'MetaPhlAn_reads_combined.csv')
```

#### Number of reads from bowtie2 file

```{python, eval=FALSE}
all_samples = []
for file in os.listdir(direc_db+'metaphlan_bowtie2/'):
  tax_dict = {}
  for row in open(direc_db+'metaphlan_bowtie2/'+file, 'r'):
    row = row.replace('\n', '').split('\t')
    tax = row[1].split('__')[0]
    if tax in tax_dict:
      tax_dict[tax] = tax_dict[tax]+1
    else: tax_dict[tax] = 1
  all_samples.append(pd.DataFrame.from_dict(tax_dict, orient='index', columns=[file.split('.fas')[0]]))

all_samples = pd.concat(all_samples).fillna(value=0)
all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum()
all_samples.to_csv(direc_db+'MetaPhlAn_reads_bowtie2_combined.csv')
```

#### Different bowtie2 settings

```{python, eval=FALSE}
files = os.listdir(direc_db+'metaphlan_reads_bowtie2_settings/')
all_samples = []
for file in files:
  if file == '.DS_Store': continue
  profile = pd.read_csv(direc_db+'metaphlan_reads_bowtie2_settings/'+file, index_col=0, header=4, sep='\t')
  rows = []
  for row in profile.index.values:
    if 's__' in row:
      taxid = profile.loc[row, 'clade_taxid']
      abundance = profile.loc[row, 'estimated_number_of_reads_from_the_clade']
      taxid = taxid.split('|')[-1]
      rows.append([taxid, abundance])
  if '_sensitive.txt' in file:
    this_sample = pd.DataFrame(rows, columns=['Taxid', 'MetaPhlAn-'+file.replace('_sensitive.txt', '-sensitive')])
  elif '_sensitive-local.txt' in file:
    this_sample = pd.DataFrame(rows, columns=['Taxid', 'MetaPhlAn-'+file.replace('_sensitive-local.txt', '-sensitive_local')])
  elif '_very-sensitive-local.txt' in file:
    this_sample = pd.DataFrame(rows, columns=['Taxid', 'MetaPhlAn-'+file.replace('_very-sensitive-local.txt', '-very_sensitive_local')])
  all_samples.append(this_sample.set_index('Taxid'))
all_samples = pd.concat(all_samples).fillna(value=0)
all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum()
all_samples.to_csv(direc_db+'MetaPhlAn_reads_bowtie2_settings_combined.csv')
```

#### Different read estimation settings

```{python, eval=FALSE}
files = os.listdir(direc_db+'metaphlan_read_estimating_options/')
all_samples = []
for file in files:
  if file == '.DS_Store': continue
  elif 'bowtie2out' not in file: continue
  elif 'bowtie2out.' in file and 'bowtie2out_' in file: continue
  profile = pd.read_csv(direc_db+'metaphlan_read_estimating_options/'+file, index_col=0, header=4, sep='\t')
  sn1 = file.split('.fast')[0]
  sn2 = file.split('bowtie2out_')[1].replace('.txt', '')
  rows = []
  for row in profile.index.values:
    if 's__' in row:
      taxid = profile.loc[row, 'clade_taxid']
      abundance = profile.loc[row, 'estimated_number_of_reads_from_the_clade']
      taxid = taxid.split('|')[-1]
      rows.append([taxid, abundance])
  this_sample = pd.DataFrame(rows, columns=['Taxid', sn1+'-MetaPhlAn-'+sn2])
  all_samples.append(this_sample.set_index('Taxid'))
all_samples = pd.concat(all_samples).fillna(value=0)
all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum()
all_samples.to_csv(direc_db+'MetaPhlAn_reads_estimation_settings_combined.csv')
```

#### HUMANN

##### Bowtie2 aligned

```{python, eval=FALSE}
import os
import pandas as pd

folders = os.listdir('humann_out/')
folders = [f for f in folders if 'temp' in f and 'bowtie2out' not in f]
count = 0
#bowtie2 = []
bowtie2 = pd.read_csv('metaphlan_humann_bowtie2_2_aligned.csv', index_col=0, header=0)
for f in folders:
  print(f)
  #if count > 0: break
  files = os.listdir('humann_out/'+f)
  files = [fi for fi in files if 'bowtie2_aligned.tsv' in fi]
  if len(files) == 0 or f.replace('_humann_temp', '') in bowtie2.columns: continue
  for fi in files:
    print(fi)
    if 'bowtie2' not in fi: continue
    this_file = pd.read_csv('humann_out/'+f+'/'+fi, header=None, sep='\t')
    this_file_seq = pd.read_csv('humann_out/'+f+'/'+fi, index_col=0, header=None, sep='\t')
    seqs = list(this_file.loc[:, 0])
    classifications = list(this_file.loc[:, 1])
    seq_classifications = {}
    for key,value in zip(seqs,classifications):
      if key not in seq_classifications:
          seq_classifications[key]=[value]
      else:
          seq_classifications[key].append(value)
    
    taxid_count = {}
    multiple_matches = {}
    for seq in seq_classifications:
      if len(seq_classifications[seq]) == 1:
        tid = seq_classifications[seq][0].split('_')[0]
      else:
        matches = seq_classifications[seq]
        matches = [match.split('_')[0] for match in matches]
        if len(set(matches)) == 1:
          tid = matches[0]
        else:
          multiple_matches[seq] = seq_classifications[seq]
          continue
      
      if tid in taxid_count:
        taxid_count[tid] += 1
      else:
        taxid_count[tid] = 1
        
    taxid_count['Multiple matches'] = len(multiple_matches)
    this_df = pd.DataFrame.from_dict(taxid_count, orient='index', columns=[f.replace('_humann_temp', '')])
      
    if isinstance(bowtie2, list):
      bowtie2 = pd.DataFrame(this_df)
    else:
      bowtie2 = pd.concat([bowtie2, this_df])
      bowtie2 = bowtie2.groupby(by=bowtie2.index, axis=0).sum()
      
  count += 1

bowtie2.to_csv('metaphlan_humann_bowtie2_3_aligned.csv')
```

##### Diamond aligned

```{python, eval=FALSE}
import os
import pandas as pd
import pickle

folders = os.listdir('humann_out/')
folders = [f for f in folders if 'temp' in f and 'bowtie2out' not in f]

# uniref_to_taxid = {}
# for row in open('idmapping.dat', 'r'):
#   if 'NCBI_TaxID' in row:
#     row = row.replace('\n', '').split('\t')
#     uniref_to_taxid[row[0]] = row[2]
# 
# with open('uniref_to_taxid.dict', 'wb') as f:
#     pickle.dump(uniref_to_taxid, f)

with open('uniref_to_taxid.dict', 'rb') as f:
    uniref_to_taxid = pickle.load(f)

diamond = []
count = 0
diamond = pd.read_csv('metaphlan_humann_diamond_aligned.csv', index_col=0, header=0)
for f in folders:
  print(f)
  #if count > 0: break
  files = os.listdir('humann_out/'+f)
  files = [fi for fi in files if 'diamond_aligned.tsv' in fi]
  if len(files) == 0: continue
  if not isinstance(diamond, list):
    if f.replace('_humann_temp', '') in diamond.columns: 
      continue
  for fi in files:
    print(fi)
    if 'diamond' not in fi: continue
    this_file = pd.read_csv('humann_out/'+f+'/'+fi, header=None, sep='\t')
    this_file_seq = pd.read_csv('humann_out/'+f+'/'+fi, index_col=0, header=None, sep='\t')
    seqs = this_file.loc[:, 0]
    classifications = list(this_file.loc[:, 1])
    seq_classifications = {}
    for key, value in zip(seqs,classifications):
      if key not in seq_classifications:
        seq_classifications[key]=[value]
      else:
        seq_classifications[key].append(value)
    taxid_count = {}
    multiple_matches = []
    for seq in seq_classifications:
      if len(seq_classifications[seq]) == 1:
        try:
          single_class = seq_classifications[seq][0].split('_')[1].split('|')[0]
          tid = uniref_to_taxid[single_class]
        except:
          tid = 'No_taxid'
      elif len(seq_classifications[seq]) == 2 and 'UniRef90' in seq_classifications[seq][0] and 'UniRef50' in seq_classifications[seq][1]:
        single_class = seq_classifications[seq][0].split('_')[1].split('|')[0]
        try: tid = uniref_to_taxid[single_class]
        except: tid = 'No_taxid'
      elif len(seq_classifications[seq]) == 2 and 'UniRef90' in seq_classifications[seq][1] and 'UniRef50' in seq_classifications[seq][0]:
        single_class = seq_classifications[seq][1].split('_')[1].split('|')[0]
        try: tid = uniref_to_taxid[single_class]
        except: tid = 'No_taxid'
      else:
        taxids = []
        for classif in seq_classifications[seq]:
          try:
            taxids.append(uniref_to_taxid[classif.split('_')[1].split('|')[0]])
          except:
            taxids.append('No_taxid')
        if len(set(taxids)) == 1:
          tid = taxids[0]
        elif len(set(taxids)) == 2 and 'No_taxid' in taxids:
          for taxid in taxids:
            if taxid != 'No_taxid': 
              tid = taxid
              break
        else:
          multiple_matches.append(seq)
          continue
      if tid in taxid_count:
        taxid_count[tid] += 1
      else:
        taxid_count[tid] = 1
    taxid_count['Multiple matches'] = len(multiple_matches)
    this_df = pd.DataFrame.from_dict(taxid_count, orient='index', columns=[f.replace('_humann_temp', '')])
    if isinstance(diamond, list):
      diamond = pd.DataFrame(this_df)
    else:
      diamond = pd.concat([diamond, this_df])
      diamond = diamond.groupby(by=diamond.index, axis=0).sum()
  count += 1

diamond.to_csv('metaphlan_humann_diamond_2_aligned.csv') 
```

## GTDB-RefSeq

Combine per sample:
```{python, eval=FALSE}
clr_transform = False

direc = '/home/robyn/simulated_samples/'
folders = ['kraken2_GTDBr202RefSeqV205/']
name = ['kraken2_GTDBr202RefSeqV205']
save_folder = '/home/robyn/simulated_samples/kraken_combined_GTDB/'

samples = os.listdir(direc+'metaphlan_profiles/')
samples = [sample.replace('.txt', '') for sample in samples if sample != 'merged_abundance_table.txt']

confidence = ['0.00', '0.05', '0.10', '0.15', '0.20', '0.25', '0.30', '0.35', '0.40', '0.45', '0.50', '0.55', '0.60', '0.65', '0.70', '0.75', '0.80', '0.85', '0.90', '0.95', '1.00']

taxid_dict = {}

for f in range(len(folders)):
  all_output = os.listdir(direc+folders[f])
  all_output = [out for out in all_output if out.split('.')[-1] == 'bracken']
  for sample in samples:
    for conf in confidence:
      #if conf != '0.00': continue
      sn = sample+'.'+conf+'.bracken'
      new_sn = sample+'-'+name[f]+'-'+conf
      if sn not in all_output:
        this_sample[new_sn] = 0
        continue
      this_conf = pd.read_csv(direc+folders[f]+sn, sep='\t', header=0, index_col=0)
      for row in this_conf.index.values:
        taxid_dict[row] = this_conf.loc[row, 'taxonomy_id']
      this_conf = pd.DataFrame(this_conf.loc[:, 'new_est_reads']).rename(columns={'new_est_reads':new_sn})
      if conf == '0.00':
        this_sample = this_conf
      else:
        this_sample = pd.concat([this_sample, this_conf]).fillna(value=0)
        this_sample = this_sample.groupby(by=this_sample.index, axis=0).sum()
    if clr_transform:
      if len(this_sample.index.values) > 2:
        this_sample[this_sample == 0] = 1
        for col in this_sample.columns:
          this_sample.loc[:, col] = clr(this_sample.loc[:, col].values)
      this_sample.to_csv(save_folder+sample+'-'+name[f]+'-clr.csv')
    else:
      this_sample.to_csv(save_folder+sample+'-'+name[f]+'.csv')

with open(direc+'gtdb_taxid_dict.dict', 'wb') as f:
    pickle.dump(taxid_dict, f)
```

Combine all:
```{python, eval=FALSE}
all_files = os.listdir('kraken_combined_GTDB/')
all_files = [f for f in all_files if 'clr' not in f]
all_files = [f for f in all_files if 'kraken2_GTDBr202RefSeqV205' in f]

df_list = []
count = 0 
for f in all_files:
  df_list.append(pd.read_csv('kraken_combined_GTDB/'+f, index_col=0, header=0))
  if count == 20:
    print(f)
    combined_df = pd.concat(df_list)
    combined_df = combined_df.fillna(value=0)
    combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
    df_list = [combined_df]
    count = 0
  count += 1

combined_df = pd.concat(df_list)
combined_df = combined_df.fillna(value=0)
combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
combined_df.to_csv('kraken_combined_GTDB.csv')
```

# Get all genome sizes from NCBI

```{bash, eval=FALSE}
wget https://api.ncbi.nlm.nih.gov/genome/v0/expected_genome_size?species_taxid=287
#this saves an xml with the the name expected_genome_size\?species_taxid\=287 that has the info that we want
```

```{python, eval=FALSE}
import os
import pickle

with open('ncbi_taxid.dict', 'rb') as f:
    taxid_dict = pickle.load(f)

print(len(taxid_dict))

id_list = []
for taxid in taxid_dict:
    id_list.append([taxid_dict[taxid], taxid])

os.chdir('expected_genome_size/')
got_id = []

for ids in id_list:
  if ids[0] not in got_id:
    os.system('wget https://api.ncbi.nlm.nih.gov/genome/v0/expected_genome_size?species_taxid='+str(ids[0])+' -q')
    got_id.append(ids[0])

new_df = pd.DataFrame(id_list, columns=['taxid', 'Genome ref']).set_index('taxid')
new_df['genome_count'] = ''
new_df['expected_ungapped_length'] = ''
new_df['minimum_ungapped_length'] = ''
new_df['maximum_ungapped_length'] = ''

os.chdir('/home/robyn/databases_May2021/scripts_and_intermediates/')
files = os.listdir('expected_genome_size/')
os.chdir('expected_genome_size/')
count = 0
for file in files:
  fname = str(file)
  #if count > 10: continue
  with open(file, 'r') as f:
    file = f.read()
    string = ''
    this_dict = {}
    for f in file:
      if f != '\n': 
        string += f
      else:
        if 'genome_count' in string or 'expected_ungapped_length' in string or 'minimum_ungapped_length' in string or 'maximum_ungapped_length' in string:
          this_row = string.split('<')[1]
          this_row = this_row.split('>')
          this_dict[this_row[0]] = this_row[1]
        string = ''
  taxid = int(fname.split('=')[1])
  for di in this_dict:
    new_df.loc[taxid, di] = this_dict[di]
  count += 1

os.chdir('/home/robyn/databases_May2021/scripts_and_intermediates/')
new_df.to_csv('expected_genome_size.csv')

```

# Get truth samples

## Get number of reads in all fasta/fastq files

```{python, eval=FALSE}
import os
import pandas as pd

files = os.listdir('samples_running/')
sample_counts = []
for f in files:
  nl = sum(1 for line in open('samples_running/'+f))
  if '.fastq' in f:
    count = nl/4
  else:
    count = nl/2
  sample_counts.append([f.replace('.fastq', '').replace('.fasta', ''), count])

sample_counts_new = [c for c in sample_counts if 'bowtie2out' not in c[0]]
sample_counts = pd.DataFrame(sample_counts_new, columns=['Sample name', 'Number of reads'])
sample_counts = sample_counts.set_index('Sample name')
sample_counts.to_csv('Number_of_reads_per_sample.csv')
```

## CAMI

```{python, eval=FALSE}
cami = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/CAMI profiles/'
reads = {'RH_S001__insert_270':99811870, 'RH_S002__insert_270':99808454, 'RH_S003__insert_270':99809214, 'RH_S004__insert_270':99805006, 'RH_S005__insert_270':99803592, 'RL_S001__insert_270':99796358, 'RM1_S001__insert_5000':33140480, 'RM1_S002__insert_5000':33128228, 'RM2_S001__insert_270':99837678, 'RM2_S002__insert_270':99787568}

cami_taxpath_dict = {}
cami_taxid_dict = {}

files = os.listdir(cami)
files = [f for f in files if 'profile' in f]

all_profiles = []
for file in files:
  fn = file
  name = cami_names[fn.replace('.profile', '')]
  file = pd.read_csv(cami+file, header=3, index_col=2, sep='\t', dtype=str)
  file_species = file.loc[file['RANK'] == 'strain']
  for row in file_species.index.values:
    #cami_taxid_dict[row] = file_species.loc[row, 'TAXPATH']
    cami_taxpath_dict[row] = file_species.loc[row, 'TAXPATHSN']
  if not isinstance(name, str):
    file_species = pd.DataFrame(file_species.loc[:, ['PERCENTAGE', 'PERCENTAGE']])
    file_species.columns = name
    for n in name:
      file_species[n] = file_species[n].astype('float')
      file_species[n] = (file_species[n]/100)*reads[n]
      file_species[n] = file_species[n].astype('int32')
  else:
    file_species = pd.DataFrame(file_species.loc[:, 'PERCENTAGE']).rename(columns={'PERCENTAGE':name})
    file_species[name] = file_species[name].astype('float')
    file_species[name] = (file_species[name]/100)*reads[name]
    file_species[name] = file_species[name].astype('int32')
  all_profiles.append(file_species)

all_profiles = pd.concat(all_profiles).fillna(value=0)
all_profiles = all_profiles.groupby(by=all_profiles.index, axis=0).sum()
all_profiles.to_csv('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/CAMI_full.csv')

levels = ['kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species', 'strain']

for a in range(8):
  this_profile = pd.DataFrame(all_profiles)
  rename = {}
  for row in this_profile.index.values:
    taxid = row.split('|')
    if taxid[a] == '': rename[row] = 'unclassified'
    else: rename[row] = taxid[a]
    if a == 8:
      cami_taxid_dict[taxid[a]] = row
  this_profile = this_profile.rename(index=rename)
  this_profile = this_profile.groupby(by=this_profile.index, axis=0).sum()
  this_profile.to_csv('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/CAMI_'+levels[a]+'.csv')

with open('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/combined/'+'CAMI_taxid_dict_strain.dict', 'wb') as f:
    pickle.dump(cami_taxid_dict, f)
with open('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/combined/'+'CAMI_taxid_dict_strain_names.dict', 'wb') as f:
    pickle.dump(cami_taxpath_dict, f)
```

## McIntyre

```{python, eval=FALSE}
mcintyre = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/mcintyre/species/'

mcintyre_taxid_dict = {}

files = os.listdir(mcintyre)
files = [f for f in files if 'TRUTH' in f]
all_profiles = []

for file in files:
  fn = file.replace('.txt', '')
  this_file = pd.read_csv(mcintyre+file, sep='\t', header=None, index_col=0)
  this_file = this_file.rename(columns={0:'taxid', 1:fn, 2:'Proportion', 3:'Rank', 4:'Species name'})
  for row in this_file.index.values:
    mcintyre_taxid_dict[row] = this_file.loc[row, 'Species name']
  this_file = pd.DataFrame(this_file.loc[:, fn])
  all_profiles.append(this_file)

all_profiles = pd.concat(all_profiles).fillna(value=0)
all_profiles = all_profiles.groupby(by=all_profiles.index, axis=0).sum()
all_profiles = all_profiles.divide(all_profiles.sum(axis=0), axis=1)
reads = pd.read_csv(direc_truth+'Number of reads.csv', index_col=0, header=0)
rename = {}
for col in all_profiles.columns:
  rename[col] = col.replace('_TRUTH', '')
rename['BioPool_BioPool_TRUTH'] = 'BioPool'
all_profiles = all_profiles.rename(columns=rename)
for col in all_profiles.columns:
  all_profiles[col] = all_profiles[col]*reads.loc[col, 'Number of reads']
  all_profiles[col] = all_profiles[col].astype('int32')

#all_profiles.drop(['UnAmbiguouslyMapped_ds.hous2', 'HMP_even_illum_SRR172902', 'ABRF_MGRG_classIplus'], axis=1, inplace=True)
all_profiles.to_csv('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/McIntyre.csv')

with open('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/combined/'+'McIntyre_taxid_dict.dict', 'wb') as f:
    pickle.dump(mcintyre_taxid_dict, f)
```

## Parks

```{python, eval=FALSE}
parks = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/parks_truth/'

gtdb_accession_taxid = {}
gtdb_archaea = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/GTDB_r202_archaea.tsv'
gtdb_bacteria = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/GTDB_r202_bacteria.tsv'

gtdb_archaea = pd.read_csv(gtdb_archaea, header=0, sep='\t')
for row in gtdb_archaea.index.values:
  acc = gtdb_archaea.loc[row, 'accession'].split('_', 1)[1].split('.')[0]
  taxid = gtdb_archaea.loc[row, 'ncbi_taxid']
  tax = gtdb_archaea.loc[row, 'ncbi_taxonomy']
  gtdb_accession_taxid[acc] = [taxid, tax]

gtdb_bacteria = pd.read_csv(gtdb_bacteria, header=0, sep='\t')
for row in gtdb_bacteria.index.values:
  acc = gtdb_bacteria.loc[row, 'accession'].split('_', 1)[1].split('.')[0]
  taxid = gtdb_bacteria.loc[row, 'ncbi_taxid']
  tax = gtdb_bacteria.loc[row, 'ncbi_taxonomy']
  gtdb_accession_taxid[acc] = [taxid, tax]

parks_taxid_dict = {}

files = os.listdir(parks)
all_profiles = []
genomes_needed_dict = {'G006384915':207340, 'G005864435':1744, 'G001515545':32013}

for file in files:
  #if file != 'ani95_cLOW_stFalse_r0.tsv': continue
  fn = file.replace('.txt', '')
  this_file = pd.read_csv(parks+file, sep='\t', header=0, index_col=0)
  this_file['Taxid'] = ''
  for row in this_file.index.values:
    genome = this_file.loc[row, 'Genome file'].split('.')[0].replace('GCA', 'GCF')
    try:
      taxid, taxon = gtdb_accession_taxid[genome]
      this_file.loc[row, 'Taxid'] = taxid
    except:
      try:
        genome = genome.replace('GCF', 'GCA')
        taxid, taxon = gtdb_accession_taxid[genome]
        this_file.loc[row, 'Taxid'] = taxid
      except:
        taxid = genomes_needed_dict[row]
        this_file.loc[row, 'Taxid'] = taxid
    parks_taxid_dict[taxid] = this_file.loc[row, 'NCBI species']
  this_file = this_file.set_index('Taxid')
  this_file = pd.DataFrame(this_file.loc[:, 'No. simulated reads'])
  this_file = this_file.rename(columns={'No. simulated reads':fn})
  all_profiles.append(this_file)

all_profiles = pd.concat(all_profiles).fillna(value=0)
all_profiles = all_profiles.groupby(by=all_profiles.index, axis=0).sum()
all_profiles.to_csv('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/Parks.csv')

with open('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/combined/'+'Parks_taxid_dict.dict', 'wb') as f:
    pickle.dump(parks_taxid_dict, f)
```

## Combine all truth

```{python, eval=FALSE}
cami = pd.read_csv(direc_truth+'CAMI_species.csv', header=0, index_col=0)
mcintyre = pd.read_csv(direc_truth+'McIntyre.csv', header=0, index_col=0)
parks = pd.read_csv(direc_truth+'Parks.csv', header=0, index_col=0)
mcintyre_neg = pd.read_csv(direc_truth+'McIntyre_negatives.csv', header=0, index_col=0)
zymo = pd.read_csv(direc_truth+'zymomock.csv', header=0, index_col=0)

parks_names = {}
for col in parks.columns:
  parks_names[col] = col.replace('.tsv', '')
parks = parks.rename(columns=parks_names)

truth = pd.concat([cami, mcintyre, parks, mcintyre_neg, zymo]).fillna(value=0)
truth = truth.drop(['unclassified'], axis=0)
truth.index = truth.index.map(str)
truth = truth.groupby(by=truth.index, axis=0).sum()
rename = {}
for col in truth.columns:
  if '_TRUTH' in col:
    rename[col] = col.replace('_TRUTH', '')
rename['BioPool_BioPool_TRUTH'] = 'BioPool'
truth = truth.rename(columns=rename)
truth.to_csv(direc_truth+'combined/truth.csv')
```

## Compare number of reads with truth samples

Basically:
- if the number of reads that are in a sample according the the "truth" sample is equal (or within 1%) to that counted in the fasta/fastq file, do nothing
- if it is half of that counted in the fasta/fastq, then we multiple the truth sample by 2 (for forward and reverse reads)
- if it is a negative control (human reads only in sample), the truth sample currently says that this has 0 reads but instead we want to assign all read to human (taxid 9606)
- if it is a CAMI sample, leave it (some levels of the CAMI truth samples - given in relative abundance - do not sum to 1)
- if it is a Mavromatis sample, remove it from the truth samples as it was contigs not reads
- if it is a Huttenhower, Carma or Raiphy sample, keep it as it is because the reads are split over more than one line in the fasta file (which is what I used to count the number of reads)
- if it is an ABRF_MGRG or BioPool sample, leave it because these ones were provided as paired fastq files and were therefore run through kneaddata and some lower quality reads were removed this way
- if it is JGI_SRR033547, remove it because it only has ~110 reads in the sample

```{python, eval=FALSE}
sample_counts = pd.read_csv(direc_db+'Number_of_reads_per_sample.csv', index_col=0, header=0)
truth_samples = pd.read_csv(direc_truth+'combined/truth.csv', index_col=0, header=0)
truth_sum = pd.DataFrame(truth_samples.sum(axis=0))

dropping = []

for sample in truth_sum.index.values:
  if sample in sample_counts.index.values:
    truth, reads = truth_sum.loc[sample, 0], sample_counts.loc[sample, 'Number of reads']
    if truth == reads: continue
    elif abs((reads-truth)/truth) <= 0.01: continue
    elif truth == 0: 
      truth_samples.loc['9606', sample] = reads
    elif round(int(reads)/int(truth)) == 2:
      truth_samples[sample] = truth_samples[sample].apply(lambda x: x*2)
    elif 'insert' in sample or 'Huttenhower' in sample or 'ABRF_MGRG' in sample or 'BioPool' in sample or 'Carma' in sample or 'Raiphy' in sample: continue
    elif 'Mavromatis' in sample or 'JGI_SRR033547' in sample: dropping.append(sample)

truth_samples = truth_samples.drop(dropping, axis=1).fillna(value=0)
truth_samples.to_csv(direc_truth+'truth.csv')
truth_samples.to_csv(direc_db+'truth.csv')
```

# GTDB taxid to NCBI taxid

```{python, eval=FALSE}
kraken_gtdb = pd.read_csv(direc_db+'kraken_combined_GTDB.csv', header=0, index_col=0)
all_sp = list(kraken_gtdb.index.values)

assembly_dir = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/assembly_lists/'
assemblies = os.listdir(assembly_dir)
assemblies = [f for f in assemblies if 'assembly_summary' in f and 'bacteria' not in f and 'archaea' not in f]
gtdb_archaea = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/GTDB_r202_archaea.tsv'
gtdb_bacteria = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/truth_sets/GTDB_r202_bacteria.tsv'

gtdb_species_taxid = {}

gtdb_archaea = pd.read_csv(gtdb_archaea, header=0, sep='\t')
for row in gtdb_archaea.index.values:
  acc = gtdb_archaea.loc[row, 'accession'].split('_', 1)[1].split('.')[0]
  taxid = gtdb_archaea.loc[row, 'ncbi_taxid']
  tax = gtdb_archaea.loc[row, 'gtdb_taxonomy']
  tax = tax.split(';')[-1]
  gtdb_species_taxid[tax] = taxid

gtdb_bacteria = pd.read_csv(gtdb_bacteria, header=0, sep='\t')
for row in gtdb_bacteria.index.values:
  acc = gtdb_bacteria.loc[row, 'accession'].split('_', 1)[1].split('.')[0]
  taxid = gtdb_bacteria.loc[row, 'ncbi_taxid']
  tax = gtdb_bacteria.loc[row, 'gtdb_taxonomy']
  tax = tax.split(';')[-1]
  gtdb_species_taxid[tax] = taxid

for assembly in assemblies:
  assembly = pd.read_csv(assembly_dir+assembly, index_col=0, header=1, sep='\t')
  for row in assembly.index.values:
    taxid = assembly.loc[row, 'taxid']
    tax = 's__'+assembly.loc[row, 'organism_name']
    gtdb_species_taxid[tax] = taxid

rank_dict = {}
rank_lineage = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/taxonomy/new_taxdump_2021-08-01/rankedlineage.dmp'
rank_lineage = pd.read_csv(rank_lineage, header=None, sep='\t')
for row in rank_lineage.index.values:
  rank_dict['s__'+rank_lineage.loc[row, 2]] = rank_lineage.loc[row, 0]

rank_dict['s__Bacillus virus vB_BsuM-Goe3'] = 2843794
rank_dict['s__Groundnut bud necrosis tospovirus'] = 1933261
rename_gtdb = {}

count = 0
not_there = []
for sp in all_sp:
  if sp in gtdb_species_taxid:
    rename_gtdb[sp] = gtdb_species_taxid[sp]
  elif sp in rank_dict:
    rename_gtdb[sp] = rank_dict[sp]
  else:
    not_there.append(sp)

kraken_gtdb = kraken_gtdb.drop(not_there, axis=0)
kraken_gtdb = kraken_gtdb.rename(index=rename_gtdb)
kraken_gtdb.to_csv(direc_db+'kraken_GTDBr202_RefSeqV205_NCBI_taxid_combined.csv')
```

# Number of reads classified kraken

```{python, eval=FALSE}
import os
import pandas as pd
names = ['kraken2_RefSeqV208_nt']#, 'kraken2_chocophlanV30', 'kraken2_minikraken', 'kraken2_refseqV205_100GB', 'kraken2_refseqV205_500GB', 'kraken2_refseqV205', 'kraken2_refseqV93', 'kraken2_GTDBr202RefSeqV205']

rows = []

for name in names:
  all_files = os.listdir(name)
  all_files = [f for f in all_files if '.kreport' in f and 'bracken' not in f]
  for file in all_files:
    #if file != 'ABRF_MGRG_10ng.0.00.kreport': continue
    this_file = pd.read_csv(name+'/'+file, header=None, index_col=5, sep='\t')
    try:
      unclassified = this_file.loc['unclassified', 1]
    except:
      unclassified = 0
    rows.append([name, file.replace('.kreport', ''), unclassified])

row_df = pd.DataFrame(rows, columns=['Database', 'Sample', 'Unclassified reads'])
row_df['Name'] = ''

count = 0
for row in row_df.index.values:
  sample, db = row_df.loc[row, 'Sample'], row_df.loc[row, 'Database']
  new_name = sample.split('.', 1)[0]+'-'+db.replace('V30', '').replace('RefSeqV208', 'refseqV208')+'-'+sample.split('.', 1)[1]
  row_df.loc[row, 'Name'] = new_name
  if count < 50:
    print(new_name)
  count += 1

row_df = row_df.set_index('Name')
row_df.to_csv('Unclassified_reads_V208.csv')
```

# Inspect databases

```{bash, eval=FALSE}
kraken2-inspect --db minikraken2_v2_8GB_201904_UPDATE/ > /home/robyn/databases_May2021/minikraken2_v2_8GB_201904_UPDATE.inspect #done

kraken2-inspect --db /home/storage/robyn/kraken2_databases/kraken2_chocophlanV30-201901 -t 12 > /home/robyn/databases_May2021/kraken2_chocophlanV30-201901.inspect #done

kraken2-inspect --db Kraken2.0.8_Bracken150mer_RefSeqCompleteV93 -t 12 > /home/robyn/databases_May2021/Kraken2.0.8_Bracken150mer_RefSeqCompleteV93.inspect

kraken2-inspect --db /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205 -t 12> /home/robyn/databases_May2021/kraken2_GTDBr202_RefSeqV205.inspect

kraken2-inspect --db /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2 -t 12 > /home/robyn/databases_May2021/RefSeqV205_Complete_V2.inspect

kraken2-inspect --db /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_100GB -t 12 > /home/robyn/databases_May2021/RefSeqV205_Complete_V2_100GB.inspect

kraken2-inspect --db /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_500GB -t 12 > /home/robyn/databases_May2021/RefSeqV205_Complete_V2_500GB.inspect
```

# Get tree for all taxonomy ID's all databases

```{python, results='hide', fig.keep='all', eval=FALSE}
direc = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/'
db_file = ['kraken_chocophlan_combined.csv', 'kraken_minikraken_combined.csv', 'kraken2_refseqV205_100GB_combined.csv', 'kraken2_refseqV205_500GB_combined.csv', 'kraken2_refseqV205_combined.csv', 'kraken2_refseqV208_nt_combined.csv', 'kraken2_refseqV93_combined.csv', 'kraken_GTDBr202_RefSeqV205_NCBI_taxid_combined.csv', 'truth.csv', 'MetaPhlAn_combined.csv', 'MetaPhlAn_reads_bowtie2_combined.csv', 'MetaPhlAn_reads_combined.csv', 'MetaPhlAn_reads_bowtie2_settings_combined.csv']

tax_id = []

for db in db_file:
    tax_id = tax_id+list(pd.read_csv(direc_db+db, index_col=0, header=0).index.values)

tax_id = list(set(tax_id))
merged =  direc+'taxonomy/new_taxdump_2021-10-01/merged.dmp'
merged = pd.read_csv(merged, sep='\t', header=None)
merged_dict = {}
for row in merged.index.values:
    merged_dict[str(merged.loc[row, 0])] = str(merged.loc[row, 2])

remove = [1673065, 1965377, 1980611, 2058935] # I knew to remove these from a first upload to PhyloT
with open(direc_db+"all_taxid_10Nov21.txt", "w") as f:
    for row in tax_id:
        if row in remove: continue
        if str(row) in merged_dict:
          writing = f.write(merged_dict[str(row)]+'\n')
        else:
          writing = f.write(str(row)+'\n')
```
Upload this list to PhyloT https://phylot.biobyte.de/index.cgi and get tree with NCBI taxonomy ID's
save the resulting tree as: direc_db+'phyloT_all_taxid_10Nov21.txt'

We have a list of taxonomy ID's (1046) now that aren't in PhyloT - direc_db+'all_taxid_not_in_phylot.txt' (pasted from the webpage when it says which ID's aren't present). These all appear to have been added in the latest version of RefSeq as they aren't in the nodes.dmp file that I downloaded in August, but are in the most recent one. I'll check how many reads these correspond to and just remove them if it's really negligible - they all seem to be to things like worms so I don't think they are very relevant to us.
```{python, eval=FALSE}
not_in_phylot = []
for row in open(direc_db+'all_taxid_not_in_phylot_10Nov21.txt', 'r'):
  not_in_phylot.append(int(row.replace('\n', '')))
not_in_phylot = [str(t) for t in not_in_phylot]

krak_combined_v208 = pd.read_csv(direc_db+'kraken2_refseqV208_nt_combined.csv', index_col=0, header=0)
krak_combined_v208.index = krak_combined_v208.index.map(str)
not_in_phylot_but_in_v208 = []
others = []
for tax in not_in_phylot:
  if tax in krak_combined_v208.index.values:
    not_in_phylot_but_in_v208.append(tax)
  else:
    others.append(tax)

# print(len(not_in_phylot_but_in_v208), len(others))
# 
# sum_v208 = krak_combined_v208.sum(axis=1)
# print(sum_v208.loc[not_in_phylot_but_in_v208].sum(), sum_v208.sum())
```
So the taxonomy ID's not present (1046, 976 of which aren't in V208 specifically) account for 52168874/36244232858 reads, or 0.14%, as well as 70 others. Perhaps a good compromise is to just use the parent ID for these, as presumably most of these will be in the database already?

```{python, eval=FALSE}
new_nodes = pd.read_csv(direc+'taxonomy/new_taxdump_2021-10-01/nodes.dmp', index_col=0, header=None, sep='|')
not_in_phylot = [int(t) for t in not_in_phylot]
tid_to_parent = {}
parents_of_tid_not_in_phylot_list = []
not_in_nodes = []
for tid in not_in_phylot:
  try:
    tid_to_parent[tid] = new_nodes.loc[tid, 1]
    parents_of_tid_not_in_phylot_list.append(new_nodes.loc[tid, 1])
  except:
    not_in_nodes.append(tid)

#remove = [1673065, 1965377, 1980611, 2058935]
remove = remove+not_in_nodes
    
with open(direc_db+'all_parents_of_taxid_not_in_phylot_10Nov21.txt', 'w') as f:
  for tid in parents_of_tid_not_in_phylot_list:
    written = f.write(str(tid)+'\n')
```
All but 63 of these are in the nodes list. The other 63 seem to be from the Bowtie2 MetaPhlAn 3 taxonomic assignments and I think are somehow actually mistakes because they don't seem to exist in the ChocoPhlAn 3 list of taxonomy ID's that I have, so I'm just going to remove them.

Now trying to make a tree with these parent taxid's on PhyloT, we have a reduced list of 113 ID's that can't be found, so let's explore these:
```{python, eval=FALSE}
phylot_children_and_parents_not_in_phylot = []
count = 0
for row in open(direc_db+'all_parents_not_in_phylot_10Nov21.txt', 'r'):
  for tid in tid_to_parent:
    if tid_to_parent[tid] == int(row.replace('\n', '')):
      phylot_children_and_parents_not_in_phylot.append(tid)
  count += 1
```
These account for a very small number of reads, so we will just remove them also. 

```{python, eval=FALSE}
# tax_id = []
# for row in open(direc_db+'all_taxid_10Nov21.txt', 'r'):
#   tax_id.append(int(row.replace('\n', '')))
#   
# merged =  direc+'taxonomy/new_taxdump_2021-10-01/merged.dmp'
# merged = pd.read_csv(merged, sep='\t', header=None)
# merged_dict = {}
# for row in merged.index.values:
#     merged_dict[str(merged.loc[row, 0])] = str(merged.loc[row, 2])

remove = remove+phylot_children_and_parents_not_in_phylot#+[2842389, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154, 2677154]
parents = tid_to_parent
count = 0

with open(direc_db+"all_taxid_with_parents_10Nov21.txt", "w") as f:
    for row in tax_id:
        if row in remove: continue
        if str(row) in merged_dict:
          written = f.write(merged_dict[str(row)]+'\n')
        elif int(row) in parents:
          if int(parents[int(row)]) not in remove:
            written = f.write(str(parents[int(row)])+'\n')
            count += 1
        else:
          written = f.write(str(row)+'\n')
```

Now this tree is saved as direc_db+'phyloT_10Nov21.txt'

```{python, results='hide', fig.keep='all', eval=FALSE}
tax_id = set([str(tax) for tax in tax_id])
tree = Tree(direc_db+'phyloT_10Nov21.txt', format=1)

# get a list of all names as well as which of these are internal nodes and rename the internal nodes that have 'INT' in the node name to remove this 'INT'
names = []
internals = []
for node in tree.traverse("postorder"):
    if 'INT' in node.name:
        node.name = node.name.split('INT')[1]
        internals.append(node.name)
    names.append(node.name)
names = set(names)
internals = set(internals)
internals = set([tax for tax in tax_id if tax in internals])

# save object with dictionary of merged tax ID's and tax ID's not present in the database
not_in_tree = [tax for tax in tax_id if tax not in names]
remove = remove+not_in_tree
for tid in parents:
  merged_dict[str(tid)] = str(parents[tid])
merged_remove = [merged_dict, remove]
with open(direc_db+'merged_remove_10Nov21.list', 'wb') as f:
    pickle.dump(merged_remove, f)

# for the nodes that are taxonomy ID's in our list but aren't leaves, make some leaves with these (with 0 distance from the node)
for node in tree.traverse("postorder"):
    if node.name in internals:
        node.add_child(name=node.name)

# write the renamed tree with the new nodes
tree.write(outfile=direc_db+"phyloT_renamed_10Nov21.txt", format=1)

# root the tree at the midpoint and write this rooted tree
R = tree.get_midpoint_outgroup()
tree.set_outgroup(R)
tree.write(outfile=direc_db+"phyloT_renamed_rooted_10Nov21.txt", format=1)
```

# Rename all of the merged and deleted taxonomy ID's within the files

We'll also get rid of the samples that we decided didn't have enough reads in the truth samples above now.

```{python, eval=FALSE}
files = ['kraken2_chocophlan_combined.csv', 'kraken2_combined_GTDB.csv', 'kraken2_GTDBr202_RefSeqV205_NCBI_taxid_combined.csv', 'kraken2_minikraken_combined.csv', 'kraken2_refseqV93_combined.csv', 'kraken2_refseqV205_100GB_combined.csv', 'kraken2_refseqV205_500GB_combined.csv', 'kraken2_refseqV205_combined.csv', 'kraken2_refseqV208_nt_combined.csv', 'MetaPhlAn_default_combined.csv', 'MetaPhlAn_reads_bowtie2_combined.csv', 'MetaPhlAn_reads_bowtie2_settings_combined.csv', 'MetaPhlAn_reads_estimated_combined.csv', 'truth.csv']
minimizers = ['kraken2_refseqV205_combined_100000minimizer.csv', 'kraken2_refseqV205_combined_5minimizer.csv',  'kraken2_refseqV205_combined_10minimizer.csv', 'kraken2_refseqV205_combined_100minimizer.csv', 'kraken2_refseqV205_combined_500minimizer.csv', 'kraken2_refseqV205_combined_1000minimizer.csv', 'kraken2_refseqV205_combined_2500minimizer.csv', 'kraken2_refseqV205_combined_5000minimizer.csv', 'kraken2_refseqV205_combined_10000minimizer.csv', 'kraken2_refseqV205_combined_25000minimizer.csv', 'kraken2_refseqV205_combined_50000minimizer.csv', 'kraken2_refseqV205_combined_1minimizer.csv']
humann = ['MetaPhlAn_humann_bowtie2_aligned_combined.csv', 'MetaPhlAn_humann_diamond_aligned_combined.csv']
files = files+minimizers+humann
files = ['kraken2_standard_0521_combined.csv']
# files = ['MetaPhlAn_reads_estimation_settings_combined.csv']
truth = pd.read_csv(direc_db+'truth.csv')
truth_samples = list(truth.columns)
with open(direc_db+'merged_remove_10Nov21.list', 'rb') as f:
    taxid_merged, taxid_remove = pickle.load(f)
taxid_remove = [str(rem) for rem in taxid_remove]

for db in files:#db_file+['truth.csv']:
  #if db != 'kraken2_chocophlan_combined.csv': continue
  this_df = pd.read_csv(direc_db+db, index_col=0, header=0).fillna(value=0)
  dropping = []
  if 'minimizer' in db: #if this was one of the minimizer ones, only keep the 0 confidence threshold samples
    for col in this_df.columns: 
      if '0.00' not in col: dropping.append(col)
  this_df = this_df.drop(dropping, axis=1) #drop these
  this_df.index = this_df.index.map(str) #convert taxonomy ID indexes to strings
  this_df = this_df.rename(index=taxid_merged) #rename if they were in the merged file
  dropping = [rem for rem in taxid_remove if rem in this_df.index.values] #drop those that are in the removing list
  this_df = this_df.drop(dropping, axis=0) #drop them
  this_df = this_df.groupby(by=this_df.index, axis=0).sum() #group all remaining indexes
  if 'MetaPhlAn' in db: #if it is one of the MetaPhlAn files, rename the samples based on how MetaPhlAn was run
    rename_meta = {}
    for col in this_df.columns:
      if db == 'MetaPhlAn_default_combined.csv': rename_meta[col] = col.split('-')[1]+'-'+col.split('-')[0]+'-default'
      elif db == 'MetaPhlAn_reads_bowtie2_combined.csv': rename_meta[col] = col+'-MetaPhlAn-bowtie2_reads'
      elif db == 'MetaPhlAn_reads_estimated_combined.csv': rename_meta[col] = col.split('-')[1]+'-'+col.split('-')[0]+'-estimated_reads'
      elif db == 'MetaPhlAn_reads_bowtie2_settings_combined.csv': rename_meta[col] = col.split('-')[1]+'-'+col.split('-')[0]+'-'+col.split('-')[2]
      elif db == 'MetaPhlAn_humann_bowtie2_aligned_combined.csv': rename_meta[col] = col+'-MetaPhlAn-humann_bowtie2'
      elif  db == 'MetaPhlAn_humann_diamond_aligned_combined.csv': rename_meta[col] = col+'-MetaPhlAn-humann_diamond'
    this_df = this_df.rename(columns=rename_meta)
  
  this_df.index = this_df.index.map(str)
  dropping = [] #drop the samples that aren't in our truth file
  for col in this_df.columns: 
    if col.split('-')[0] not in truth_samples:
      dropping.append(col)
  this_df = this_df.drop(dropping, axis=1)
  
  all_tax_ids = [] #now a final check to only keep taxonomy ID's that were in the file we used to make the tree
  for row in open(direc_db+'all_taxid_with_parents_10Nov21.txt', 'r'):
    all_tax_ids.append(row.replace('\n', ''))
  all_tax_ids = set(all_tax_ids)
  dropping = []
  for tax in this_df.index.values:
    if tax not in all_tax_ids:
      dropping.append(tax)
  this_df = this_df.drop(dropping, axis=0)
  
  this_df.to_csv(direc_db+db.replace('.csv', '_rename.csv').replace('_NCBI_taxid', '')) #save the file
```

Combine the minimizer dataframes:
```{python, eval=FALSE}
minimizers = ['kraken2_refseqV205_combined_100000minimizer.csv', 'kraken2_refseqV205_combined_5minimizer.csv',  'kraken2_refseqV205_combined_10minimizer.csv', 'kraken2_refseqV205_combined_100minimizer.csv', 'kraken2_refseqV205_combined_500minimizer.csv', 'kraken2_refseqV205_combined_1000minimizer.csv', 'kraken2_refseqV205_combined_2500minimizer.csv', 'kraken2_refseqV205_combined_5000minimizer.csv', 'kraken2_refseqV205_combined_10000minimizer.csv', 'kraken2_refseqV205_combined_25000minimizer.csv', 'kraken2_refseqV205_combined_50000minimizer.csv', 'kraken2_refseqV205_combined_1minimizer.csv']

dfs = []
for mini in minimizers:
  this_mini = pd.read_csv(direc_db+mini.replace('.csv', '_rename.csv'), index_col=0, header=0)
  rename = {}
  for col in this_mini.columns:
    rename[col] = col.replace('kraken2_refseqV205', 'kraken2_refseqV205_minimizers').replace('0.00', mini.split('_')[3].replace('.csv', ''))
  this_mini = this_mini.rename(columns=rename)
  dfs.append(this_mini)

all_minimizers = pd.concat(dfs).fillna(value=0)
all_minimizers = all_minimizers.groupby(by=all_minimizers.index, axis=0).sum()
all_minimizers.to_csv(direc_db+'kraken2_refseqV205_minimizers_combined_rename.csv')
```

Convert metaphlan default to number of reads (multiply relative abundances by number of reads in truth samples):
```{python, eval=FALSE}
truth = pd.read_csv(direc_db+'truth_rename.csv', index_col=0, header=0)

metaphlan = pd.read_csv(direc_db+'MetaPhlAn_default_combined_rename.csv', index_col=0, header=0)

for col in metaphlan.columns:
    num_reads = sum(truth.loc[:, col.split('-')[0]].values)
    metaphlan[col] = metaphlan[col].apply(lambda x: (x/100)*num_reads)

metaphlan = metaphlan.astype(int)
metaphlan.to_csv(direc_db+'MetaPhlAn_default_convert_reads_combined_rename.csv')
```

Make a file with RefSeq V205 confidence = 0 filtered to only include taxa that are classified with higher confidence thresholds (do this separately for each sample):
```{python, eval=FALSE}
samples = list(pd.read_csv(direc_db+'truth_rename.csv', index_col=0, header=0).columns)
confidence = ['0.00', '0.05', '0.10', '0.15', '0.20', '0.25', '0.30', '0.35', '0.40', '0.45', '0.50', '0.55', '0.60', '0.65', '0.70', '0.75', '0.80', '0.85', '0.90', '0.95', '1.00']
refseq_V205 = pd.read_csv(direc_db+'kraken2_refseqV205_combined_rename.csv', index_col=0, header=0)
new_samples = []
print(refseq_V205.shape[0], refseq_V205.shape[1])

new_df = []
for sample in samples:
  this_samples = []
  try:
    zero_conf = pd.DataFrame(refseq_V205.loc[:, sample+'-kraken2_refseqV205-0.00'])
  except:
    continue
  for conf in confidence[1:]:
    try:
      other_sample = pd.DataFrame(refseq_V205.loc[:, sample+'-kraken2_refseqV205-'+conf])
      other_sample = other_sample[other_sample.max(axis=1) > 0]
      this_samples.append(zero_conf.loc[other_sample.index.values, :].rename(columns={sample+'-kraken2_refseqV205-0.00':sample+'-kraken2_refseqV205-0.00_filtered_'+conf}))
    except:
      do_nothing = True

  all_samples = pd.concat(this_samples).fillna(value=0)
  all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum()
  if sample == samples[0]: print(all_samples)
  if isinstance(new_df, list):
    new_df = all_samples
  else:
    new_df = pd.concat([new_df, all_samples]).fillna(value=0)
    new_df = new_df.groupby(by=new_df.index, axis=0).sum()

new_df.to_csv(direc_db+'kraken2_refseqV205_confidence_filtering_taxa_combined_rename.csv')
```

# Get proportion of taxa covered by database and genomes in databases

## Make lists of genomes in databases

Custom databases get list of genomes included (made from the lists of genomes included I made when constructing the databases):
```{python, eval=FALSE}
lists_folder = direc+'databases/kraken2_database_genomes/'
list_names = ['kraken2_chocophlan_genomes_added.txt', 'kraken2_GTDB_all_genomes.txt', 'kraken2_RefSeqV205_genomes.txt']
genomes_in_databases = []
for ln in list_names:
  this_db = []
  count = 0
  for row in open(lists_folder+ln, 'r'):
      count += 1
      #if count > 10: break
      if '\t' in row:
          this_db.append([row.split('\t')[0], 'Y'])
      else:
          row = row.split('_')
          this_db.append([row[0]+'_'+row[1], 'Y'])
  this_db = pd.DataFrame(this_db, columns = ['Genome', ln.split('.')[0]]).set_index('Genome')
  genomes_in_databases.append(this_db)

genomes_in_databases = pd.concat(genomes_in_databases).fillna(value='')
genomes_in_databases = genomes_in_databases.groupby(by=genomes_in_databases.index, axis=0).sum()
genomes_in_databases.to_csv(lists_folder+'all_genomes_in_databases.csv')
```

Now get the information on these from the assembly summaries:
```{python, eval=FALSE}
assembly_lists = direc+'assembly_lists/'
assembly_files = [f for f in os.listdir(assembly_lists) if 'metadata' in f or 'assembly_summary' in f]

all_assemblies = []
for af in assembly_files:
    if '.tsv' in af:
      this_assembly = pd.read_csv(assembly_lists+af, index_col=0, header=0, sep='\t')
    else:
      this_assembly = pd.read_csv(assembly_lists+af, index_col=0, header=1, sep='\t')
    if '.tsv' in af:
      this_assembly = this_assembly.loc[:, ['gtdb_taxonomy', 'ncbi_species_taxid', 'ncbi_taxid']]
      rename_assembly = {}
      for row in this_assembly.index.values:
        r1 = row.split('_')
        rename_assembly[row] = r1[1]+'_'+r1[2]
      this_assembly = this_assembly.rename(index=rename_assembly, columns={'gtdb_taxonomy':'organism_name', 'ncbi_species_taxid':'species_taxid', 'ncbi_taxid':'taxid'})
    else:
      this_assembly = this_assembly.loc[:, ['organism_name', 'species_taxid', 'taxid']]
    all_assemblies.append(this_assembly)

all_assemblies = pd.concat(all_assemblies)
all_assemblies = all_assemblies.groupby(by=all_assemblies.index, axis=0).first()
all_assemblies.to_csv(assembly_lists+'all_assemblies.csv')
```

Now add this info to the genomes file:
```{python, eval=FALSE}
all_genomes = pd.concat([genomes_in_databases, all_assemblies]).fillna('')
all_genomes = all_genomes.astype(str)
all_genomes = all_genomes.groupby(by=all_genomes.index, axis=0).sum()
all_genomes['taxid'] = all_genomes['taxid'].astype(float).astype(int)
all_genomes['species_taxid'] = all_genomes['species_taxid'].astype(float).astype(int)
all_genomes.to_csv(lists_folder+'all_genomes_with_info.csv')
```

## Get lists of taxonomy ID's

Get lists of sequences and taxonomy ID's:
```{python, eval=FALSE}
#on vulcan
import pandas as pd
databases = ['Kraken2.0.8_Bracken150mer_RefSeqCompleteV93', 'kraken2_chocophlanV30-201901', 'kraken2_GTDBr202_RefSeqV205', 'kraken2_RefSeqV208_nt', 'RefSeqV205_Complete_V2']
direc = '/home/robyn/'

for db in databases:
  seq_map = pd.read_csv(db+'/seqid2taxid.map', header=None, sep='\t')
  ids = set(list(seq_map.iloc[:, 1]))
  with open(direc+db+'_taxid_in_db.txt', 'w') as f:
    for row in ids:
      f.write(str(row)+'\n')
```
Not sure if using the seqid2taxid.map is appropriate here? Is it only sequences that are in the database, or all possible headers? 

We have the database inspection files for the other databases (standard_0521 and minikraken)
Get lists for the inspection files:
```{python, eval=FALSE}
inspect = ['minikraken2_v2_8GB_201904_UPDATE.inspect', 'kraken2_standard.inspect']

for i in inspect:
    taxid = []
    for row in open(direc+'databases/'+i):
      row = row.split('\t')
      if row[3] == 'S':
        taxid.append(row[4])
    
    with open(direc+'databases/'+i.replace('.inspect', '_taxid_in_db.txt'), 'w') as f:
      for tid in taxid: 
        writing = f.write(tid+'\n')
```

## Get the lists of included taxa for checking the taxa/reads included

```{python, results='hide', fig.keep='all', eval=FALSE}
# Calculate for lists:
this_direc = direc+'databases/'
tax_lists = ['kraken2_chocophlanV30-201901_taxid_in_db.txt', 'Kraken2.0.8_Bracken150mer_RefSeqCompleteV93_taxid_in_db.txt', 'RefSeqV205_Complete_V2_taxid_in_db.txt', 'kraken2_RefSeqV208_nt_taxid_in_db.txt']
with open(direc_db+'merged_remove_10Nov21.list', 'rb') as f:
    taxid_merged, taxid_remove = pickle.load(f)
taxid_remove = [str(rem) for rem in taxid_remove]

all_lists = []
for tax_list in tax_lists:
  tlist = list(pd.read_csv(this_direc+tax_list, header=None, sep='\t').loc[:, 0].values)
  for rem in taxid_remove:
    try: tlist.remove(rem)
    except: do_nothing = True
  tlist = set(tlist)
  new_list = []
  count = 0
  for t in tlist:
    if str(t) in taxid_merged:
      new_list.append(taxid_merged[str(t)])
      count += 1
    else:
      new_list.append(str(t))
  all_lists.append(new_list)

# Calculate for inspect:
mini_inspect = pd.read_csv('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/databases/minikraken2_v2_8GB_201904_UPDATE.inspect', header=None, sep='\t')
tax_id = []
for row in mini_inspect.index.values:
  if mini_inspect.loc[row, 3] == 'S': tax_id.append(mini_inspect.loc[row, 4])

tax_id = [str(tax) for tax in set(tax_id)]
for rem in taxid_remove:
  try: tax_id.remove(rem)
  except: do_nothing = True
tax_id = set(tax_id)
new_list = []
count = 0
for t in tax_id:
  if t in taxid_merged:
    new_list.append(taxid_merged[t])
    count += 1
  else:
    new_list.append(t)

all_lists.append(new_list)

standard_inspect = pd.read_csv('/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/databases/kraken2_standard_05-2021.inspect', header=None, sep='\t')
tax_id = []
for row in standard_inspect.index.values:
  if standard_inspect.loc[row, 3] == 'S': tax_id.append(standard_inspect.loc[row, 4])

tax_id = [str(tax) for tax in set(tax_id)]
for rem in taxid_remove:
  try: tax_id.remove(rem)
  except: do_nothing = True
tax_id = set(tax_id)
new_list = []
count = 0
for t in tax_id:
  if t in taxid_merged:
    new_list.append(taxid_merged[t])
    count += 1
  else:
    new_list.append(t)

all_lists.append(new_list)



# Calculate for GTDB:
assembly = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/assembly_lists/'
gtdb = [f for f in os.listdir(assembly) if 'metadata' in f]
refseq = [f for f in os.listdir(assembly) if 'assembly_summary' in f and 'bacteria' not in f and 'archaea' not in f]

tax_id = []
for f in gtdb:
  df = pd.read_csv(assembly+f, index_col=0, header=0, sep='\t')
  ids = list(df.loc[:, 'ncbi_species_taxid'].values)
  tax_id = tax_id+ids

for f in refseq:
  df = pd.read_csv(assembly+f, index_col=0, header=1, sep='\t')
  ids = list(df.loc[:, 'species_taxid'].values)
  tax_id = tax_id+ids

tax_id = [str(tax) for tax in set(tax_id)]
for rem in taxid_remove:
  try: tax_id.remove(rem)
  except: do_nothing = True
tax_id = set(tax_id)
new_list = []
count = 0
for t in tax_id:
  if t in taxid_merged:
    new_list.append(taxid_merged[t])
    count += 1
  else:
    new_list.append(t)
all_lists.append(new_list)
```

Number of taxa in GTDB:
```{python, eval=FALSE}
assembly = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/assembly_lists/'
gtdb = [f for f in os.listdir(assembly) if 'metadata' in f]
refseq = [f for f in os.listdir(assembly) if 'assembly_summary' in f and 'bacteria' not in f and 'archaea' not in f]

tax_id = []
for f in gtdb:
  df = pd.read_csv(assembly+f, index_col=0, header=0, sep='\t')
  ids = list(df.loc[:, 'ncbi_species_taxid'].values)
  tax_id = tax_id+ids

for f in refseq:
  df = pd.read_csv(assembly+f, index_col=0, header=1, sep='\t')
  ids = list(df.loc[:, 'species_taxid'].values)
  tax_id = tax_id+ids

print(len(list(set(tax_id))))
```

```{python, eval=FALSE}
# Calculate truth:
truth = pd.read_csv(direc_db+'truth_rename.csv', index_col=0, header=0)
truth.index = truth.index.map(str)
db_names = ['kraken2_chocophlan', 'kraken2_refseqV93', 'kraken2_refseqV205', 'kraken2_refseqV208_nt', 'kraken2_minikraken', 'kraken2_standard_0521', 'kraken2_GTDBr202RefSeqV205']

all_samples_taxa, all_samples_reads = [], []

for sample in truth.columns:
  this_df = pd.DataFrame(truth.loc[:, sample])
  this_df = this_df[this_df.max(axis=1) > 0]
  total_reads = this_df.loc[:, sample].sum()
  this_sample = list(this_df.index.values)
  one_sample_taxa = [sample]
  one_sample_reads = [sample]
  if len(this_sample) == 0: continue
  for d in range(len(all_lists)):
    db = set(all_lists[d])
    count = 0
    id_in_db = []
    for tid in this_sample:
      if tid in db:
        count += 1
        id_in_db.append(tid)
    proportion = count/len(this_sample)
    reads_covered = this_df.loc[id_in_db, sample].sum()
    prop_reads = reads_covered/total_reads
    one_sample_taxa.append(proportion)
    one_sample_reads.append(prop_reads)
  all_samples_taxa.append(one_sample_taxa)
  all_samples_reads.append(one_sample_reads)
all_samples_taxa = pd.DataFrame(all_samples_taxa, columns=['Sample']+db_names).set_index('Sample')
all_samples_taxa.to_csv(this_direc+'truth_proportion_taxa_covered.csv')

all_samples_reads = pd.DataFrame(all_samples_reads, columns=['Sample']+db_names).set_index('Sample')
all_samples_reads.to_csv(this_direc+'truth_proportion_reads_covered.csv')
```

# Calculate all metrics

Unfortunately multiprocessing doesn't work in R so this needs to be set to false if run here (not really recommended because there are thousands of samples to calculate these metrics for). I ran it as a standalone python script.

```{python, eval=FALSE}
import pandas as pd
import os
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from sklearn.metrics import precision_recall_fscore_support
from skbio import read
from skbio.tree import TreeNode
from skbio.stats.composition import clr
from deicode.preprocessing import rclr
import numpy as np
from scipy.spatial import distance
from sklearn.metrics import auc
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

using_multiprocessing = True
n_proc=40

direc = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/'
direc_db = direc+'database_classifications/'
direc_save = direc+'analysis/calculations/'
direc_temp = direc+'temporary/'
db_files = ['kraken2_chocophlan_combined_rename.csv', 'kraken2_GTDBr202RefSeqV205_combined_rename.csv', 'kraken2_minikraken_combined_rename.csv', 'kraken2_refseqV93_combined_rename.csv', 'kraken2_refseqV205_100GB_combined_rename.csv', 'kraken2_refseqV205_500GB_combined_rename.csv', 'kraken2_refseqV205_combined_rename.csv', 'kraken2_refseqV205_minimizers_combined_rename.csv', 'kraken2_refseqV208_nt_combined_rename.csv', 'kraken2_standard_0521_combined_rename.csv',  'MetaPhlAn_default_convert_reads_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_settings_combined_rename.csv', 'MetaPhlAn_reads_estimated_combined_rename.csv', 'MetaPhlAn_reads_estimation_settings_combined_rename.csv']

truth = pd.read_csv(direc_db+'truth_rename_reads.csv', index_col=0, header=0)
truth.index = truth.index.map(str)
samples = list(truth.columns)
tree = read(direc_db+"phyloT_renamed_rooted_10Nov21_internals.txt", format="newick", into=TreeNode)

metrics = {'Proportion classified':['proportion_classified', 'basic'],
            'Precision reads':['precision_reads', 'basic'], 
            'Precision taxa':['precision_taxa', 'basic'], 
            'Recall reads':['recall_reads', 'basic'], 
            'Recall taxa':['recall_taxa', 'basic'], 
            'F1 score reads':['f1_score_reads', 'basic'], 
            'F1 score taxa':['f1_score_taxa', 'basic'], 
            'L1 distance':['l1_distance', 'beta', 'cityblock', 'none'],
            'Aitchisons distance':['aitchisons_distance', 'beta', 'euclidean', 'clr'], 
            'Robust Aitchisons distance':['robust_aitchisons_distance', 'beta', 'euclidean', 'rclr'],
            'Weighted unifrac distance raw':['weighted_unifrac_distance_raw', 'beta', 'weighted_unifrac', 'none'],
            'Weighted unifrac distance relative abundance':['weighted_unifrac_distance_ra', 'beta', 'weighted_unifrac', 'ra'],
            'Unweighted unifrac distance raw':['unweighted_unifrac_distance_raw', 'beta', 'unweighted_unifrac', 'none'],
            'Unweighted unifrac distance relative abundance':['unweighted_unifrac_distance_ra', 'beta', 'unweighted_unifrac', 'ra'],
            'Bray-Curtis dissimilarity raw':['bray_curtis_dissimilarity_raw', 'beta', 'braycurtis', 'none'],
            'Bray-Curtis dissimilarity relative abundance':['bray_curtis_dissimilarity_ra', 'beta', 'braycurtis', 'ra'],
            "Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            "Faith's phylogenetic diversity":['faiths_diversity', 'alpha', 'faith_pd'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e']}

#for each of these metrics, the first value is what to call the file name, the second is the type of measure (basic, alpha, beta), third is the name within the alpha/beta diversity functions, and fourth is the type of normalisation to perform prior to calculations
#print(get_beta_diversity_metrics())
#print(get_alpha_diversity_metrics())

def append_text(fn, sn, text):
    with open(direc_save+fn+'.txt', 'a') as f:
        f.write(sn+'\t'+str(text)+'\n')
    return

def new_file(fn, cn1, cn2):
    with open(direc_save+fn+'.txt', 'w') as f:
        f.write(cn1+'\t'+cn2+'\n')
    return

def calc_aupr(sample_df):
    sn = sample_df.columns[1]
    pc = sample_df.sum(axis=0).values
    #if the number of reads classified is zero, set all of the metrics to be zero and return
    if pc[1] == 0: 
        prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads = 0, 0, 0, 0, 0, 0, 0
        return prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads
    else: prop_classified = pc[1]/pc[0]
    
    #otherwise, loop through the taxa in the truth sample and look at whether the classification is accurate - add 1 to correct taxa if it is, if the number of reads classified is higher than the truth sample then only add the number of reads in the truth sample to the total number of correct reads, otherwise add the number of reads predicted to it
    y_true, y_pred = sample_df.iloc[:, 0].values, sample_df.iloc[:, 1].values
    correct_reads, correct_taxa = 0, 0
    for v in range(len(y_true)):
        if y_true[v] > 0 and y_pred[v] > 0:
            if y_pred[v] >= y_true[v]:
                correct_reads += y_true[v]
            else:
                correct_reads += y_pred[v]
            if y_pred[v] > 0 and y_true[v] > 0: 
                correct_taxa += 1
    
    #calculate precision and recall
    precision_reads = correct_reads/sum(y_pred) #reads correctly classified (true positives) divided by reads correctly classified (true positives) + reads incorrectly classified (false positives), i.e. number of reads classified
    recall_reads = correct_reads/sum(y_true) #reads correctly classified (true positives) divided by reads correctly classified (true positives) + reads not classified (false negatives), i.e. number of reads in truth sample
    if precision_reads == 0 or recall_reads == 0: f1_score_reads = 0
    else: f1_score_reads = 2*((precision_reads*recall_reads)/(precision_reads+recall_reads))
    
    precision_taxa = correct_taxa/sum([1 for y in y_pred if y > 0])
    recall_taxa = correct_taxa/sum([1 for y in y_true if y > 0])
    if precision_taxa == 0 or recall_taxa == 0: f1_score_taxa = 0
    else: f1_score_taxa = 2*((precision_taxa*recall_taxa)/(precision_taxa+recall_taxa))
        
    return prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads


def calc_all(sample_df):
    sn = list(sample_df.columns)[1]
    if len(sample_df.index) == 1:
        for metric in metrics:
            append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, 0)
        return
    sample_df.to_csv(direc_temp+sn+'.csv')
    fn = 'calculations/'+sn.split('-')[1]
    # if '2401' in sample_df.index.values: print(True)
    # else: print(False)
    calculated_aupr = False
    for metric in metrics:
        sample_df = pd.read_csv(direc_temp+sn+'.csv', index_col=0, header=0)
        sample_df.index = sample_df.index.map(str)
        if metrics[metric][1] == 'alpha':
            if metrics[metric][2] != 'faith_pd':
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values)))[0]
            else:
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values), otu_ids=sample_df.index.values, tree=tree, validate=False))[0]
        elif metrics[metric][1] == 'beta':
            if metrics[metric][3] == 'clr':
                sample_df[sample_df == 0] = 1
                for col in sample_df.columns:
                    sample_df.loc[:, col] = clr(sample_df.loc[:, col].values)
                X = sample_df.transpose().iloc[0:].values
            elif metrics[metric][3] == 'rclr':
                X = sample_df.iloc[0:].values
                rclr_sample = rclr(X)
                rclr_sample = pd.DataFrame(rclr_sample, columns=sample_df.columns, index=sample_df.index.values).fillna(value=0)
                X = rclr_sample.transpose().iloc[0:].values
            elif metrics[metric][3] == 'ra':
                sample_df = sample_df.divide(sample_df.sum(axis=0), axis=1).multiply(100)
                X = sample_df.transpose().iloc[0:].values
            else:
                X = sample_df.transpose().iloc[0:].values
                
            if 'unifrac' not in metric:
                similarities = np.nan_to_num(distance.cdist(X, X, metrics[metric][2])) 
            else:
                sample_df.index = sample_df.index.map(str)
                similarities = beta_diversity(metrics[metric][2], X, sample_df.columns, tree=tree, otu_ids=sample_df.index.values, validate=False)
            val = similarities[0][1]
        else:
            if not calculated_aupr:
                prop_classified, precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads = calc_aupr(sample_df)
                list_vals = [prop_classified, precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads]
                metric_names = ['Proportion classified', 'Precision taxa', 'Recall taxa', 'F1 score taxa', 'Precision reads', 'Recall reads', 'F1 score reads']
                for a in range(len(list_vals)):
                    append_text(sn.split('-')[1]+'_'+metrics[metric_names[a]][0], sn, list_vals[a])
                calculated_aupr = True
                continue
            else:
                continue
        append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, val)
    os.remove(direc_temp+sn+'.csv')
    return
    

for db in db_files:
    print('\n\n\n', db, '\n\n\n')
    db_name = db.replace('_combined_rename.csv', '')
    if 'MetaPhlAn' in db_name: db_name = 'MetaPhlAn'
    for metric in metrics:
        if not os.path.exists(direc_save+db_name+'_'+metrics[metric][0]+'.txt'):
            new_file(db_name+'_'+metrics[metric][0], 'Sample name', metric)
    if not os.path.exists(direc_save+db_name+'_'+metrics[metric][0]+'.txt'):
        new_file(db_name+'_didnt_get', 'Sample name', '')
    db_tests = pd.read_csv(direc_db+db, index_col=0, header=0)
    db_tests.index = db_tests.index.map(str)
    
    all_tax_ids = [] #now a final check to only keep taxonomy ID's that were in the file we used to make the tree
    for row in open(direc_db+'all_taxid_with_parents_10Nov21.txt', 'r'):
        all_tax_ids.append(row.replace('\n', ''))
    all_tax_ids = set(all_tax_ids)
    dropping = []
    for tax in db_tests.index.values:
        if tax not in all_tax_ids:
            dropping.append(tax)
    db_tests = db_tests.drop(dropping, axis=0)
    
    all_running = []
    count_all = 1
    count_samples = 0
    for sample in db_tests.columns:
        count_samples += 1
        truth_sample_df = pd.DataFrame(truth.loc[:, sample.split('-')[0]])
        truth_sample_df = truth_sample_df[truth_sample_df.max(axis=1) > 0]
        test_sample_df = pd.DataFrame(db_tests.loc[:,sample])
        test_sample_df = test_sample_df[test_sample_df.max(axis=1) > 0]
        sample_df = pd.concat([truth_sample_df, test_sample_df]).fillna(value=0)
        sample_df = sample_df.groupby(by=sample_df.index, axis=0).sum()
        all_running.append(sample_df)
        
        if len(all_running) == n_proc or count_samples == len(list(db_tests.columns)):
            print('Getting distances for '+str(n_proc), count_all)
            count_all += 1
            if using_multiprocessing:
                if __name__ == "__main__":
                    manager = Manager()
                    with manager.Pool(processes=n_proc) as pool:
                        pool.map(calc_all, all_running)
            else:
                for df in all_running:
                    calc_all(df)
            all_running = []
    
    all_dfs = []
    for metric in metrics:
        this_metric = pd.read_csv(direc_save+db_name+'_'+metrics[metric][0]+'.txt', index_col=0, header=0, sep='\t')
        all_dfs.append(this_metric)
    
    calculations = pd.concat(all_dfs).fillna(value=0)
    calculations = calculations.groupby(by=calculations.index, axis=0).sum()
    calculations['Mean F1 score'] = calculations.loc[:, ['F1 score taxa', 'F1 score reads']].mean(axis=1)
    calculations.to_csv(direc+'analysis/'+db_name+'_calculations.csv')
```

Calculate alpha diversity of truth samples:
```{python, eval=FALSE}
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from skbio import read
from skbio.tree import TreeNode

direc = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/'
truth = pd.read_csv(direc_db+'truth_rename.csv', index_col=0, header=0)
truth.index = truth.index.map(str)
tree = read(direc_db+"phyloT_renamed_rooted_10Nov21_internals.txt", format="newick", into=TreeNode)

metrics = {"Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            "Faith's phylogenetic diversity":['faiths_diversity', 'alpha', 'faith_pd'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e']}

all_calculations = []
for sample in truth.columns:
    calculations = []
    for metric in metrics:
      if metrics[metric][2] != 'faith_pd':
        val = list(alpha_diversity(metrics[metric][2], list(truth.loc[:, sample].values)))[0]
      else:
        val = list(alpha_diversity(metrics[metric][2], list(truth.loc[:, sample].values), otu_ids=truth.index.values, tree=tree, validate=False))[0]
      calculations.append(val)
    all_calculations.append(calculations)

calcs = pd.DataFrame(all_calculations, columns=[metric for metric in metrics], index=truth.columns).fillna(value=0)
calcs.to_csv(direc+'analysis/truth_calculations.csv')
print(calcs)
```

# Get times for all runs

```{python, eval=FALSE}
import os
import pandas as pd

folders = os.listdir('times_all/')
for folder in folders:
  if folder != 'standard': continue
  files = os.listdir('times_all/'+folder)
  all_files = []
  for f in files:
    user_time, system_time, wall_time, max_mem, threads, cpu = '', '', '', '', '', ''
    for row in open('times_all/'+folder+'/'+f, 'r'):
      if 'User time' in row: 
        user_time = row.replace('\n', '').split(': ')[1]
        continue
      elif 'System time' in row:
        system_time = row.replace('\n', '').split(': ')[1]
        continue
      elif 'Elapsed (wall clock)' in row: 
        wall_time = row.replace('\n', '').split(': ')[1]
        continue
      elif 'Maximum resident set size' in row:
        max_mem = row.replace('\n', '').split(': ')[1]
        continue
      elif '--threads' in row:
        threads = row.replace('\n', '').split('--threads')[1]
        if '--' in threads: threads = threads.split('--')[0]
      elif '--nproc' in row:
        threads = row.replace('\n', '').split('--nproc')[1]
        if '--' in threads: threads = threads.split('--')[0]
      elif 'Percent of CPU' in row:
        cpu = row.replace('\n', '').split(': ')[1]
        continue
    all_files.append([f.replace('.txt', ''), user_time, system_time, wall_time, max_mem, threads, cpu])
  
  summary = pd.DataFrame(all_files, columns=['File name', 'User time (s)', 'System time (s)', 'Wall time (h:mm:ss or m:ss)', 'Maximum set size (kb)', 'Threads', 'CPU (%)'])
  summary = summary.set_index('File name')
  summary.to_csv('times_all/'+folder+'_time.csv')
        
```

# Split samples

I did this manually, removing the samples from the truth file that were proportions rather than number of reads as there were only a few (it's indicated in the sample information sheet which sample is which). So now I have truth_rename_proportions.csv and truth_rename_reads.csv. The samples in the reads file are exactly as have already been used for the calculations above, and I don't need to do anything with these. See below for conversion back into proportions. 

# Convert Kraken2 samples into proportions with genome lengths

So I will get only the samples from Kraken2 RefSeqV205 Complete and only the ones that are in proportions in the initial input. Then I'll divide the reads for each taxa in the Kraken2 classifications by the average genome length for that taxon ID, convert to proportions, and compare the outputs with MetaPhlAn 3 default relative abundance.

## Get the truth samples

I'm actually just going to manually take all of the samples truth values because there are only a few of them anyway. 
They are also all already in the tree, so no need to worry about this.

```{python, eval=FALSE}
sample_names = ['ZymoMock', 'BioPool', 'HMP_even_illum_SRR172902', 'HMP_even_454_SRR072233', 'ABRF_MGRG_10ng', 'ABRF_MGRG_classIplus', 'ABRF_MGRG_5ng', 'ABRF_MGRG_1ng', 'ABRF_MGRG_Half', 'ABRF_MGRG_Normal', 'JGI_SRR033549', 'JGI_SRR033548']
truth_props = pd.read_csv(direc+'truth_sets/proportions/proportions.csv', index_col=0, header=0)
truth_props = truth_props.divide(truth_props.sum(axis=0), axis=1).multiply(100)
truth_props = truth_props.groupby(by=truth_props.index, axis=0).sum()
truth_props.to_csv(direc_db+'truth_proportions.csv')
```

## Get the RefSeq V205 samples

```{python, eval=FALSE}
direc_props = direc+'analysis/proportions/'
truth_props = pd.read_csv(direc_db+'truth_proportions.csv', header=0, index_col=0)
samples_props = list(truth_props.columns)
refseq_v205 = pd.read_csv(direc_db+'kraken2_refseqV205_combined_rename.csv', header=0, index_col=0)
keeping = []
for sample in refseq_v205.columns:
  if sample.split('-')[0] in samples_props:
    keeping.append(sample)

refseq_props = refseq_v205.loc[:, keeping]
refseq_props = refseq_props[refseq_props.max(axis=1) > 0]
refseq_props.to_csv(direc_db+'kraken2_refseqV205_proportions_reads_combined_rename.csv')
```

## Now get the genome sizes for all of these samples

Get the taxid to genome accession:
```{python, eval=FALSE}
assembly_lists = ['archaea_assembly_summary.txt', 'bacteria_assembly_summary.txt', 'fungi_assembly_summary.txt', 'invertebrate_assembly_summary.txt', 'plant_assembly_summary.txt', 'protozoa_assembly_summary.txt', 'vertebrate_mammalian_assembly_summary.txt', 'vertebrate_other_assembly_summary.txt', 'viral_assembly_summary.txt']

taxid_to_accession = {}
for assembly in assembly_lists:
  assembly = pd.read_csv(direc+'assembly_lists/'+assembly, index_col=0, header=1, sep='\t')
  for row in assembly.index.values:
    taxid = assembly.loc[row, 'species_taxid']
    taxid = str(taxid)
    if taxid in taxid_to_accession:
      taxid_to_accession[taxid] = taxid_to_accession[taxid]+[row]
    else:
      taxid_to_accession[taxid] = [row]
```

Now go through and get genome sizes:
```{python, eval=FALSE}
refseq_props = pd.read_csv(direc_db+'kraken2_refseqV205_proportions_reads_combined_rename.csv', index_col=0, header=0)
genome_sizes = pd.read_csv(direc+'genome_sizes/expected_genome_size.csv', index_col=0, header=0)
actual_sizes = pd.read_csv(direc+'genome_sizes/actual_genome_size.csv', index_col=2, header=0)
genome_sizes.index = genome_sizes.index.map(str)
refseq_props.index = refseq_props.index.map(str)

rename_genome = {}
count = 0
for genome in actual_sizes.index.values:
  try:
    rename_genome[genome] = genome.split('.')[0]
  except:
    count += 1
    if count < 100:
      print(genome)
actual_sizes = actual_sizes.rename(index=rename_genome)

no_length = []
lengths = {}
#count = 0
for index in refseq_props.index:
  #count += 1
  #if count > 100: break
  need_to_check = False
  if index in genome_sizes.index:
    try:
      this_length = list(genome_sizes.loc[index, 'expected_ungapped_length'].values)[0]
    except:
      this_length = genome_sizes.loc[index, 'expected_ungapped_length']
    lengths[index] = this_length/1000000
    if np.isnan(this_length):
      need_to_check = True
  else:
    need_to_check = True
  
  if need_to_check:
    try:
        genomes = taxid_to_accession[index]
        genomes = [genome.split('.')[0] for genome in genomes]
        sizes = []
        for genome in genomes:
          if genome in actual_sizes.index:
            sizes.append(actual_sizes.loc[genome, 'Size(Mb)'])
          elif genome.replace('GCF', 'GCA') in actual_sizes.index:
            sizes.append(actual_sizes.loc[genome.replace('GCF', 'GCA'), 'Size(Mb)'])
        if len(sizes) == 1:
          lengths[index] = sizes[0]
        elif len(sizes) > 1:
          lengths[index] = np.median(sizes)
        elif len(sizes) == 0:
          no_length.append(index)
    except:
      no_length.append(index)
      do_nothing = True

print(len(no_length), len(lengths), refseq_props.shape[0])
```


Check which taxonomy ID's are actually not in the length list and get the scientific names for all taxonomy ID's:
```{python, eval=FALSE}
real_no_length = []
for index in no_length:
  if index not in lengths: real_no_length.append(index)

not_in_accession = []
for index in real_no_length:
  if index not in taxid_to_accession:
    not_in_accession.append(index)

taxid_to_name = {}
for row in open(direc+'taxonomy/new_taxdump_2021-10-01/names.dmp', 'r'):
  if 'scientific name' in row:
    row = row.replace('\n', '')
    row = row.split('|')
    taxid_to_name[row[0].strip()] = row[1].strip()
```
So 2,793 of the 25,126 taxon ID's in our reads don't have a genome length.

Look at the proportions of reads that don't have a genome length:
```{python, eval=FALSE}
proportions = list(refseq_props.loc[real_no_length, :].sum(axis=0)/refseq_props.sum(axis=0))
print(max(proportions)*100, min(proportions)*100, np.median(proportions)*100)
```
So the maximum amount of the reads without a genome length in a sample is 0.54%, and the median is 0.004%. So probably not a big deal really? I'll go ahead and just use the median genome length for these reads for now.

Get the median length:
```{python, eval=FALSE}
all_lengths = []
for length in lengths:
  if not np.isnan(lengths[length]):
    all_lengths.append(lengths[length])

print(all_lengths[:100])
median_length = np.median(all_lengths)
print(median_length)
```
So the median length is 4.59181 (seems pretty reasonable for most bacteria).

## Normalise the reads to genome length 

Divide the number of reads by genome length and then convert to relative abundance.

```{python, eval=FALSE}
dividing = []
for index in refseq_props.index.values:
  if index in lengths:
    if not np.isnan(lengths[index]):
      dividing.append(lengths[index])
    else:
      dividing.append(median_length)
  else:
    dividing.append(median_length)

refseq_props_relabun = pd.DataFrame(refseq_props)
refseq_props_relabun = refseq_props_relabun.divide(dividing, axis=0)
refseq_props_relabun = refseq_props_relabun.divide(refseq_props_relabun.sum(axis=0), axis=1).multiply(100)
refseq_props_relabun.to_csv(direc_db+'kraken2_refseqV205_proportions_length_normalised_combined_rename.csv')
```

## Also just get the reads in proportions

```{python, eval=FALSE}
refseq_props = pd.read_csv(direc_db+'kraken2_refseqV205_proportions_reads_combined_rename.csv', index_col=0, header=0)
rename = {}
for col in refseq_props:
  rename[col] = col.split('-')[0]+'-'+col.split('-')[1]+'_proportions-'+col.split('-')[2]

refseq_props = refseq_props.rename(columns=rename)
refseq_props = refseq_props.divide(refseq_props.sum(axis=0), axis=1).multiply(100)
refseq_props.to_csv(direc_db+'kraken2_refseqV205_proportions_combined_rename.csv')
```

## Calculate all metrics for these samples

```{python, eval=FALSE}
import pandas as pd
import os
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from sklearn.metrics import precision_recall_fscore_support
from skbio import read
from skbio.tree import TreeNode
from skbio.stats.composition import clr
from deicode.preprocessing import rclr
import numpy as np
from scipy.spatial import distance
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

using_multiprocessing = True
n_proc=10

direc = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/'
direc_db = direc+'database_classifications/'
direc_save = direc+'analysis/proportions/calculations/'
direc_temp = direc+'temporary/'
#db_files = ['kraken2_chocophlan_combined_rename.csv', 'kraken2_GTDBr202RefSeqV205_combined_rename.csv', 'kraken2_minikraken_combined_rename.csv', 'kraken2_refseqV93_combined_rename.csv', 'kraken2_refseqV205_100GB_combined_rename.csv', 'kraken2_refseqV205_500GB_combined_rename.csv', 'kraken2_refseqV205_combined_rename.csv', 'kraken2_refseqV205_minimizers_combined_rename.csv', 'kraken2_refseqV208_nt_combined_rename.csv', 'MetaPhlAn_default_convert_reads_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_settings_combined_rename.csv', 'MetaPhlAn_reads_estimated_combined_rename.csv']
#db_files = ['kraken2_GTDBr202RefSeqV205_combined_rename.csv', 'kraken2_minikraken_combined_rename.csv', 'kraken2_refseqV93_combined_rename.csv', 'kraken2_refseqV205_100GB_combined_rename.csv', 'kraken2_refseqV205_500GB_combined_rename.csv', 'kraken2_refseqV205_combined_rename.csv', 'kraken2_refseqV205_minimizers_combined_rename.csv', 'kraken2_refseqV208_nt_combined_rename.csv', 'MetaPhlAn_default_convert_reads_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_settings_combined_rename.csv', 'MetaPhlAn_reads_estimated_combined_rename.csv', 'kraken2_refseqV205_confidence_filtering_taxa_combined_rename.csv']
#db_files = ['MetaPhlAn_default_convert_reads_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_combined_rename.csv', 'MetaPhlAn_reads_bowtie2_settings_combined_rename.csv', 'MetaPhlAn_reads_estimated_combined_rename.csv']
#db_files = ['MetaPhlAn_reads_estimation_settings_combined_rename.csv']
#db_files = ['MetaPhlAn_humann_diamond_aligned_combined_rename.csv', 'MetaPhlAn_humann_bowtie2_aligned_combined_rename.csv']
db_files = ['MetaPhlAn_default_combined_rename.csv', 'kraken2_refseqV205_proportions_length_normalised_combined_rename.csv']
truth = pd.read_csv(direc_db+'truth_proportions.csv', index_col=0, header=0)
truth.index = truth.index.map(str)
samples = list(truth.columns)
tree = read(direc_db+"phyloT_renamed_rooted_10Nov21_internals.txt", format="newick", into=TreeNode)

metrics = {'Proportion classified':['proportion_classified', 'basic'],
            'Precision taxa':['precision_taxa', 'basic'], 
            'Recall taxa':['recall_taxa', 'basic'], 
            'F1 score taxa':['f1_score_taxa', 'basic'], 
            'L1 distance':['l1_distance', 'beta', 'cityblock', 'none'],
            'Aitchisons distance':['aitchisons_distance', 'beta', 'euclidean', 'clr'], 
            'Robust Aitchisons distance':['robust_aitchisons_distance', 'beta', 'euclidean', 'rclr'],
            'Weighted unifrac distance relative abundance':['weighted_unifrac_distance_ra', 'beta', 'weighted_unifrac', 'ra'],
            'Unweighted unifrac distance relative abundance':['unweighted_unifrac_distance_ra', 'beta', 'unweighted_unifrac', 'ra'],
            'Bray-Curtis dissimilarity relative abundance':['bray_curtis_dissimilarity_ra', 'beta', 'braycurtis', 'ra'],
            "Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            "Faith's phylogenetic diversity":['faiths_diversity', 'alpha', 'faith_pd'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e']}
#for each of these metrics, the first value is what to call the file name, the second is the type of measure (basic, alpha, beta), third is the name within the alpha/beta diversity functions, and fourth is the type of normalisation to perform prior to calculations
#print(get_beta_diversity_metrics())

def append_text(fn, sn, text):
    with open(direc_save+fn+'.txt', 'a') as f:
        f.write(sn+'\t'+str(text)+'\n')
    return

def new_file(fn, cn1, cn2):
    with open(direc_save+fn+'.txt', 'w') as f:
        f.write(cn1+'\t'+cn2+'\n')
    return

def calc_aupr(sample_df):
    sn = sample_df.columns[1]
    pc = sample_df.sum(axis=0).values
    if pc[1] == 0: 
        prop_classified, precision_taxa, recall_taxa, f1_score_taxa = 0, 0, 0, 0
        return prop_classified, precision_taxa, recall_taxa, f1_score_taxa
    else: prop_classified = pc[1]/pc[0]
    
    # try:
    y_true, y_pred = sample_df.iloc[:, 0].values, sample_df.iloc[:, 1].values
    correct_taxa = 0
    for v in range(len(y_true)):
        if y_true[v] > 0 and y_pred[v] > 0:
            if y_pred[v] > 0 and y_true[v] > 0: 
                correct_taxa += 1
    precision_taxa = correct_taxa/sum([1 for y in y_pred if y > 0])
    recall_taxa = correct_taxa/sum([1 for y in y_true if y > 0])
    if precision_taxa == 0 or recall_taxa == 0: f1_score_taxa = 0
    else: f1_score_taxa = 2*((precision_taxa*recall_taxa)/(precision_taxa+recall_taxa))
        
    # except:
    #     print(sample_df)
    #     precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads = 0, 0, 0, 0, 0, 0

    return prop_classified, precision_taxa, recall_taxa, f1_score_taxa


def calc_all(sample_df):
    sn = list(sample_df.columns)[1]
    if len(sample_df.index) == 1:
        for metric in metrics:
            append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, 0)
        return
    sample_df.to_csv(direc_temp+sn+'.csv')
    fn = 'calculations/'+sn.split('-')[1]
    # if '2401' in sample_df.index.values: print(True)
    # else: print(False)
    calculated_aupr = False
    for metric in metrics:
        sample_df = pd.read_csv(direc_temp+sn+'.csv', index_col=0, header=0)
        sample_df.index = sample_df.index.map(str)
        if metrics[metric][1] == 'alpha':
            if metrics[metric][2] != 'faith_pd':
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values)))[0]
            else:
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values), otu_ids=sample_df.index.values, tree=tree, validate=False))[0]
        elif metrics[metric][1] == 'beta':
            if metrics[metric][3] == 'clr':
                sample_df[sample_df == 0] = 1
                for col in sample_df.columns:
                    sample_df.loc[:, col] = clr(sample_df.loc[:, col].values)
                X = sample_df.transpose().iloc[0:].values
            elif metrics[metric][3] == 'rclr':
                X = sample_df.iloc[0:].values
                rclr_sample = rclr(X)
                rclr_sample = pd.DataFrame(rclr_sample, columns=sample_df.columns, index=sample_df.index.values).fillna(value=0)
                X = rclr_sample.transpose().iloc[0:].values
            elif metrics[metric][3] == 'ra':
                sample_df = sample_df.divide(sample_df.sum(axis=0), axis=1).multiply(100)
                X = sample_df.transpose().iloc[0:].values
            else:
                X = sample_df.transpose().iloc[0:].values
                
            if 'unifrac' not in metric:
                similarities = np.nan_to_num(distance.cdist(X, X, metrics[metric][2])) 
            else:
                sample_df.index = sample_df.index.map(str)
                similarities = beta_diversity(metrics[metric][2], X, sample_df.columns, tree=tree, otu_ids=sample_df.index.values, validate=False)
            val = similarities[0][1]
        else:
            if not calculated_aupr:
                prop_classified, precision, recall, f1_score = calc_aupr(sample_df)
                list_vals = [prop_classified, precision, recall, f1_score]#[prop_classified, precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads]
                metric_names = ['Proportion classified', 'Precision taxa', 'Recall taxa', 'F1 score taxa']#['Proportion classified', 'Precision taxa', 'Recall taxa', 'F1 score taxa', 'Precision reads', 'Recall reads', 'F1 score reads']
                for a in range(len(list_vals)):
                    append_text(sn.split('-')[1]+'_'+metrics[metric_names[a]][0], sn, list_vals[a])
                calculated_aupr = True
                continue
            else:
                continue
        append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, val)
    os.remove(direc_temp+sn+'.csv')
    return
    

for db in db_files:
    #if db != 'kraken2_minikraken_combined_rename.csv': continue
    print('\n\n\n', db, '\n\n\n')
    db_name = db.replace('_combined_rename.csv', '')
    filtered = False
    if 'confidence_filtering' in db_name: 
        db_name = 'kraken2_refseqV205'
        filtered = True
    if 'MetaPhlAn' in db_name: db_name = 'MetaPhlAn'
    for metric in metrics:
        if not os.path.exists(direc_save+db_name+'_'+metrics[metric][0]+'.txt'):
            new_file(db_name+'_'+metrics[metric][0], 'Sample name', metric)
    if not os.path.exists(direc_save+db_name+'_'+metrics[metric][0]+'.txt'):
        new_file(db_name+'_didnt_get', 'Sample name', '')
    db_tests = pd.read_csv(direc_db+db, index_col=0, header=0)
    db_tests.index = db_tests.index.map(str)
    
    all_tax_ids = [] #now a final check to only keep taxonomy ID's that were in the file we used to make the tree
    for row in open(direc_db+'all_taxid_with_parents_10Nov21.txt', 'r'):
        all_tax_ids.append(row.replace('\n', ''))
    all_tax_ids = set(all_tax_ids)
    dropping = []
    for tax in db_tests.index.values:
        if tax not in all_tax_ids:
            dropping.append(tax)
    db_tests = db_tests.drop(dropping, axis=0)
    
    all_running = []
    count_all = 1
    count_samples = 0
    for sample in db_tests.columns:
        #if count_samples > 105: break
        count_samples += 1
        if sample.split('-')[0] in truth.columns: 
            truth_sample_df = pd.DataFrame(truth.loc[:, sample.split('-')[0]])
            truth_sample_df = truth_sample_df[truth_sample_df.max(axis=1) > 0]
            test_sample_df = pd.DataFrame(db_tests.loc[:,sample])
            test_sample_df = test_sample_df[test_sample_df.max(axis=1) > 0]
            sample_df = pd.concat([truth_sample_df, test_sample_df]).fillna(value=0)
            sample_df = sample_df.groupby(by=sample_df.index, axis=0).sum()
            all_running.append(sample_df)
        
        if len(all_running) == n_proc or count_samples == len(list(db_tests.columns)):
            print('Getting distances for '+str(n_proc), count_all)
            count_all += 1
            if using_multiprocessing:
                if __name__ == "__main__":
                    # #freeze_support()   # required to use multiprocessing
                    manager = Manager()
                    with manager.Pool(processes=n_proc) as pool:
                        pool.map(calc_all, all_running)
            else:
                for df in all_running:
                    calc_all(df)
            all_running = []
    
    all_dfs = []
    for metric in metrics:
        this_metric = pd.read_csv(direc_save+db_name+'_'+metrics[metric][0]+'.txt', header=0, sep='\t')
        this_metric = this_metric.drop_duplicates().set_index('Sample name')
        all_dfs.append(this_metric)
    
    calculations = pd.concat(all_dfs).fillna(value=0)
    calculations = calculations.groupby(by=calculations.index, axis=0).sum()
    #calculations['Mean F1 score'] = calculations.loc[:, ['F1 score taxa', 'F1 score reads']].mean(axis=1)
    if filtered: db_name = db_name+'_filtered'
    calculations.to_csv(direc+'analysis/proportions/'+db_name+'_calculations.csv')
```

Calculate alpha diversity of truth samples:
```{python, eval=FALSE}
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from skbio import read
from skbio.tree import TreeNode

direc = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/kraken_confidence_testing_mock/'
truth = pd.read_csv(direc_db+'truth_proportions.csv', index_col=0, header=0)
truth.index = truth.index.map(str)
tree = read(direc_db+"phyloT_renamed_rooted_10Nov21_internals.txt", format="newick", into=TreeNode)

metrics = {"Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            "Faith's phylogenetic diversity":['faiths_diversity', 'alpha', 'faith_pd'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e']}

all_calculations = []
for sample in truth.columns:
    calculations = []
    for metric in metrics:
      if metrics[metric][2] != 'faith_pd':
        val = list(alpha_diversity(metrics[metric][2], list(truth.loc[:, sample].values)))[0]
      else:
        val = list(alpha_diversity(metrics[metric][2], list(truth.loc[:, sample].values), otu_ids=truth.index.values, tree=tree, validate=False))[0]
      calculations.append(val)
    all_calculations.append(calculations)

calcs = pd.DataFrame(all_calculations, columns=[metric for metric in metrics], index=truth.columns).fillna(value=0)
calcs.to_csv(direc+'analysis/proportions/truth_calculations.csv')
print(calcs)
```

# Real world validation

## Combine Kraken classifications

```{python, eval=FALSE}
import os
import pandas as pd

for folder in ['kraken2_bracken_species/', 'kraken2_bracken_genus/']:
  dbs = os.listdir(folder)
  for db in dbs:
    if 'GTDB' not in db: continue
    files = os.listdir(folder+db)
    files = [f for f in files if 'kreport' not in f and '_bracken.bracken' not in f]
    print(folder, db)
    all_all_df = []
    all_df = []
    count = 0
    for fi in files:
      count += 1
      # if count > 2: break
      fn = fi.replace('.fastq', '').replace('.bracken', '').replace('_R1_R2_cat', '').replace('R1.', '').rsplit('.', 2)
      fn = fn[0]+'-'+fn[1]+'.'+fn[2]
      print(folder, db, fn, count)
      this_df = pd.DataFrame(pd.read_csv(folder+db+'/'+fi, index_col=[0,1], header=0, sep='\t').loc[:, 'new_est_reads']).rename(columns={'new_est_reads':fn})
      if isinstance(all_df, list):
        all_df = pd.DataFrame(this_df)
      else:
        all_df = pd.concat([all_df, this_df]).fillna(value=0)
        all_df = all_df.groupby(by=all_df.index, axis=0).sum()
      if all_df.shape[1] > 50:
        if isinstance(all_all_df, list):
          all_all_df = pd.DataFrame(all_df)
        else:
          all_all_df = pd.concat([all_all_df, all_df]).fillna(value=0)
          all_all_df = all_all_df.groupby(by=all_all_df.index, axis=0).sum()
          all_df = []
          print(all_all_df)
    all_all_df = pd.concat([all_all_df, all_df]).fillna(value=0)
    all_all_df = all_all_df.groupby(by=all_all_df.index, axis=0).sum()
    all_all_df.to_csv('summary/'+folder.replace('/', '')+db.replace('/', '')+'.csv')
```

## Combine MetaPhlAn classifications

```{python, eval=FALSE}
import os
import pandas as pd

folder = 'metaphlan_out/'
files = os.listdir(folder)
all_df_species, all_df_genus = [], []
count = 0
for fi in files:
  #if count > 2: break
  fn = fi.replace('.fastq', '').replace('.txt', '').replace('_R1_R2_cat', '').replace('R1.', '')
  print(fn, count)
  this_df = pd.read_csv(folder+fi, index_col=0, header=4, sep='\t')
  keeping_species, keeping_genus = [], []
  rename_species, rename_genus = {}, {}
  for row in this_df.index.values:
    new_row = row.split('|')
    if 's__' in new_row[-1]: 
      keeping_species.append(row)
      rename_species[row] = new_row[-1].replace('s__', '').replace('_', ' ').replace('sp ', 'sp. ')
    elif 'g__' in new_row[-1]: 
      keeping_genus.append(row)
      rename_genus[row] = new_row[-1].replace('g__', '')
  
  this_species = pd.DataFrame(this_df.loc[keeping_species, :].rename(index=rename_species))
  this_genus = pd.DataFrame(this_df.loc[keeping_genus, :].rename(index=rename_genus))
  
  for row in this_species.index.values:
    this_species.loc[row, 'clade_taxid'] = this_species.loc[row, 'clade_taxid'].split('|')[-1]
  
  for row in this_genus.index.values:
    this_genus.loc[row, 'clade_taxid'] = this_genus.loc[row, 'clade_taxid'].split('|')[-1]
  
  this_species = pd.DataFrame(this_species.reset_index().set_index(['#clade_name', 'clade_taxid']).loc[:, 'estimated_number_of_reads_from_the_clade']).rename(columns={'estimated_number_of_reads_from_the_clade':fn})
  this_genus = pd.DataFrame(this_genus.reset_index().set_index(['#clade_name', 'clade_taxid']).loc[:, 'estimated_number_of_reads_from_the_clade']).rename(columns={'estimated_number_of_reads_from_the_clade':fn})
  
  if isinstance(all_df_species, list):
    all_df_species = pd.DataFrame(this_species)
  else:
    all_df_species = pd.concat([all_df_species, this_species]).fillna(value=0)
    all_df_species = all_df_species.groupby(by=all_df_species.index, axis=0).sum()
    
  if isinstance(all_df_genus, list):
    all_df_genus = pd.DataFrame(this_genus)
  else:
    all_df_genus = pd.concat([all_df_genus, this_genus]).fillna(value=0)
    all_df_genus = all_df_genus.groupby(by=all_df_genus.index, axis=0).sum()
  
  count += 1

all_df_species.to_csv('MetaPhlAn3_species.csv')
all_df_genus.to_csv('MetaPhlAn3_genus.csv')
```

## Get all parent taxonomy ID's

```{python, eval=FALSE}
import os
import pickle
import pandas as pd

folder = 'kraken2_kreport/'
dbs = os.listdir(folder)
kraken_files = []
for db in dbs:
  files = [f for f in os.listdir(folder+db) if 'bracken' not in f and '0.00' in f and 'GTDB' not in db]
  files = [folder+db+'/'+f for f in files]
  kraken_files = kraken_files+files

kraken_dict_genus, kraken_dict_species = {}, {}
for fi in kraken_files:
  D = ''
  for row in open(fi, 'r'):
    row = row.split('\t')
    if row[3] in ['D', 'G', 'S']:
      if row[3] == 'D': D = row[5].replace('\n', '').strip()
      elif row[3] == 'G': kraken_dict_genus[row[4]] = D
      elif row[3] == 'S': kraken_dict_species[row[4]] = D

meta_folder = 'metaphlan_out/'
meta_files = os.listdir(meta_folder)
metaphlan_dict_genus, metaphlan_dict_species = {}, {}
replacing = {'2':'Bacteria', '2759':'Eukaryota', '10239':'Viruses', '2157':'Archaea'}
for fi in meta_files:
  this_file = pd.read_csv(meta_folder+fi, index_col=0, header=4, sep='\t')
  all_taxid = this_file.loc[:, 'clade_taxid'].values
  for taxid in all_taxid:
    if not isinstance(taxid, str): continue
    taxid = taxid.split('|')
    if len(taxid) == 7:
      metaphlan_dict_species[taxid[-1]] = replacing[taxid[0]]
    elif len(taxid) == 6:
      metaphlan_dict_genus[taxid[-1]] = replacing[taxid[0]]

combined_dict_genus = {}
for taxid in kraken_dict_genus:
  combined_dict_genus[taxid] = kraken_dict_genus[taxid]

for taxid in metaphlan_dict_genus:
  combined_dict_genus[taxid] = metaphlan_dict_genus[taxid]

combined_dict_species = {}
for taxid in kraken_dict_species:
  combined_dict_species[taxid] = kraken_dict_species[taxid]
  
for taxid in metaphlan_dict_species:
  combined_dict_species[taxid] = metaphlan_dict_species[taxid]

with open('combined_dict_genus.dict', 'wb') as f:
    pickle.dump(combined_dict_genus, f)

with open('combined_dict_species.dict', 'wb') as f:
    pickle.dump(combined_dict_species, f)
    
folder = 'kraken2_kreport/'
dbs = os.listdir(folder)
kraken_files = []
for db in dbs:
  files = [f for f in os.listdir(folder+db) if 'bracken' not in f and '0.00' in f and 'GTDB' in db]
  files = [folder+db+'/'+f for f in files]
  kraken_files = kraken_files+files

kraken_dict_genus, kraken_dict_species = {}, {}
for fi in kraken_files:
  D = ''
  for row in open(fi, 'r'):
    row = row.split('\t')
    if row[3] in ['D', 'G', 'S']:
      if row[3] == 'D': D = row[5].replace('\n', '').strip()
      elif row[3] == 'G': kraken_dict_genus[row[4]] = D
      elif row[3] == 'S': kraken_dict_species[row[4]] = D

with open('GTDB_dict_genus.dict', 'wb') as f:
    pickle.dump(kraken_dict_genus, f)

with open('GTDB_dict_species.dict', 'wb') as f:
    pickle.dump(kraken_dict_species, f)
```

## Proportion of reads classified

Kraken:
```{python, eval=FALSE}
import os
import pandas as pd

folder = 'kraken2_kreport/'
dbs = os.listdir(folder)
for db in dbs:
  if 'GTDB' not in db: continue
  files = [f for f in os.listdir(folder+db) if 'bracken' not in f]
  all_files = []
  count = 0
  for fi in files:
    count += 1
    #if count > 2: break
    this_file = []
    fn = fi.replace('.fastq', '').replace('.kreport', '').replace('_R1_R2_cat', '').replace('R1.', '').rsplit('.', 2)
    fn = fn[0]+'-'+fn[1]+'.'+fn[2]
    for row in open(folder+db+'/'+fi, 'r'):
      row = row.split('\t')
      if row[3] in ['U', 'R', 'D']:
        this_file.append([row[5].strip(), int(row[1])])
    this_file = pd.DataFrame(this_file, columns=['Level', fn]).set_index('Level')
    if isinstance(all_files, list):
      all_files = pd.DataFrame(this_file)
    else:
      all_files = pd.concat([all_files, this_file]).fillna(value=0)
      all_files = all_files.groupby(by=all_files.index, axis=0).sum()
  
  all_files.to_csv('summary/'+db.replace('/', '')+'_reads_classified.csv')
```

MetaPhlAn:
```{python, eval=FALSE}
import os
import pandas as pd

folder = 'metaphlan_out/'
files = os.listdir(folder)
all_files = []
for fi in files:
  fn = fi.replace('.fastq', '').replace('.txt', '').replace('_R1_R2_cat', '').replace('R1.', '')
  this_file = []
  for row in open(folder+fi, 'r'):
    row = row.replace('\n', '').split('\t')
    if row[0].count('|') == 0:
      if 'k__' in row[0] or 'UNKNOWN' in row[0]:
        if 'k__' in row[0]:
          this_file.append([row[0].split('k__')[-1], int(row[-1])])
        else:
          this_file.append([row[0], int(row[-1])])
      if 'estimated_reads' in row[0]:
        this_file.append(['Estimated mapped reads', int(row[0].split(':')[-1])])
  this_file = pd.DataFrame(this_file, columns=['Level', fn]).set_index('Level')
  if isinstance(all_files, list):
    all_files = pd.DataFrame(this_file)
  else:
    all_files = pd.concat([all_files, this_file]).fillna(value=0)
    all_files = all_files.groupby(by=all_files.index, axis=0).sum()

all_files.to_csv('MetaPhlAn3_reads_classified.csv')
```

```{python, eval=FALSE}
folder_16S = direc+'picrust_validation/16S_datasets/'
files = [f for f in os.listdir(folder_16S) if '.tsv' in f and 'species_table' not in f and 'genus_table' not in f]
taxonomy = pd.read_csv(folder_16S+'taxa/taxonomy.tsv', index_col=0, header=0, sep='\t')
feature_table = []

for f in files:
  fn = f.split('_')[0]
  this_file = pd.read_csv(folder_16S+f, index_col=0, header=1, sep='\t')
  sample_rename = {}
  for col in this_file.columns:
    sample_rename[col] = fn+'_'+col
  this_file = this_file.rename(columns=sample_rename)
  if isinstance(feature_table, list):
    feature_table = pd.DataFrame(this_file)
  else:
    feature_table = pd.concat([feature_table, this_file]).fillna(value=0)
    feature_table = feature_table.groupby(by=feature_table.index, axis=0).sum()

tax_ordered = []
for row in feature_table.index.values:
  tax_ordered.append(taxonomy.loc[row, 'Taxon'])

feature_table['Taxonomy'] = tax_ordered
bac_in_ft = []
for row in feature_table.index.values:
  if 'Bacteria' in feature_table.loc[row, 'Taxonomy']:
    bac_in_ft.append(row)

feature_table = feature_table.loc[bac_in_ft, :]
feature_table.to_csv(folder_16S+'asv_table.csv')
# keeping_species, keeping_genus = [], []
# for row in feature_table.index.values:
#   if 's__' in feature_table.loc[row, 'Taxonomy']:
#     keeping_species.append(row)
#   if 'g__' in feature_table.loc[row, 'Taxonomy']:
#     keeping_genus.append(row)


# species_table = pd.DataFrame(feature_table.loc[keeping_species, :])
# genus_table = pd.DataFrame(feature_table.loc[keeping_genus, :])
species_table = pd.DataFrame(feature_table)
genus_table = pd.DataFrame(feature_table)

rename_species, rename_genus = {}, {}
for row in species_table.index.values:
  if 's__' in species_table.loc[row, 'Taxonomy']:
    species = species_table.loc[row, 'Taxonomy'].split('s__')[1].replace('_', ' ')
  else:
    species = species_table.loc[row, 'Taxonomy'].split(';')[-1].replace('_', ' ')
  rename_species[row] = species

for row in genus_table.index.values:
  if 'g__' not in genus_table.loc[row, 'Taxonomy']:
    genus = genus_table.loc[row, 'Taxonomy'].split(';')[-1].replace('_', ' ')
  else:
    genus = genus_table.loc[row, 'Taxonomy'].split('g__')[1]
    if 's__' in genus: genus = genus.split(';')[0]
    genus = genus.replace('_', ' ')
  rename_genus[row] = genus

species_table = species_table.rename(index=rename_species).drop('Taxonomy', axis=1)
genus_table = genus_table.rename(index=rename_genus).drop('Taxonomy', axis=1)

species_table = species_table.groupby(by=species_table.index, axis=0).sum()
genus_table = genus_table.groupby(by=genus_table.index, axis=0).sum()

species_table.to_csv(folder_16S+'species_table.csv')
genus_table.to_csv(folder_16S+'genus_table.csv')
```

Rename samples:
```{python, eval=FALSE}
genus = pd.read_csv(direc+'picrust_validation/16S_datasets/genus_table.csv', index_col=0, header=0)
species = pd.read_csv(direc+'picrust_validation/16S_datasets/species_table.csv', index_col=0, header=0)
asv = pd.read_csv(direc+'picrust_validation/16S_datasets/asv_table.csv', index_col=0, header=0)

cameroon_names = pd.read_csv(direc+'picrust_validation/cameroon_names.txt', index_col=1, header=0, sep='\t')
cameroon_rename = {}
for row in cameroon_names.index.values:
    cameroon_rename[cameroon_names.loc[row, 'sample_title'].replace('Cam2013_', '')] = cameroon_names.loc[row, 'run_accession']

indian_names = pd.read_csv(direc+'picrust_validation/indian_names.txt', index_col=4, header=0, sep='\t')
indian_rename = {}
for row in indian_names.index.values:
    if indian_names.loc[row, 'library_strategy'] != 'WGS': continue
    indian_rename[indian_names.loc[row, 'sample_alias']] = indian_names.loc[row, 'run_accession']

ocean_16S = pd.read_csv(direc+'picrust_validation/ocean_16S.txt', header=0, index_col=0)
ocean_MGS = pd.read_csv(direc+'picrust_validation/ocean_MGS.txt', header=0, index_col=0)
rename_16S, name_16S_to_MGS = {}, {}
MGS_sample_to_acc = {}
for row in ocean_16S.index.values:
    rename_16S[row] = ocean_16S.loc[row, 'Library Name']
for row in ocean_MGS.index.values:
    MGS_sample_to_acc[ocean_MGS.loc[row, 'Sample Name'].split(':')[0]] = row
for sample in rename_16S:
    if rename_16S[sample] in MGS_sample_to_acc:
        name_16S_to_MGS[sample] = MGS_sample_to_acc[rename_16S[sample]]

rename_16S = {}
for row in genus.columns:
    if '11212.' in row:
        rename_16S[row] = row.replace('11212.', '')
    elif 'blueberry' in row:
        rename_16S[row] = row.replace('Bact', 'BB')
    elif 'cameroon' in row:
        try:
            sn = row.split('_')[1]
            rename_16S[row] = row.replace(sn, cameroon_rename[sn])
        except:
            do_nothing = True
    elif 'indian' in row:
        try:
            sn = row.split('_')[1]
            rename_16S[row] = row.replace(sn, indian_rename[sn])
        except:
            do_nothing = True
    elif 'ocean' in row:
        try:
            sn = row.split('_')[1]
            rename_16S[row] = row.replace(sn, name_16S_to_MGS[sn])
        except:
            do_nothing = True
    
genus = genus.rename(columns=rename_16S)
species = species.rename(columns=rename_16S)
asv = asv.rename(columns=rename_16S)
genus.to_csv(direc+'picrust_validation/16S_datasets/genus_table_rename.csv')
species.to_csv(direc+'picrust_validation/16S_datasets/species_table_rename.csv')
asv.to_csv(direc+'picrust_validation/16S_datasets/asv_table_rename.csv')
```

## Get number of species and number of genera

Metagenome:
```{python, eval=FALSE}
files = os.listdir(direc+'picrust_validation/summary/')
files = [f for f in files if 'reads' not in f and '.csv' in f]
genus, species = [], []

count = 0
for fi in files:
  #if count > 0: break
  #if 'species' in fi: continue
  this_file = pd.read_csv(direc+'picrust_validation/summary/'+fi, index_col=0, header=0)
  this_file[this_file > 0] = 1
  if 'genus' in fi:
    rename = {}
    for col in this_file.columns:
      rename[col] = col.replace('.1-00.genus', '-1.00').replace('.0-00.genus', '-0.00').replace('.0-15.genus', '-0.15').replace('.0-50.genus', '-0.50').replace('.0-65.genus', '-0.65').replace('.R1', '')
    this_file = this_file.rename(columns=rename)
  this_file = pd.DataFrame(this_file.sum(axis=0)).transpose().rename(index={0:fi.replace('.csv', '')})
  if 'genus' in fi:
    genus.append(this_file)
  else:
    species.append(this_file)
  count += 1

genus = pd.concat(genus).fillna(value=0)
genus.to_csv(direc+'picrust_validation/analysis/metagenome_number_of_genus.csv')
species = pd.concat(species).fillna(value=0)
species.to_csv(direc+'picrust_validation/analysis/metagenome_number_of_species.csv')
```

16S (and add to same file as metagenome):
```{python, eval=FALSE}
asv = pd.read_csv(direc+'picrust_validation/16S_datasets/asv_table_rename.csv', index_col=0).drop('Taxonomy', axis=1)
genus = pd.read_csv(direc+'picrust_validation/16S_datasets/genus_table_rename.csv', index_col=0)

metagenome_genus = pd.read_csv(direc+'picrust_validation/analysis/metagenome_number_of_genus.csv', index_col=0)
metagenome_species = pd.read_csv(direc+'picrust_validation/analysis/metagenome_number_of_species.csv', index_col=0)

samples = list(metagenome_genus.columns)
samples = [s.split('-')[0] for s in samples]
for s in range(len(samples)):
  if '.' in samples[s]: samples[s] = samples[s].split('.')[0]
samples = list(set(samples))

samples_in_16S = [sample for sample in samples if sample in asv.columns]
sample_not_in_16S = [sample for sample in samples if sample not in asv.columns]
asv = asv.loc[:, samples_in_16S]
genus = genus.loc[:, samples_in_16S]

asv[asv > 0] = 1
genus[genus > 0] = 1

asv = pd.DataFrame(asv.sum(axis=0)).transpose().rename(index={0:'16S'})
genus = pd.DataFrame(genus.sum(axis=0)).transpose().rename(index={0:'16S'})

metagenome_genus = pd.concat([metagenome_genus, genus]).fillna(value=0)
metagenome_species = pd.concat([metagenome_species, asv]).fillna(value=0)
rename_genus, rename_species = {}, {}
for row in metagenome_genus.index.values:
  rename_genus[row] = row.replace('kraken2_bracken_genus_', '').replace('_genus', '')

for row in metagenome_species.index.values:
  rename_species[row] = row.replace('kraken2_bracken_species_', '').replace('kraken2_bracken_species', '').replace('_species', '')

rename_samples = {}
for sample in metagenome_genus.columns:
  if '.R1' in sample: 
    rename_samples[sample] = sample.replace('.R1', '')

metagenome_genus = metagenome_genus.rename(index=rename_genus, columns=rename_samples)
metagenome_species = metagenome_species.rename(index=rename_species, columns=rename_samples)

metagenome_genus.to_csv(direc+'picrust_validation/analysis/metagenome_16S_number_of_genus.csv')
metagenome_species.to_csv(direc+'picrust_validation/analysis/metagenome_16S_number_of_species.csv')
```

## Get proportion of reads classified

```{python, eval=FALSE}
databases = ['minikraken', 'standard', 'chocophlan', 'RefSeqCompleteV205_100GB', 'RefSeqV208_nt', 'RefSeqCompleteV205_500GB', 'GTDB', 'RefSeqCompleteV205', 'MetaPhlAn3']
totals = {}
proportion_classified = []
proportion_bacteria = []

for db in databases:
  this_db = pd.read_csv(direc+'picrust_validation/summary/'+db+'_reads_classified.csv', index_col=0, header=0).transpose()
  rename_sample = {}
  for row in this_db.index.values:
    rename_sample[row] = row.replace('.R1', '')
  this_db = this_db.rename(index=rename_sample)
  if db != 'MetaPhlAn3':
    this_db['Total'] = this_db['root']+this_db['unclassified']
    if db == 'RefSeqCompleteV205':
      for sample in this_db.index.values:
        if '0.00' in sample:
          totals[sample.replace('-0.00', '')] = this_db.loc[sample, 'Total']
    this_db['Proportion classified'] = (this_db['root']/this_db['Total'])*100
    this_db['Proportion bacteria'] = (this_db['Bacteria']/this_db['Total'])*100
    proportion_classified.append(this_db.loc[:, ['Proportion classified']].rename(columns={'Proportion classified':db}).transpose())
    proportion_bacteria.append(this_db.loc[:, ['Proportion bacteria']].rename(columns={'Proportion bacteria':db}).transpose())
  else:
    this_db = this_db.drop(['UNKNOWN'], axis=1)
    this_db['Total'] = ''
    for sample in this_db.index.values:
      this_db.loc[sample, 'Total'] = totals[sample.replace('.R1', '')]
    this_db['Proportion classified'] = (this_db['Estimated mapped reads']/this_db['Total'])*100
    this_db['Proportion bacteria'] = (this_db['Bacteria']/this_db['Total'])*100
    proportion_classified.append(this_db.loc[:, ['Proportion classified']].rename(columns={'Proportion classified':db}).transpose())
    proportion_bacteria.append(this_db.loc[:, ['Proportion bacteria']].rename(columns={'Proportion bacteria':db}).transpose())

proportion_classified = pd.concat(proportion_classified).fillna(value=0)
proportion_classified.to_csv(direc+'picrust_validation/analysis/metagenome_proportion_of_reads_classified.csv')
proportion_bacteria = pd.concat(proportion_bacteria).fillna(value=0)
proportion_bacteria.to_csv(direc+'picrust_validation/analysis/metagenome_proportion_of_reads_classified_bacteria.csv')
```

# Calculate size of genomes for different domains:

```{python, eval=FALSE}
import os
import csv
import pandas as pd

assembly_lists = os.listdir('refseq_assembly_lists/')
genome_folder_old = 'fasta_renamed_RefSeqV205_Complete/'
genome_folder_new = 'refseq_genomes_fasta_renamed/'

for assembly in assembly_lists:
  file = pd.read_csv('refseq_assembly_lists/'+assembly, index_col=0, header=1, sep='\t')
  not_in_folder = []
  for genome in file.index.values:
    file_name = file.loc[genome, 'ftp_path'].split('/')[-1]+'_genomic.tax.fna.gz'
    if file_name in all_genomes:
      move = os.system('sudo mv '+genome_folder_old+file_name+' '+genome_folder_new+assembly.replace('_assembly_summary.txt', '')+'/')
    else:
      not_in_folder.append(file_name)
  with open('/home/robyn/'+assembly.replace('_assembly_summary.txt', 'not_in_folder.txt'), 'w') as f:
    for genome in not_in_folder:
      f.write(genome+'\n')
```

# Get CAMI2 datasets

Get samples:
```{bash, eval=FALSE}
#marine
parallel -j 3 --progress 'wget https://frl.publisso.de/data/frl:6425521/marine/short_read/marmgCAMI2_sample_{1}_reads.tar.gz' ::: {0..10} #done
wget https://frl.publisso.de/data/frl:6425521/marine/short_read/marmgCAMI2_setup.tar.gz #done

#plant associated
parallel -j 3 --progress 'wget https://frl.publisso.de/data/frl:6425521/plant_associated/short_read/rhimgCAMI2_sample_{1}_reads.tar.gz' ::: {1..21} #done
wget https://frl.publisso.de/data/frl:6425521/plant_associated/short_read/rhimgCAMI2_setup.tar.gz #done

#strain
parallel -j 3 --progress 'wget https://frl.publisso.de/data/frl:6425521/strain/short_read/strmgCAMI2_sample_{1}_reads.tar.gz' ::: {0..100} #done
wget https://frl.publisso.de/data/frl:6425521/strain/short_read/strmgCAMI2_setup.tar.gz #done

#mouse gut
parallel -j 3 --progress 'wget https://frl.publisso.de/data/frl:6421672/dataset/2017.12.29_11.37.26_sample_{1}_reads.tar' ::: {0..64} #done
wget https://frl.publisso.de/data/frl:6421672/dataset/CAMISIM_setup.tar.gz #done

#human gut
#data doesn't seem to be there yet?


#taxonomic binnings
#wget https://zenodo.org/record/4982288/files/taxonomic_binning_cami2.tar.gz?download=1 - this seems to be in the setup file for each dataset
```

## Sort samples

Unzip all tar files:
```{bash, eval=FALSE}
#marine
parallel -j 4 --progress 'tar -xvf {1}' ::: *.tar.gz

#plant
parallel -j 3 --progress 'tar -xvf {1}' ::: *

#mouse
parallel -j 3 --progress 'tar -xvf {1}' ::: *.tar

#strain
parallel -j 3 --progress 'tar -xvf {1}' ::: *

#Also moved all of the original tar files to storage (they are not actually any smaller because the files within them are compressed anyway)
```

Marine move samples and rename:
```{python, eval=FALSE}
import os

samples = os.listdir('simulation_short_read/')
samples = [s for s in samples if 'sample_' in s]
for s in samples:
  reads = 'simulation_short_read/'+s+'/reads/anonymous_reads.fq.gz'
  new_name = 'marine_sample'+s.split('_sample')[1]+'.fq.gz'
  os.system('mv '+reads+' '+new_name)
```

Plant move samples and rename:
```{python, eval=FALSE}
import os

samples = os.listdir('simulation_short_read/')
samples = [s for s in samples if 'sample_' in s]
for s in samples:
  reads = 'simulation_short_read/'+s+'/reads/anonymous_reads.fq.gz'
  new_name = 'plant_sample'+s.split('_sample')[1]+'.fq.gz'
  os.system('mv '+reads+' '+new_name)
```

Strain move samples and rename:
```{python, eval=FALSE}
import os

samples = os.listdir('short_read/')
samples = [s for s in samples if 'sample_' in s]
for s in samples:
  reads = 'short_read/'+s+'/reads/anonymous_reads.fq.gz'
  new_name = 'strain_sample'+s.split('_sample')[1]+'.fq.gz'
  os.system('mv '+reads+' '+new_name)
```

Mouse move samples and rename:
```{python, eval=FALSE}
import os

samples = os.listdir('mouse/')
samples = [s for s in samples if 'sample_' in s and 'tar' not in s]
for s in samples:
  reads = 'mouse/'+s+'/reads/anonymous_reads.fq.gz'
  new_name = 'mouse/mouse_sample'+s.split('_sample')[1]+'.fq.gz'
  os.system('mv '+reads+' '+new_name)
```

## Classify samples

### Kraken2

Kraken RefSeq Complete V205:
```{bash, eval=FALSE}
#done
sudo cp -a /home/shared/Kraken2_RefSeqCompleteV205/ /scratch/ramdisk/
mkdir kraken2_outraw
mkdir kraken2_kreport
mkdir kraken2_kreport/RefSeqCompleteV205
mkdir kraken2_outraw/RefSeqCompleteV205
mkdir redo/kraken2_kreport/RefSeqCompleteV205
mkdir redo/kraken2_outraw/RefSeqCompleteV205

parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output kraken2_outraw/RefSeqCompleteV205/{1/.}.kraken --report kraken2_kreport/RefSeqCompleteV205/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/

parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/RefSeqCompleteV205/{1/.}.kraken --report redo/kraken2_kreport/RefSeqCompleteV205/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/

parallel -j 48 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205/*.kreport ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/
mkdir kraken2_bracken_species
mkdir kraken2_bracken_species/RefSeqCompleteV205/
mv kraken2_kreport/RefSeqCompleteV205/*bracken* kraken2_bracken_species/RefSeqCompleteV205/

parallel -j 48 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205/*.kreport ::: /home/shared/Kraken2_RefSeqCompleteV205/
mkdir kraken2_bracken_genus
mkdir kraken2_bracken_genus/RefSeqCompleteV205/
mv kraken2_kreport/RefSeqCompleteV205/*genus.bracken kraken2_bracken_genus/RefSeqCompleteV205/

sudo rm -r /scratch/ramdisk/Kraken2_RefSeqCompleteV205/

```

Kraken RefSeq Complete V205 index runs:
```{bash, eval=FALSE}
#done
sudo cp -a /home/shared/Kraken2_RefSeqCompleteV205/ /scratch/ramdisk/
mkdir index
mkdir index/kraken2_outraw
mkdir index/kraken2_kreport

parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/marine* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/




parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/plant* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/



parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/mouse* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/




parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/strain* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/
```

Kraken RefSeq Complete V205 100 GB:
```{bash, eval=FALSE}
#done
#also saw the error about children - probably just issues with not many reads classified
#redo done
sudo cp -r /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_100GB/ /scratch/ramdisk/
mkdir kraken2_kreport/RefSeqCompleteV205_100GB/
mkdir kraken2_outraw/RefSeqCompleteV205_100GB/
mkdir redo/kraken2_kreport/RefSeqCompleteV205_100GB/
mkdir redo/kraken2_outraw/RefSeqCompleteV205_100GB/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/RefSeqCompleteV205_100GB/{1/.}.kraken --report kraken2_kreport/RefSeqCompleteV205_100GB/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/

parallel -j 1 --progress 'kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/RefSeqCompleteV205_100GB/{1/.}.kraken --report redo/kraken2_kreport/RefSeqCompleteV205_100GB/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/

parallel -j 6 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_100GB/*.kreport ::: /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_100GB/
mkdir kraken2_bracken_species/RefSeqCompleteV205_100GB/
mv kraken2_kreport/RefSeqCompleteV205_100GB/*bracken* kraken2_bracken_species/RefSeqCompleteV205_100GB/

#Run also with redo because there seems to be an issue with the 0 confidence threshold
parallel -j 6 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: redo/kraken2_kreport/RefSeqCompleteV205_100GB/*.kreport ::: /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_100GB/
mv redo/kraken2_kreport/RefSeqCompleteV205_100GB/*bracken* kraken2_bracken_species/RefSeqCompleteV205_100GB/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_100GB/*.kreport ::: /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_100GB/
mkdir kraken2_bracken_genus/RefSeqCompleteV205_100GB/
mv kraken2_kreport/RefSeqCompleteV205_100GB/*genus.bracken kraken2_bracken_genus/RefSeqCompleteV205_100GB/

sudo rm -r /scratch/ramdisk/RefSeqV205_Complete_V2_100GB/
```

Kraken RefSeq Complete V205 500 GB:
```{bash, eval=FALSE}
#done
#redo doing
sudo cp -r /home/storage/robyn/kraken2_databases/RefSeqV205_Complete_V2_500GB/ /scratch/ramdisk/
mkdir kraken2_kreport/RefSeqCompleteV205_500GB/
mkdir kraken2_outraw/RefSeqCompleteV205_500GB/
mkdir redo/kraken2_kreport/RefSeqCompleteV205_500GB/
mkdir redo/kraken2_outraw/RefSeqCompleteV205_500GB/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/RefSeqCompleteV205_500GB/{1/.}.kraken --report kraken2_kreport/RefSeqCompleteV205_500GB/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/

parallel -j 1 --progress 'kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/RefSeqCompleteV205_500GB/{1/.}.kraken --report redo/kraken2_kreport/RefSeqCompleteV205_500GB/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_500GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/
mkdir kraken2_bracken_species/RefSeqCompleteV205_500GB/
mv kraken2_kreport/RefSeqCompleteV205_500GB/*bracken* kraken2_bracken_species/RefSeqCompleteV205_500GB/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqCompleteV205_500GB/*.kreport ::: /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/
mkdir kraken2_bracken_genus/RefSeqCompleteV205_500GB/
mv kraken2_kreport/RefSeqCompleteV205_500GB/*bracken* kraken2_bracken_genus/RefSeqCompleteV205_500GB/

sudo rm -r /scratch/ramdisk/RefSeqV205_Complete_V2_500GB/
```

GTDB r202 + NCBI RefSeq V205:
```{bash, eval=FALSE}
sudo cp -a /home/storage/robyn/kraken2_databases/kraken2_GTDBr202_RefSeqV205/ /scratch/ramdisk/
mkdir kraken2_kreport/GTDBr202RefSeqV205/
mkdir kraken2_outraw/GTDBr202RefSeqV205/
mkdir redo/kraken2_kreport/GTDBr202RefSeqV205/
mkdir redo/kraken2_outraw/GTDBr202RefSeqV205/

parallel -j 2 --progress '/home/robyn/anaconda3/bin/kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output kraken2_outraw/GTDBr202RefSeqV205/{1/.}.kraken --report kraken2_kreport/GTDBr202RefSeqV205/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/

parallel -j 2 --progress '/home/robyn/anaconda3/bin/kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/GTDBr202RefSeqV205/{1/.}.kraken --report redo/kraken2_kreport/GTDBr202RefSeqV205/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/

parallel -j 48 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/GTDBr202RefSeqV205/*.kreport ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/
mkdir kraken2_bracken_species/GTDBr202RefSeqV205/
mv kraken2_kreport/GTDBr202RefSeqV205/*bracken* kraken2_bracken_species/GTDBr202RefSeqV205/

parallel -j 48 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/GTDBr202RefSeqV205/*.kreport ::: /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/
mkdir kraken2_bracken_genus/GTDBr202RefSeqV205/
mv kraken2_kreport/GTDBr202RefSeqV205/*bracken* kraken2_bracken_genus/GTDBr202RefSeqV205/

sudo rm -r /scratch/ramdisk/kraken2_GTDBr202_RefSeqV205/
```

MiniKraken V2:
```{bash, eval=FALSE}
#might be issues with because there was some error often about children
#done
#redo done
sudo cp -a /home/storage/robyn/kraken2_databases/minikraken2_v2_8GB_201904_UPDATE/ /scratch/ramdisk/
mkdir kraken2_kreport/minikraken/
mkdir kraken2_outraw/minikraken/
mkdir redo/kraken2_kreport/minikraken/
mkdir redo/kraken2_outraw/minikraken/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/minikraken/{1/.}.kraken --report kraken2_kreport/minikraken/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0.00 ::: /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/

parallel -j 1 --progress 'kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/minikraken/{1/.}.kraken --report redo/kraken2_kreport/minikraken/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 ::: /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/minikraken/*.kreport ::: /home/storage/robyn/kraken2_databases/minikraken2_v2_8GB_201904_UPDATE/
mkdir kraken2_bracken_species/minikraken/
mv kraken2_kreport/minikraken/*bracken* kraken2_bracken_species/minikraken/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/minikraken/*.kreport ::: /home/storage/robyn/kraken2_databases/minikraken2_v2_8GB_201904_UPDATE/
mkdir kraken2_bracken_genus/minikraken/
mv kraken2_kreport/minikraken/*bracken* kraken2_bracken_genus/minikraken/

sudo rm -r /scratch/ramdisk/minikraken2_v2_8GB_201904_UPDATE/
```

ChocoPhlAn:
```{bash, eval=FALSE}
#done
#redo done
sudo cp -a /home/storage/robyn/kraken2_databases/kraken2_chocophlanV30-201901/ /scratch/ramdisk/
mkdir redo
mkdir redo/kraken2_kreport
mkdir redo/kraken2_outraw
mkdir redo/kraken2_kreport/chocophlan/
mkdir redo/kraken2_outraw/chocophlan/
mkdir kraken2_kreport/chocophlan/
mkdir kraken2_outraw/chocophlan/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/chocophlan/{1/.}.kraken --report redo/kraken2_kreport/chocophlan/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0.00 ::: /scratch/ramdisk/kraken2_chocophlanV30-201901/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/chocophlan/*.kreport ::: /home/storage/robyn/kraken2_databases/kraken2_chocophlanV30-201901/
mkdir kraken2_bracken_species/chocophlan/
mv kraken2_kreport/chocophlan/*bracken* kraken2_bracken_species/chocophlan/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/chocophlan/*.kreport ::: /home/storage/robyn/kraken2_databases/kraken2_chocophlanV30-201901/
mkdir kraken2_bracken_genus/chocophlan/
mv kraken2_kreport/chocophlan/*bracken* kraken2_bracken_genus/chocophlan/

sudo rm -r /scratch/ramdisk/kraken2_chocophlanV30-201901/
```

RefSeq V208 nt:
```{bash, eval=FALSE}
#done
#redo done
sudo cp -a /home/storage/robyn/kraken2_databases/kraken2_RefSeqV208_nt/ /scratch/ramdisk/
mkdir kraken2_kreport/RefSeqV208_nt/
mkdir kraken2_outraw/RefSeqV208_nt/
mkdir redo/kraken2_kreport/RefSeqV208_nt/
mkdir redo/kraken2_outraw/RefSeqV208_nt/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/RefSeqV208_nt/{1/.}.kraken --report kraken2_kreport/RefSeqV208_nt/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0.00 ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/

parallel -j 1 --progress 'kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/RefSeqV208_nt/{1/.}.kraken --report redo/kraken2_kreport/RefSeqV208_nt/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/RefSeqV208_nt/*.kreport ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/
mkdir kraken2_bracken_species/RefSeqV208_nt/
mv kraken2_kreport/RefSeqV208_nt/*bracken* kraken2_bracken_species/RefSeqV208_nt/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/RefSeqV208_nt/*.kreport ::: /scratch/ramdisk/kraken2_RefSeqV208_nt/
mkdir kraken2_bracken_genus/RefSeqV208_nt/
mv kraken2_kreport/RefSeqV208_nt/*bracken* kraken2_bracken_genus/RefSeqV208_nt/

sudo rm -r /scratch/ramdisk/kraken2_RefSeqV208_nt/
```

Standard:
```{bash, eval=FALSE}
#done
#redo done
sudo cp -a /home/storage/robyn/kraken2_databases/kraken2_standard_0521/ /scratch/ramdisk/
mkdir kraken2_kreport/standard/
mkdir kraken2_outraw/standard/
mkdir redo/kraken2_kreport/standard/
mkdir redo/kraken2_outraw/standard/

parallel -j 2 --progress 'kraken2 --use-names --threads 18 --db {3} --memory-mapping {1} --output kraken2_outraw/standard/{1/.}.kraken --report kraken2_kreport/standard/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 0.00 ::: /scratch/ramdisk/kraken2_standard_0521/

parallel -j 1 --progress 'kraken2 --use-names --threads 12 --db {3} --memory-mapping {1} --output redo/kraken2_outraw/standard/{1/.}.kraken --report redo/kraken2_kreport/standard/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/* ::: 0.00 ::: /scratch/ramdisk/kraken2_standard_0521/

parallel -j 36 'bracken -d {2} -i {1} -l S -o {1.}.bracken -r 150' ::: kraken2_kreport/standard/*.kreport ::: /scratch/ramdisk/kraken2_standard_0521/
mkdir kraken2_bracken_species/standard/
mv kraken2_kreport/standard/*bracken* kraken2_bracken_species/standard/

parallel -j 36 'bracken -d {2} -i {1} -l G -o {1.}.genus.bracken -r 150' ::: kraken2_kreport/standard/*.kreport ::: /scratch/ramdisk/kraken2_standard_0521/
mkdir kraken2_bracken_genus/standard/
mv kraken2_kreport/standard/*bracken* kraken2_bracken_genus/standard/

sudo rm -r /scratch/ramdisk/kraken2_standard_0521/
```

Move raw files to storage:
```{bash, eval=FALSE}
sudo mv kraken2_outraw/chocophlan/ /home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/
sudo mv kraken2_outraw/minikraken/ /home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/
sudo mv kraken2_outraw/RefSeqCompleteV205_100GB/ /home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/
sudo mv kraken2_outraw/standard/ /home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/
```

### MetaPhlAn

```{bash, eval=FALSE}
mkdir metaphlan_out
parallel -j 4 --progress 'metaphlan {} --nproc 12 --input_type fastq --bowtie2db /home/robyn/databases_May2021/metaphlan/ --unknown_estimation -o metaphlan_out/{/.}.txt -t rel_ab_w_read_stats' ::: all_samples/*
```

## CAMI2 truth

So each sample comes with the Otu that each read is from, along with the taxonomic classification of the Otu. There is also a profile given, but if I will be matching whether each read is correctly classified and then I may as well put together the truth set as I want to, too.

Maybe first I will just go through and get a list of all taxonomy and then I can see at what level they each are classified.

### Move truth samples and rename them in the same way as the samples

Marine:
```{python, eval=FALSE}
import os

samples = os.listdir('simulation_short_read/')
samples = [s for s in samples if 'sample_' in s]
for s in samples:
  reads = 'simulation_short_read/'+s+'/reads/reads_mapping.tsv.gz'
  new_name = 'marine_sample'+s.split('_sample')[1]+'.tsv.gz'
  print(reads, new_name)
  os.system('mv '+reads+' '+new_name)
```

Plant move samples and rename:
```{python, eval=FALSE}
import os

samples = os.listdir('simulation_short_read/')
samples = [s for s in samples if 'sample_' in s]
for s in samples:
  reads = 'simulation_short_read/'+s+'/reads/reads_mapping.tsv.gz'
  new_name = 'plant_sample'+s.split('_sample')[1]+'.tsv.gz'
  print(reads, new_name)
  os.system('mv '+reads+' '+new_name)
```

Strain move samples and rename:
```{python, eval=FALSE}
import os

samples = os.listdir('short_read/')
samples = [s for s in samples if 'sample_' in s]
for s in samples:
  reads = 'short_read/'+s+'/reads/reads_mapping.tsv.gz'
  new_name = 'strain_sample'+s.split('_sample')[1]+'.tsv.gz'
  print(reads, new_name)
  os.system('mv '+reads+' '+new_name)
```

Mouse move samples and rename:
```{python, eval=FALSE}
import os

samples = os.listdir('mouse/')
samples = [s for s in samples if 'sample_' in s and 'tar' not in s]
for s in samples:
  reads = 'mouse/'+s+'/reads/reads_mapping.tsv.gz'
  new_name = 'mouse/mouse_sample'+s.split('_sample')[1]+'.tsv.gz'
  print(reads, new_name)
  os.system('mv '+reads+' '+new_name)
```

And then these were just all moved to the same folder.

### Get all taxonomy ID's

Go through samples and get the ID's (I don't think this was really necessary for anything! It should just be done when I'm processing the samples):
```{python, eval=FALSE}
import os
import pandas as pd
import pickle

tax_id = []

files = sorted(os.listdir('truth_samples/'))
count = 0
for f in files:
  #if count > 1: break
  this_file = pd.read_csv('truth_samples/'+f, index_col=0, header=0, sep='\t')
  taxid = list(set(list(this_file.loc[:, 'tax_id'].values)))
  count += 1
  tax_id = list(set(tax_id+taxid))
  print(f, len(tax_id))

with open('all_truth_taxid.list', 'wb') as f:
    pickle.dump(tax_id, f)
```

Get same NCBI taxonomy as used above:
```{bash, eval=FALSE}
wget https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump_archive/new_taxdump_2021-10-01.zip
unzip new_taxdump_2021-10-01.zip
```

Make taxid dictionary and also the merged and deleted taxid's:
```{python, eval=FALSE}
import os
import pickle

taxid_dict = {}

for row in open('taxidlineage.dmp', 'r'):
  row = row.split('\t')
  tid = row[0]
  lineage = row[2].split(' ')
  taxid_dict[tid] = lineage[:-1]

with open('taxidlineage.dict', 'wb') as f:
    pickle.dump(taxid_dict, f)

merged = {}

for row in open('merged.dmp', 'r'):
  row = row.split('\t')
  merged[row[0]] = row[2]

with open('merged.dict', 'wb') as f:
    pickle.dump(merged, f)
    
deleted = []
for row in open('delnodes.dmp', 'r'):
  deleted.append(row.split('\t')[0])
  
with open('deleted.list', 'wb') as f:
    pickle.dump(deleted, f)
```

Previously I only had the GTDB to NCBI conversion for species level. Now I need this for all levels so I think what we'll do is get all of the species (lowest classification), these can be converted to NCBI and then I can get the lineage for each in GTDB and NCBI and convert between the two that way? I copied the gtdb_to_ncbi dictionary from what I'd made previously.
```{python, eval=FALSE}
import pickle

gtdb_all_parent = {}
gtdb_species_lineage = {}
gtdb_species_list = []
gtdb_nodes = '/home/storage/robyn/kraken2_databases/creation/kraken2_GTDBr202_RefSeqV205/taxonomy/nodes.dmp'
count = 0
for row in open(gtdb_nodes, 'r'):
  #count += 1
  #if count > 100: break
  row = row.split('\t')
  gtdb_all_parent[row[0]] = row[2]
  if row[4] == 'strain': gtdb_species_list.append(row[0])

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/gtdb_to_ncbi_taxid.dict', 'rb') as f:
    gtdb_to_ncbi = pickle.load(f)

with open('taxonomy/taxidlineage.dict', 'rb') as f:
    taxidlineage = pickle.load(f)
    
with open('taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)

ncbi_rank = {}
for row in open('/home/robyn/simulated_samples/CAMI2/taxonomy/nodes.dmp', 'r'):
  row = row.split('\t')
  ncbi_rank[row[0]] = row[4]

for sp in gtdb_species_list:
  tax = sp[:]
  this_lineage = []
  while tax != '1':
    this_lineage.append(gtdb_all_parent[tax])
    tax = gtdb_all_parent[tax]
  gtdb_species_lineage[sp] = this_lineage

all_levels_gtdb_to_ncbi = {}
rank_index = {'superkingdom':-2, 'kingdom':-3, 'phylum':-4, 'class':-5, 'order':-6, 'family':-7, 'genus':-8, 'species':-9}
other_ranks = []
best_ranks = [r for r in rank_index]
for sp in gtdb_species_lineage:
  gtdb_lineage = gtdb_species_lineage[sp]
  ncbi_sp = str(gtdb_to_ncbi[int(sp)])
  if ncbi_sp in merged:
    ncbi_sp = merged[ncbi_sp]
  ncbi_lineage = taxidlineage[ncbi_sp]
  lineage_rank = []
  added_lineage = []
  this_lineage = []
  for tid in ncbi_lineage:
    rank = ncbi_rank[tid]
    lineage_rank.append(rank)
  all_ranks = True
  for r in best_ranks:
    if r not in lineage_rank: all_ranks = False
  if all_ranks:
    for tid in ncbi_lineage:
      if ncbi_rank[tid] in rank_index:
        gtdb_equivalent = gtdb_lineage[rank_index[ncbi_rank[tid]]]
        all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
      elif tid == '131567':
        gtdb_equivalent = gtdb_lineage[-1]
        all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
  else:
    clade = 1
    for tid in ncbi_lineage:
      rank = ncbi_rank[tid]
      if -9 in added_lineage: continue
      if tid == '131567':
        gtdb_equivalent = gtdb_lineage[-1]
        all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
        added_lineage.append(-1)
      elif rank in best_ranks:
        gtdb_equivalent = gtdb_lineage[rank_index[rank]]
        all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
        added_lineage.append(rank_index[rank])
      elif rank == 'no rank' or rank == 'clade':
        ind = ncbi_lineage.index(tid)
        if len(added_lineage) > 1:
          if added_lineage[-1] == 'genus' and 'species' not in lineage_rank:
            gtdb_equivalent = gtdb_lineage[rank_index['species']]
            all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
            added_lineage.append(rank_index['species'])
          else:
            if rank != lineage_rank[-1]:
              if lineage_rank[ind+1] in best_ranks and lineage_rank[ind-1] in best_ranks:
                rank_diff = best_ranks.index(lineage_rank[ind+1])-best_ranks.index(lineage_rank[ind-1])
                if rank_diff > 1:
                  for a in range(rank_diff-1):
                    gtdb_equivalent = gtdb_lineage[rank_index[lineage_rank[ind-1]]-(a+1)]
                    all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
                    added_lineage.append(rank_index[lineage_rank[ind-1]]-(a+1))
        else:
          if len(lineage_rank) >= 3:
            if lineage_rank[ind-1] == 'superkingdom' and lineage_rank[ind+1] == 'kingdom':
              continue
            elif len(lineage_rank) > 5:
              work_something_out = True
      elif rank in ['subgenus', 'species subgroup', 'section'] and 'species' not in lineage_rank:
        gtdb_equivalent = gtdb_lineage[rank_index['species']]
        all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
        added_lineage.append(rank_index['species'])
      elif rank == 'subfamily' and 'genus' not in lineage_rank:
        gtdb_equivalent = gtdb_lineage[rank_index['genus']]
        all_levels_gtdb_to_ncbi[gtdb_equivalent] = tid
        added_lineage.append(rank_index['genus'])
      else:
        if rank not in ['species group', 'forma specialis', 'subspecies', 'strain']:
          other_ranks.append(rank)
  all_levels_gtdb_to_ncbi[sp] = ncbi_sp
  for lev in gtdb_lineage:
    if lev not in all_levels_gtdb_to_ncbi:
      #print(lev, gtdb_lineage, ncbi_lineage, lineage_rank, gtdb_lineage.index(lev))
      if 9-gtdb_lineage.index(lev) >= len(ncbi_lineage):
        all_levels_gtdb_to_ncbi[lev] = ncbi_lineage[-1]
      elif lev == gtdb_lineage[0]:
        all_levels_gtdb_to_ncbi[lev] = ncbi_lineage[-1]
      elif len(gtdb_lineage) == len(ncbi_lineage):
        ind = gtdb_lineage.index(lev)+1
        all_levels_gtdb_to_ncbi[lev] = ncbi_lineage[-ind]
      else:
        all_levels_gtdb_to_ncbi[lev] = ncbi_lineage[0] #basically, if I wasn't able to match the taxonomy ID in any of the other ways, then just assign it to the superkingdom

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/gtdb_to_ncbi_taxid_all_levels.dict', 'wb') as f:
    pickle.dump(all_levels_gtdb_to_ncbi, f)
```

### Process samples

Here the idea is to run through the raw output of Kraken2 (the classifications for each read, plus the number of minimizers mapped) and see if the taxonomy ID matches with what it should be in the CAMI2 files.
At the end of this, I want to save a csv of each sample which will have:
Read name / Real taxid / Real OTU name / Kraken taxid / Confidence of Kraken taxid / Classification index / Note (e.g. kraken classified at lower level)
Classification index:
0 = correctly classified
U = unclassified (can assign this maximum value at the end when plotting)
1 = kraken classification was correct at 1 rank higher (e.g. strain classification from CAMI was correct at species level in kraken)
...
7 = kraken classification was correct at 8 ranks higher (e.g. strain classification from CAMI was correct at domain level in kraken)

First go through the kraken2 outraw files and get what we can from there (the taxid and confidence):
```{python, eval=FALSE}
#not used
import os
import pickle
import time
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

with open('taxonomy/taxidlineage.dict', 'rb') as f:
    taxidlineage = pickle.load(f)
    
with open('taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)

folder = '/scratch/robyn/kraken2_outraw/RefSeqCompleteV205_500GB/'
prefix = folder.split('/')[-2]
save_folder = '/scratch/robyn/summary_outraw/'
files = sorted(os.listdir(folder))

def write_row(row):
  with open(save_folder+'temporary_1.kraken', 'a') as f:
    wr = f.write(row)
  return

def get_row(row):
  if row[0] == 'U':
    write_row(row[1]+'\tU\tNA\n')
  else:
    classif = row[2]
    mini = row[4]
    tid = classif.split(' ')[-1].replace(')', '')
    if tid in merged: tid = merged[tid]
    elif tid in deleted: 
      write_row(row[1]+'\tU\tDeleted\n')
      return
    tid_all_lineage = taxidlineage[tid]+[tid]
    tid_all_lineage.reverse()
    mini = mini.split(' ')
    for m in range(len(mini)):
      tid_test = mini[m].split(':')[0]
      if tid_test in merged: mini[m] = mini[m].replace(tid_test, merged[tid_test])
      elif tid_test in deleted: mini[m] = mini[m].replace(tid_test, '0')
    all_confidence = ''
    for taxid in tid_all_lineage:
      if taxid != tid_all_lineage[0]: break
      tid_count = 0
      mini_count = 0
      for m in mini:
        if ':' not in m: continue
        tid_test = m.split(':')[0]
        c = int(m.split(':')[1].replace('\n', ''))
        if tid_test != '0' and tid_test != 'A':
          tid_test_lineage = taxidlineage[tid_test]
        if tid_test == '0' or tid_test == 'A': 
          mini_count += c
        elif tid_test == taxid:
          tid_count += c
          mini_count += c
        elif taxid in tid_test_lineage:
          tid_count += c
          mini_count += c
        else:
          mini_count += c
      confidence = tid_count/mini_count
      all_confidence += taxid+':'+str(round(confidence, 4))+'; '
    write_row(row[1]+'\t'+tid+'\t'+all_confidence+'\n')
  return

for f in files:
  start_time = time.time()
  if f != 'marine_sample_0.kraken': break
  #this_file = []
  print(f)
  new_fn = save_folder+prefix+'_'+f
  if os.path.exists(new_fn):
    print(f+' already exists, please delete if you were wanting to re-run')
    continue
  if os.path.exists(save_folder+'temporary_1.kraken'):
    os.system('rm '+save_folder+'temporary_1.kraken')
    print('Removed the previous '+save_folder+'temporary_1.kraken folder')
  # this_file = []
  # for row in open(folder+f, 'r'):
  #   row = row.split('\t')
  #   this_file.append(row)
  print('Opened file, starting processing')
  print(time.time() - start_time)
  getting_file = []
  count = 0
  for row in this_file:
    getting_file.append(row)
    #if count == 27000: break
    if count % 1000 == 0 or row == this_file[-1]:
      print('Getting the next 1000, total now: '+str(count))
      print(time.time() - start_time)
      if __name__ == "__main__":
        manager = Manager()
        with manager.Pool(processes=12) as pool:
          pm = pool.map(get_row, getting_file)
      break
      getting_file = []
    count += 1
  os.system('mv '+save_folder+'/temporary_1.kraken '+new_fn)
  print(time.time() - start_time)
            
```
Not on scratch, this took 501.8090932369232 for 27001 sequences
On scratch, this took 412.04569911956787 for the same number
So this is on average about 4s per 1000 sequences, which is just too slow. 

Just saving the classification for each read and getting the real classification:
```{python, eval=FALSE}
import os
import time
import pickle
import numpy as np
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/taxidlineage.dict', 'rb') as f:
    taxidlineage = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/gtdb_to_ncbi_taxid_all_levels.dict', 'rb') as f:
    all_levels_gtdb_to_ncbi = pickle.load(f)

def get_single_file(f):
    folder = f.rsplit('/', 1)[0]+'/'
    f = f.rsplit('/', 1)[1]
    prefix = folder.split('/')[-2]
    #try:
    new_fn = save_folder+prefix+'_'+f
    if os.path.exists(new_fn):
      #print(f+' already exists, please delete if you were wanting to re-run')
      return
    start_time = time.time()
    truth_fn = truth_samples+f.replace('.kraken', '.tsv')
    all_index = []
    kraken_higher_level = []
    kraken_wrong_higher = []
    truth_dict = {}
    for row in open(truth_fn, 'r'):
      row = row.split('\t')
      truth_dict[row[0]] = [row[1], row[2]]
    #unique_tax = set([])
    #print(f, time.time()-start_time)
    this_file = []
    total = 0
    count = 0
    for row in open(folder+f, 'r'):
      total += 1
      try:
        #if total % 10000000 == 0: print(f, total, time.time()-start_time)
        row = row.split('\t')
        if len(row) < 3:
          count += 1
          continue
        if row[0] not in ['C', 'U']:
          count += 1
          continue
        if row[1] not in truth_dict:
          count += 1
          continue
        truth = truth_dict[row[1]]
        truth_tid, truth_otu = truth[1], truth[0]
        index = None
        if row[0] == 'U':
          row = row[1]+'\tU'
          index = 'U'
        else:
          tax = row[2].split('taxid ')[1].replace(')', '')
          if 'GTDB' in folder:
            tax = str(all_levels_gtdb_to_ncbi[tax])
          if tax == truth_tid:
            index = 0
          elif tax == '1' or tax == '0':
            index = 'U'
          elif truth_tid == '32644':
            index = 'CAMI U'
          else:
            if tax in merged: 
              tax = merged[tax]
            elif tax in deleted: 
              index = 'NA'
            if truth_tid in merged: 
              truth_tid = merged[truth_tid]
            elif truth_tid in deleted: 
              index = 'NA'
            if index == None:
              kraken_lineage = taxidlineage[tax]
              truth_lineage = taxidlineage[truth_tid]
              if truth_tid in kraken_lineage:
                index = str(0)+'\tkcll'
              else:
                if tax in truth_lineage:
                  t_reverse = truth_lineage[:]
                  t_reverse.reverse()
                  index = str(t_reverse.index(tax)+1)+'\tkchl' #kraken classified at higher level that was this many levels away
                  kraken_higher_level.append(index)
                else:
                  min_index = 0
                  for a in range(min(len(kraken_lineage), len(truth_lineage))):
                    if kraken_lineage[a] == truth_lineage[a]:
                      min_index = truth_lineage[a]
                  t_reverse = truth_lineage[:]
                  t_reverse.reverse()
                  if min_index != 0:
                    index = str(t_reverse.index(min_index)+1)+'\tkw' #kraken wrong, classified correctly at higher level which was this many levels away
                    kraken_wrong_higher.append(index)
          row = row[1]+'\t'+tax
        if index == None: 
          index = 'U'
        else: index = str(index)
        this_file.append(row+'\t'+truth[0]+'\t'+truth[1]+'\t'+index+'\n')
        all_index.append(index)
      except:
        count += 1
    print(f, 'problems with ', count, ' out of ', total, ' reads')
    with open(new_fn, 'w') as f:
      wr = f.write('Sequence ID\tKraken taxid\tCAMI OTU\tCAMI taxid\tIndex\tNotes on index\n')
      for row in this_file:
        wr = f.write(row)
    #krak_high_level = [int(f.split('\t')[0]) if '\t' in f else int(f) for f in kraken_higher_level]
    #krak_wrong_high = [int(f.split('\t')[0]) if '\t' in f else int(f) for f in kraken_wrong_higher]
    #print(np.mean(krak_high_level), np.median(krak_high_level), np.mean(krak_wrong_high), np.median(krak_wrong_high))
    #print(f, time.time()-start_time)
    # except:
    #   print(f, 'Had a problem')
    return

folders = ['/home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/chocophlan/', '/home/robyn/simulated_samples/CAMI2/kraken2_outraw/RefSeqCompleteV205/', '/home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/minikraken/', '/home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/RefSeqCompleteV205_100GB/', '/home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/RefSeqV208_nt/', '/home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/standard/', '/home/robyn/simulated_samples/CAMI2/kraken2_outraw/RefSeqCompleteV205_500GB/','/home/robyn/simulated_samples/CAMI2/kraken2_outraw/GTDBr202RefSeqV205/']
folders = ['/home/robyn/simulated_samples/CAMI2/redo/kraken2_outraw/RefSeqCompleteV205/']
save_folder = '/home/robyn/simulated_samples/CAMI2/redo/summary_outraw/'
truth_samples = '/home/robyn/simulated_samples/CAMI2/truth_samples/'

for fol in folders:
  #this_folder = '/home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/'+fol
  this_folder = fol
  files = sorted(os.listdir(this_folder))
  files = [this_folder+f for f in files]
  print('\n\n'+this_folder)
  # for f in files:
  #   get_single_file(f)
  if __name__ == "__main__":
    manager = Manager()
    with manager.Pool(processes=12) as pool:
      pm = pool.map(get_single_file, files)
```

In this output we have: read name, kraken taxid, otu name, real taxid, index and notes:
- kcll = kraken was correct at the level that CAMI gave, but had classified this to a lower rank.
- kchl = the kraken classification was correct, but the CAMI classification was at a lower rank.
- kw = the kraken classification at the taxonomic rank classified was wrong, but this classification did share a higher level with the correct classification.
- I also changed Kraken classifications that were 0 or 1 (root) to be unclassified and CAMI classifications of 32644 (unidentified) to be unclassified. 
- Taxonomy ID's that have been merged were switched to the new ID and those that have been deleted were removed. 

Generate a summary of these and combine:
This will include: mean and median of index, proportion of reads correctly classified, proportion of reads classified at a lower level by kraken, index of reads that were classified wrong by kraken and index of reads that were classified at a higher level by kraken. We'll also add some info on each taxonomy ID and how well it was classified, for now just as a whole. Maybe I can come back to this if it seems interesting.
```{python, eval=FALSE}
import os
import numpy as np
import pandas as pd
import time
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

databases = {'chocophlan_':'kraken2_chocophlan-', 'minikraken_':'kraken2_minikraken-', 'standard_':'kraken2_standard_0521-', 'RefSeqCompleteV205_':'kraken2_refseqV205-', 'RefSeqCompleteV205_100GB_':'kraken2_refseqV205_100GB-', 'RefSeqCompleteV205_500GB_':'kraken2_refseqV205_500GB-', 'GTDBr202RefSeqV205_':'kraken2_GTDBr202RefSeqV205-', 'RefSeqV208_nt_':'kraken2_refseqV208_nt-'}
folder = 'summary_outraw/'
all_files = os.listdir(folder)

columns = ['Sample', 'Median Index', 'Mean Index', 'Number of reads', 'Number of correctly classified reads', 'Number of reads classified at a lower level by Kraken', 'Number of reads classified at a higher level by Kraken', 'Number of reads classified wrong by Kraken', 'Unclassified reads', 'Median Index of reads classified at a higher level by Kraken', 'Mean Index of reads classified at a higher level by Kraken', 'Median Index of reads classified wrong by Kraken', 'Mean Index of reads classified wrong by Kraken']

def get_file(f):
  start_time = time.time()
  print(f)
  for d in databases:
    if d in f:
      if '100GB' in f and '100GB' not in d: continue
      elif '500GB' in f and '500GB' not in d: continue
      db = d
      break
  new_fn = f.replace(db, databases[db]).replace('.kraken', '')
  new_fn = new_fn.split('-')
  new_fn = new_fn[1]+'-'+new_fn[0]
  if os.path.exists('summary_summary_outraw/'+new_fn+'_pandas.csv'): 
    print('This file already exists: summary_summary_outraw/'+new_fn+'_pandas.csv')
    return
  this_file = pd.read_csv(folder+f, index_col=0, header=0, sep='\t')
  unclassified = list(this_file.loc[:, 'Index'].values).count('U')
  this_file[this_file['Index'] == 'U'] = 9
  this_file[this_file['Index'] == 'CAMI U'] = 0
  this_file.Index = this_file.Index.fillna(value=9)
  this_file.Index = this_file.Index.map(int)
  this_file[this_file['Index'] > 9] = 9
  this_sample = [new_fn, np.median(list(this_file.loc[:, 'Index'].values)), np.mean(list(this_file.loc[:, 'Index'].values)), this_file.shape[0], list(this_file.loc[:, 'Index'].values).count(0), list(this_file.loc[:, 'Notes on index'].values).count('kcll'), list(this_file.loc[:, 'Notes on index'].values).count('kchl'), list(this_file.loc[:, 'Notes on index'].values).count('kw'), unclassified]
  this_file_kchl = pd.DataFrame(this_file)[this_file['Notes on index'] == 'kchl']
  this_sample.append(np.median(list(this_file_kchl.loc[:, 'Index'].values)))
  this_sample.append(np.mean(list(this_file_kchl.loc[:, 'Index'].values)))
  this_file_kw = pd.DataFrame(this_file)[this_file['Notes on index'] == 'kw']
  this_sample.append(np.median(list(this_file_kw.loc[:, 'Index'].values)))
  this_sample.append(np.mean(list(this_file_kw.loc[:, 'Index'].values)))
  this_sample_df = pd.DataFrame(this_sample, index=columns).transpose().set_index('Sample')
  this_sample_df.to_csv('summary_summary_outraw/'+new_fn+'_pandas.csv')
  print(f, time.time()-start_time)
  return

if __name__ == "__main__":
  manager = Manager()
  with manager.Pool(processes=12) as pool:
    pm = pool.map(get_file, all_files)

summary_files = os.listdir('summary_summary_outraw/')
all_files = []
for f in summary_files:
  print(f)
  this_file = pd.read_csv('summary_summary_outraw/'+f, index_col=0, header=0)
  if isinstance(all_files, list):
    all_files = pd.DataFrame(this_file)
  else:
    all_files = pd.concat([all_files, this_file])
    all_files = all_files.groupby(by=all_files.index, axis=0).sum().fillna(value=0)

all_files.to_csv('summary_outraw.csv')
```

### Put together regular truth samples

```{python, eval=FALSE}
import os
import pandas as pd

truth_samples = os.listdir('truth_samples/')
all_samples = []
for f in truth_samples:
  #if f not in ['mouse_sample_0.tsv', 'mouse_sample_1.tsv']: continue
  taxids = []
  for row in open('truth_samples/'+f, 'r'):
    if row[0] != '#':
      taxids.append(row.split('\t')[2])
  unique_taxids = set(taxids)
  taxid_count = {}
  for ut in unique_taxids:
    taxid_count[ut] = taxids.count(ut)
  
  df = pd.DataFrame.from_dict(taxid_count, orient='index', columns=[f.replace('.tsv', '')])
  if isinstance(all_samples, list):
    all_samples = pd.DataFrame(df)
  else:
    all_samples = pd.concat([all_samples, df])
    all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum().fillna(value=0)
```

### Put together regular truth samples from profiles

Move samples:
```{python, eval=FALSE}
import os

folders = ['marine/simulation_short_read/', 'mouse/', 'plant/simulation_short_read/', 'strain_madness/short_read/']
for folder in folders:
  files = os.listdir(folder)
  new_name = folder.split('/')[0]
  for f in files:
    if 'taxonomic_profile' not in f: continue
    this_new_name = new_name+'_sample_'+f.replace('taxonomic_profile_', '')
    mv = os.system('mv '+folder+f+' '+'truth_profiles/'+this_new_name)
```

Put samples together:
```{python, eval=FALSE}
import os
import pandas as pd
import pickle

# reads_in_samples = {}
# files = os.listdir('truth_samples/')
# for f in files:
#   print(f)
#   count = 0
#   for line in open('truth_samples/'+f): count += 1
#   reads_in_samples[f.replace('.tsv', '')] = count-1
# 
# with open('kraken_confidence_testing_mock/database_classifications/reads_in_samples.dict', 'wb') as f:
#     pickle.dump(reads_in_samples, f)

with open('kraken_confidence_testing_mock/database_classifications/reads_in_samples.dict', 'rb') as f:
    reads_in_samples = pickle.load(f)

files = sorted(os.listdir('/home/robyn/simulated_samples/CAMI2/truth_profiles/'))
all_files = []
for f in files:
  print(f)
  #if f != 'marine_sample_0.txt': break
  this_file = []
  sn = f.replace('.txt', '').replace('_madness', '')
  for row in open('/home/robyn/simulated_samples/CAMI2/truth_profiles/'+f, 'r'):
    row = row.split('\t')
    if len(row) > 4:
      if row[1] == 'species':
        this_file.append([row[0], row[4]])
  this_file = pd.DataFrame(this_file, columns=['Taxid', sn]).set_index('Taxid')
  for row in this_file.index.values:
    this_file.loc[row, sn] = float(this_file.loc[row, sn])/100
    if this_file.loc[row, sn] > 0:
      this_file.loc[row, sn] = int(this_file.loc[row, sn]*reads_in_samples[sn])
    
  if isinstance(all_files, list):
    all_files = pd.DataFrame(this_file)
  else:
    all_files = pd.concat([all_files, this_file]).fillna(value=0)
    all_files = all_files.groupby(by=all_files.index, axis=0).sum()

all_files.to_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_profiles_species.csv')
```


## Combine output for all runs

### Kraken combine per sample (RefSeq)

```{python, eval=FALSE}
#obviously some parts of this need editing depending on whether it's genus or species we're putting together
import os
import pandas as pd

direc = '/home/robyn/simulated_samples/CAMI2/'
folders = ['chocophlan/', 'minikraken/', 'RefSeqCompleteV205/', 'RefSeqCompleteV205_100GB/', 'RefSeqCompleteV205_500GB/', 'RefSeqV208_nt/', 'standard/']
folders = ['RefSeqCompleteV205_100GB/']
name = ['kraken2_chocophlan', 'kraken2_minikraken', 'kraken2_refseqV205', 'kraken2_refseqV205_100GB', 'kraken2_refseqV205_500GB', 'kraken2_refseqV208_nt', 'kraken2_standard_0521']
name = ['kraken2_refseqV205_100GB']
save_folder = '/home/robyn/simulated_samples/CAMI2/kraken_combined_species/'

samples = os.listdir(direc+'truth_samples/')
samples = sorted([sample.replace('.tsv', '') for sample in samples])

direc = direc+'kraken2_bracken_species/'

confidence = ['0.00', '0.05', '0.10', '0.15', '0.20', '0.25', '0.30', '0.35', '0.40', '0.45', '0.50', '0.55', '0.60', '0.65', '0.70', '0.75', '0.80', '0.85', '0.90', '0.95', '1.00']

for f in range(len(folders)):
  print(folders[f])
  all_output = os.listdir(direc+folders[f])
  all_output = [out for out in all_output if out.split('.')[-1] == 'bracken']
  for sample in samples:
    print(sample)
    for conf in confidence:
      #if conf != '0.00': continue
      sn = sample+'.'+conf+'.bracken'
      new_sn = sample+'-'+name[f]+'-'+conf
      if sn not in all_output:
        this_sample[new_sn] = 0
        continue
      this_conf = pd.read_csv(direc+folders[f]+sn, sep='\t', header=0, index_col=1)
      this_conf = pd.DataFrame(this_conf.loc[:, 'new_est_reads']).rename(columns={'new_est_reads':new_sn})
      if conf == '0.00':
        this_sample = this_conf
      else:
        this_sample = pd.concat([this_sample, this_conf]).fillna(value=0)
        this_sample = this_sample.groupby(by=this_sample.index, axis=0).sum()
    this_sample.to_csv(save_folder+sample+'-'+name[f]+'_species.csv')
```

### Combine all

```{python, eval=FALSE}
all_files = os.listdir('kraken_combined_species/')

names = ['kraken2_chocophlan', 'kraken2_minikraken', 'kraken2_refseqV205', 'kraken2_refseqV205_100GB', 'kraken2_refseqV205_500GB', 'kraken2_refseqV208_nt', 'kraken2_standard_0521']
names = ['kraken2_refseqV205_100GB']

for name in names:
  df_list = []
  these_dfs = []
  count = 0
  these_files = [f for f in all_files if name in f]
  if name == 'kraken2_refseqV205':
    these_files = [f for f in these_files if 'GB' not in f]
  for f in these_files:
    df_list.append(pd.read_csv('kraken_combined_species/'+f, index_col=0, header=0))
    if len(df_list) > 0:
      print(name, count)
      combined_df = pd.concat(df_list)
      combined_df = combined_df.fillna(value=0)
      combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
      if count%20 == 0:
        these_dfs.append(combined_df)
        df_list = []
      else:
        df_list = [combined_df]
    count += 1
  combined_df = pd.concat(these_dfs+df_list)
  combined_df = combined_df.fillna(value=0)
  combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
  combined_df.to_csv(name+'_combined.csv')
```

### MetaPhlAn

#### Estimated reads

```{python, eval=FALSE}
#needs editing between genus and species
files = os.listdir('metaphlan_out/')
all_samples = []
for file in files:
  if file == '.DS_Store': continue
  profile = pd.read_csv('metaphlan_out/'+file, index_col=0, header=4, sep='\t')
  rows = []
  for row in profile.index.values:
    if 'g__' in row and 's__' not in row:
      taxid = profile.loc[row, 'clade_taxid']
      abundance = profile.loc[row, 'estimated_number_of_reads_from_the_clade']
      taxid = taxid.split('|')[-1]
      rows.append([taxid, abundance])
  this_sample = pd.DataFrame(rows, columns=['Taxid', file.replace('.txt', '')+'-MetaPhlAn'])
  all_samples.append(this_sample.set_index('Taxid'))
all_samples = pd.concat(all_samples).fillna(value=0)
all_samples = all_samples.groupby(by=all_samples.index, axis=0).sum()
all_samples.to_csv('MetaPhlAn_reads_combined_genus.csv')
```

### GTDB-RefSeq

Combine per sample:
```{python, eval=FALSE}
import pandas as pd
import os

direc = '/home/robyn/simulated_samples/CAMI2/'
folders = ['GTDBr202RefSeqV205/']
name = ['kraken2_GTDBr202RefSeqV205']
save_folder = '/home/robyn/simulated_samples/CAMI2/kraken_combined_genus/'

samples = os.listdir(direc+'truth_samples/')
samples = sorted([sample.replace('.tsv', '') for sample in samples])

direc = direc+'kraken2_bracken_genus/'

confidence = ['0.00', '0.05', '0.10', '0.15', '0.20', '0.25', '0.30', '0.35', '0.40', '0.45', '0.50', '0.55', '0.60', '0.65', '0.70', '0.75', '0.80', '0.85', '0.90', '0.95', '1.00']

for f in range(len(folders)):
  print(folders[f])
  all_output = os.listdir(direc+folders[f])
  all_output = [out for out in all_output if out.split('.')[-1] == 'bracken']
  for sample in samples:
    print(sample)
    for conf in confidence:
      #if conf != '0.00': continue
      sn = sample+'.'+conf+'.genus.bracken'
      new_sn = sample+'-'+name[f]+'-'+conf
      if sn not in all_output:
        this_sample[new_sn] = 0
        continue
      this_conf = pd.read_csv(direc+folders[f]+sn, sep='\t', header=0, index_col=1)
      this_conf = pd.DataFrame(this_conf.loc[:, 'new_est_reads']).rename(columns={'new_est_reads':new_sn})
      if conf == '0.00':
        this_sample = this_conf
      else:
        this_sample = pd.concat([this_sample, this_conf]).fillna(value=0)
        this_sample = this_sample.groupby(by=this_sample.index, axis=0).sum()
    this_sample.to_csv(save_folder+sample+'-'+name[f]+'_genus.csv')
```

Combine all:
```{python, eval=FALSE}
all_files = os.listdir('kraken_combined_genus/')
all_files = [f for f in all_files if 'kraken2_GTDBr202RefSeqV205' in f]

df_list = []
count = 0 
for f in all_files:
  df_list.append(pd.read_csv('kraken_combined_genus/'+f, index_col=0, header=0))
  if count == 20:
    print(f)
    combined_df = pd.concat(df_list)
    combined_df = combined_df.fillna(value=0)
    combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
    df_list = [combined_df]
    count = 0
  count += 1

combined_df = pd.concat(df_list)
combined_df = combined_df.fillna(value=0)
combined_df = combined_df.groupby(by=combined_df.index, axis=0).sum()
combined_df.to_csv('kraken2_GTDBr202RefSeqV205_combined_GTDB_taxid_genus.csv')
```

Convert to NCBI taxid:
```{python, eval=FALSE}
import pandas as pd
import pickle

gtdb_df = pd.read_csv('kraken2_GTDBr202RefSeqV205_combined_GTDB_taxid_genus.csv', header=0, index_col=0)

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/gtdb_to_ncbi_taxid_all_levels.dict', 'rb') as f:
    all_levels_gtdb_to_ncbi = pickle.load(f)

rename_dict = {}
for row in gtdb_df.index:
  rename_dict[row] = all_levels_gtdb_to_ncbi[str(row)]

ncbi_df = gtdb_df.rename(index=rename_dict)
ncbi_df = ncbi_df.groupby(by=ncbi_df.index, axis=0).sum()
ncbi_df.to_csv('kraken2_GTDBr202RefSeqV205_combined_genus.csv')
```

## Rename all of the merged and deleted taxonomy ID's within the files

We'll also get rid of the samples that we decided didn't have enough reads in the truth samples above now.

```{python, eval=FALSE}
import os
import pandas as pd
import pickle

files = ['kraken2_standard_0521_combined_genus.csv', 'kraken2_chocophlan_combined_genus.csv', 'kraken2_minikraken_combined_genus.csv', 'kraken2_GTDBr202RefSeqV205_combined_genus.csv', 'kraken2_refseqV205_100GB_combined_genus.csv', 'kraken2_refseqV208_nt_combined_genus.csv', 'MetaPhlAn_reads_combined_genus.csv', 'kraken2_refseqV205_500GB_combined_genus.csv', 'kraken2_refseqV205_combined_genus.csv', 'truth_profiles_species.csv']
files = ['kraken2_refseqV205_100GB_combined.csv']
files = ['truth_profiles_species.csv']

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)

for db in files:
  print(db)
  this_df = pd.read_csv('database_classifications/'+db, index_col=0, header=0).fillna(value=0)
  dropping = []
  this_df.index = this_df.index.map(str) #convert taxonomy ID indexes to strings
  this_df = this_df.rename(index=merged) #rename if they were in the merged file
  dropping = [rem for rem in deleted if rem in this_df.index.values] #drop those that are in the removing list
  this_df = this_df.drop(dropping, axis=0) #drop them
  this_df = this_df.groupby(by=this_df.index, axis=0).sum() #group all remaining indexes
  this_df.to_csv('database_classifications/'+db.replace('.csv', '_rename.csv').replace('_NCBI_taxid', '')) #save the file
```

## Get the truth samples at species and genus levels

No longer needed after realising that the CAMI2 classifications by reads aren't the same as the gold standard profiles.

```{python, eval=FALSE}
import os
import pandas as pd
import pickle
import time

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/taxidlineage.dict', 'rb') as f:
    taxidlineage = pickle.load(f)

#get a dictionary that will give which rank each taxid is
tax_rank = {}
for row in open('/home/robyn/simulated_samples/CAMI2/taxonomy/nodes.dmp', 'r'):
  row = row.split('\t')
  tax_rank[row[0]] = row[4]
  
#only need to do this if it wasn't done previously
# truth = pd.read_csv('database_classifications/truth_samples.csv', index_col=0, header=0)
# truth.index = truth.index.map(str)
# 
# rename_truth = {}
# dropping = []
# for row in truth.index:
#   if row in merged:
#     rename_truth[row] = merged[row]
#   if row in deleted:
#     dropping.append(row)
#  #luckily dropping is empty so we don't need to worry about that, but now I can rename the merged taxonomy ID's
# 
# truth = truth.rename(index=rename_truth)
# truth = truth.groupby(by=truth.index, axis=0).sum()
# truth.to_csv('database_classifications/truth_samples_rename.csv')

truth = pd.read_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_samples_rename.csv', index_col=0, header=0)
truth.index = truth.index.map(str)

not_species = {}
rename_below_species = {}
for row in truth.index:
  if tax_rank[row] == 'species': continue
  lineage = taxidlineage[row]
  below_species = False
  for lin in lineage:
    if tax_rank[lin] == 'species':
      rename_below_species[row] = lin
      below_species = True
  if not below_species:
    not_species[row] = lineage

truth = truth.rename(index=rename_below_species)
truth = truth.groupby(by=truth.index, axis=0).sum()
truth.to_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_samples_species_rename.csv')

rename_below_genus = {}
for row in truth.index:
  if tax_rank[row] == 'genus': 
    continue
  lineage = taxidlineage[row]
  below_genus = False
  for lin in lineage:
    if tax_rank[lin] == 'genus':
      rename_below_genus[row] = lin
      below_genus = True

print(len(rename_below_genus))
truth = truth.rename(index=rename_below_genus)
truth = truth.groupby(by=truth.index, axis=0).sum()
truth.to_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_samples_genus_rename.csv')
```

## Get the lists of included taxa for checking the taxa/reads included

Mainly using the lists that were made previously. But here we need to start looking at how many of the taxid's are not at the species level.

```{python, eval=FALSE}
#this still needs modifying to get the lists
import os
import pandas as pd
import pickle
import time
import numpy as np

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/taxidlineage.dict', 'rb') as f:
    taxidlineage = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/gtdb_to_ncbi_taxid_all_levels.dict', 'rb') as f:
    all_levels_gtdb_to_ncbi = pickle.load(f)

#get a dictionary that will give which rank each taxid is
tax_rank = {}
for row in open('/home/robyn/simulated_samples/CAMI2/taxonomy/nodes.dmp', 'r'):
  row = row.split('\t')
  tax_rank[row[0]] = row[4]

# truth = pd.read_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_samples_rename.csv', index_col=0, header=0)
# truth.index = truth.index.map(str)
# 
# ###genus-level classification
# below_genus_dict = {}
# above_genus_dict = {}
# for row in truth.index:
#   if tax_rank[row] == 'genus': continue
#   lineage = taxidlineage[row]
#   below_genus = False
#   for lin in lineage:
#     if tax_rank[lin] == 'genus':
#       below_genus_dict[row] = lin
#       below_genus = True
#   above_genus = False
#   if not below_genus:
#     above_genus_dict[row] = lineage
# 
# above_genus_set = set([ng for ng in above_genus_dict])
# truth = truth.rename(index=below_genus_dict)
# truth_sum = truth.sum(axis=0)
# truth_not_below_genus = pd.DataFrame(truth).loc[list(above_genus_set), :]
# truth_not_below_genus_sum = truth_not_below_genus.sum(axis=0)
# truth_not_below_genus_prop = pd.DataFrame(truth_not_below_genus_sum/truth_sum).rename(columns={0:'Proportion'})
# truth_not_below_genus_prop.to_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_not_below_genus_proportion.csv')
# 
# not_species = {}
# rename_below_species = {}
# for row in truth.index:
#   if tax_rank[row] == 'species': continue
#   lineage = taxidlineage[row]
#   below_species = False
#   for lin in lineage:
#     if tax_rank[lin] == 'species':
#       rename_below_species[row] = lin
#       below_species = True
#   if not below_species:
#     not_species[row] = lineage
# #so we have 162 of these 989 taxid's that were at a lower level than species and 177 that are above species. The ones that are below species we'll just rename as the species ID, the ones that are lower we'll have to convert the databases to those higher levels to see if they exist (but I'd assume that they will). I guess first I'll look at those ID's and how many reads they equate to.
# 
# not_species_set = set([nsp for nsp in not_species])
# truth = truth.rename(index=rename_below_species)
# truth_sum = truth.sum(axis=0)
# truth_not_below_species = pd.DataFrame(truth).loc[list(not_species_set), :]
# truth_not_below_species_sum = truth_not_below_species.sum(axis=0)
# truth_not_below_species_prop = pd.DataFrame(truth_not_below_species_sum/truth_sum).rename(columns={0:'Proportion'})
# truth_not_below_species_prop.to_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_not_below_species_proportion.csv')

truth_species = pd.read_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_samples_species_rename.csv', index_col=0, header=0)
truth_genus = pd.read_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_samples_genus_rename.csv', index_col=0, header=0)

#if we want to get the taxa that are covered by the database at genus or species level then we need to rewrite this part
db_lists = ['kraken2_chocophlanV30-201901_taxid_in_db.txt','kraken2_GTDBr202_RefSeqV205_taxid_in_db.txt','kraken2_RefSeqV208_nt_taxid_in_db.txt','kraken2_standard_taxid_in_db.txt','minikraken2_v2_8GB_201904_UPDATE_taxid_in_db.txt','RefSeqV205_Complete_V2_taxid_in_db.txt']
db_names = ['kraken2_chocophlan', 'kraken2_GTDBr202RefSeqV205', 'kraken2_refseqV208_nt', 'kraken2_standard_0521', 'kraken2_minikraken', 'kraken2_refseqV205']

genus = True
truth = truth_genus
truth.index = truth.index.map(str)
all_db_taxa, all_db_reads = [], []
for d in range(len(db_lists)):
  #if d != 0: continue
  start_time = time.time()
  #if d > 0: break
  print(db_lists[d])
  all_samples_taxa, all_samples_reads = [], []
  this_list = []
  #all_levels = []
  count = 0
  for row in open('databases/taxid_in_db/'+db_lists[d], 'r'):
    count += 1
    tax = row.replace('\n', '')
    if 'GTDB' in db_lists[d]:
      tax = all_levels_gtdb_to_ncbi[tax]
    #if count % 10000 == 0: print(count, time.time()-start_time)
    if tax in merged: tax = merged[tax]
    elif tax in deleted: continue
    if not genus:
      this_list.append(tax)
    else:
      try:
        lineage = taxidlineage[tax]
        for lin in lineage:
          if tax_rank[lin] == 'genus':
            this_list.append(lin)
            species.append(tax)
            break
      except:
        continue
    # try:
    #   this_list.append(tax)
    #   lineage = taxidlineage[tax]
    #   all_levels = all_levels+lineage
    # except:
    #   continue
  this_list = set(this_list)
  #all_levels = set(all_levels)
  print(len(this_list), count)
  for sample in truth.columns:
    this_df = pd.DataFrame(truth.loc[:, sample])
    this_df = this_df[this_df.max(axis=1) > 0]
    total_reads = this_df.loc[:, sample].sum()
    this_sample = list(this_df.index.values)
    one_sample_taxa = [sample]
    one_sample_reads = [sample]
    count1 = 0
    id_in_db = []
    for tid in this_sample:
      if tid in this_list:
        count1 += 1
        id_in_db.append(tid)
    proportion = count1/len(this_sample)
    reads_covered = this_df.loc[id_in_db, sample].sum()
    prop_reads = reads_covered/total_reads
    one_sample_taxa.append(proportion)
    one_sample_reads.append(prop_reads)
    all_samples_taxa.append(one_sample_taxa)
    all_samples_reads.append(one_sample_reads)
  all_samples_taxa = pd.DataFrame(all_samples_taxa, columns=['Sample']+[db_names[d]]).set_index('Sample')
  all_samples_reads = pd.DataFrame(all_samples_reads, columns=['Sample']+[db_names[d]]).set_index('Sample')
  all_db_taxa.append(all_samples_taxa)
  all_db_reads.append(all_samples_reads)

all_db_taxa = pd.concat(all_db_taxa).fillna(value=0)
all_db_taxa = all_db_taxa.groupby(by=all_db_taxa.index, axis=0).sum()
all_db_taxa.to_csv('databases/CAMI2_truth_proportion_taxa_covered_genus.csv')

all_db_reads = pd.concat(all_db_reads).fillna(value=0)
all_db_reads = all_db_reads.groupby(by=all_db_reads.index, axis=0).sum()
all_db_reads.to_csv('databases/CAMI2_truth_proportion_reads_covered_genus.csv')
```

Redo after realising that the CAMI2 classifications by reads aren't the same as the gold standard profiles.

```{python, eval=FALSE}
#this still needs modifying to get the lists
import os
import pandas as pd
import pickle
import time
import numpy as np

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)

# with open('/home/robyn/simulated_samples/CAMI2/taxonomy/taxidlineage.dict', 'rb') as f:
#     taxidlineage = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/gtdb_to_ncbi_taxid_all_levels.dict', 'rb') as f:
    all_levels_gtdb_to_ncbi = pickle.load(f)

truth = pd.read_csv('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/database_classifications/truth_profiles_species_rename.csv', index_col=0, header=0)
truth.index = truth.index.map(str)

#if we want to get the taxa that are covered by the database at genus or species level then we need to rewrite this part
db_lists = ['kraken2_chocophlanV30-201901_taxid_in_db.txt','kraken2_GTDBr202_RefSeqV205_taxid_in_db.txt','kraken2_RefSeqV208_nt_taxid_in_db.txt','kraken2_standard_taxid_in_db.txt','minikraken2_v2_8GB_201904_UPDATE_taxid_in_db.txt','RefSeqV205_Complete_V2_taxid_in_db.txt']
db_names = ['kraken2_chocophlan', 'kraken2_GTDBr202RefSeqV205', 'kraken2_refseqV208_nt', 'kraken2_standard_0521', 'kraken2_minikraken', 'kraken2_refseqV205']

all_db_taxa, all_db_reads = [], []
list_not_included = []
for d in range(len(db_lists)):
  #if d != 0: continue
  start_time = time.time()
  #if d > 0: break
  print(db_lists[d])
  all_samples_taxa, all_samples_reads = [], []
  this_list = []
  #all_levels = []
  count = 0
  for row in open('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/databases/taxid_in_db/'+db_lists[d], 'r'):
    count += 1
    tax = row.replace('\n', '')
    if 'GTDB' in db_lists[d]:
      tax = all_levels_gtdb_to_ncbi[tax]
    if tax in merged: tax = merged[tax]
    elif tax in deleted: continue
    this_list.append(tax)
  this_list = set(this_list)
  print(len(this_list), count)
  for sample in truth.columns:
    this_df = pd.DataFrame(truth.loc[:, sample])
    this_df = this_df[this_df.max(axis=1) > 0]
    total_reads = this_df.loc[:, sample].sum()
    this_sample = list(this_df.index.values)
    one_sample_taxa = [sample]
    one_sample_reads = [sample]
    count1 = 0
    id_in_db = []
    for tid in this_sample:
      if tid in this_list:
        count1 += 1
        id_in_db.append(tid)
      else:
        list_not_included.append(sample+'; '+db_names[d]+'; '+tid)
    proportion = count1/len(this_sample)
    reads_covered = this_df.loc[id_in_db, sample].sum()
    prop_reads = reads_covered/total_reads
    one_sample_taxa.append(proportion)
    one_sample_reads.append(prop_reads)
    all_samples_taxa.append(one_sample_taxa)
    all_samples_reads.append(one_sample_reads)
  all_samples_taxa = pd.DataFrame(all_samples_taxa, columns=['Sample']+[db_names[d]]).set_index('Sample')
  all_samples_reads = pd.DataFrame(all_samples_reads, columns=['Sample']+[db_names[d]]).set_index('Sample')
  all_db_taxa.append(all_samples_taxa)
  all_db_reads.append(all_samples_reads)

with open('/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/databases/CAMI2_not_in_databases_all.txt', 'w') as f:
  for tax in list_not_included:
    f.write(tax+'\n')

all_db_taxa = pd.concat(all_db_taxa).fillna(value=0)
all_db_taxa = all_db_taxa.groupby(by=all_db_taxa.index, axis=0).sum()
all_db_taxa.to_csv('databases/CAMI2_truth_proportion_taxa_covered_profile.csv')

all_db_reads = pd.concat(all_db_reads).fillna(value=0)
all_db_reads = all_db_reads.groupby(by=all_db_reads.index, axis=0).sum()
all_db_reads.to_csv('databases/CAMI2_truth_proportion_reads_covered_profile.csv')
```

## Calculate all metrics before profile

Unfortunately multiprocessing doesn't work in R so this needs to be set to false if run here (not really recommended because there are thousands of samples to calculate these metrics for). I ran it as a standalone python script.

```{python, eval=FALSE}
import pandas as pd
import os
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from sklearn.metrics import precision_recall_fscore_support
from skbio import read
from skbio.tree import TreeNode
from skbio.stats.composition import clr
from deicode.preprocessing import rclr
import numpy as np
from scipy.spatial import distance
from sklearn.metrics import auc
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

using_multiprocessing = True
n_proc=12

direc = '/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/'
direc_db = direc+'database_classifications/'
direc_save = direc+'analysis/calculations/'
direc_temp = direc+'temporary/'
db_files = ['kraken2_chocophlan_combined_rename.csv', 'kraken2_GTDBr202RefSeqV205_combined_rename.csv', 'kraken2_minikraken_combined_rename.csv', 'kraken2_refseqV205_100GB_combined_rename.csv', 'kraken2_refseqV205_500GB_combined_rename.csv', 'kraken2_refseqV205_combined_rename.csv', 'kraken2_refseqV208_nt_combined_rename.csv', 'kraken2_standard_0521_combined_rename.csv',  'MetaPhlAn_reads_combined_rename.csv']+['kraken2_chocophlan_combined_genus_rename.csv', 'kraken2_GTDBr202RefSeqV205_combined_genus_rename.csv', 'kraken2_minikraken_combined_genus_rename.csv', 'kraken2_refseqV205_100GB_combined_genus_rename.csv', 'kraken2_refseqV205_500GB_combined_genus_rename.csv', 'kraken2_refseqV205_combined_genus_rename.csv', 'kraken2_refseqV208_nt_combined_genus_rename.csv', 'kraken2_standard_0521_combined_genus_rename.csv',  'MetaPhlAn_reads_combined_genus_rename.csv']

truth_genus = pd.read_csv(direc_db+'truth_samples_genus_rename.csv', index_col=0, header=0)
truth_genus.index = truth_genus.index.map(str)
truth_species = pd.read_csv(direc_db+'truth_samples_species_rename.csv', index_col=0, header=0)
truth_species.index = truth_species.index.map(str)
samples = list(truth_genus.columns)

metrics = {'Proportion classified':['proportion_classified', 'basic'],
            'Precision reads':['precision_reads', 'basic'], 
            'Precision taxa':['precision_taxa', 'basic'], 
            'Recall reads':['recall_reads', 'basic'], 
            'Recall taxa':['recall_taxa', 'basic'], 
            'F1 score reads':['f1_score_reads', 'basic'], 
            'F1 score taxa':['f1_score_taxa', 'basic'], 
            'L1 distance':['l1_distance', 'beta', 'cityblock', 'none'],
            'Aitchisons distance':['aitchisons_distance', 'beta', 'euclidean', 'clr'], 
            'Robust Aitchisons distance':['robust_aitchisons_distance', 'beta', 'euclidean', 'rclr'],
            'Bray-Curtis dissimilarity raw':['bray_curtis_dissimilarity_raw', 'beta', 'braycurtis', 'none'],
            'Bray-Curtis dissimilarity relative abundance':['bray_curtis_dissimilarity_ra', 'beta', 'braycurtis', 'ra'],
            "Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e'],
            "Number of taxa":['number_of_taxa', 'alpha', 'observed_otus']}

#for each of these metrics, the first value is what to call the file name, the second is the type of measure (basic, alpha, beta), third is the name within the alpha/beta diversity functions, and fourth is the type of normalisation to perform prior to calculations
#print(get_beta_diversity_metrics())
#print(get_alpha_diversity_metrics())

def append_text(fn, sn, text):
    with open(direc_save+fn+'.txt', 'a') as f:
        f.write(sn+'\t'+str(text)+'\n')
    return

def new_file(fn, cn1, cn2):
    with open(direc_save+fn+'.txt', 'w') as f:
        f.write(cn1+'\t'+cn2+'\n')
    return

def calc_aupr(sample_df):
    sn = sample_df.columns[1]
    pc = sample_df.sum(axis=0).values
    #if the number of reads classified is zero, set all of the metrics to be zero and return
    if pc[1] == 0: 
        prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads = 0, 0, 0, 0, 0, 0, 0
        return prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads
    else: prop_classified = pc[1]/pc[0]
    #otherwise, loop through the taxa in the truth sample and look at whether the classification is accurate - add 1 to correct taxa if it is, if the number of reads classified is higher than the truth sample then only add the number of reads in the truth sample to the total number of correct reads, otherwise add the number of reads predicted to it
    y_true, y_pred = sample_df.iloc[:, 0].values, sample_df.iloc[:, 1].values
    correct_reads, correct_taxa = 0, 0
    for v in range(len(y_true)):
        if y_true[v] > 0 and y_pred[v] > 0:
            if y_pred[v] >= y_true[v]:
                correct_reads += y_true[v]
            else:
                correct_reads += y_pred[v]
            if y_pred[v] > 0 and y_true[v] > 0: 
                correct_taxa += 1
    #calculate precision and recall
    precision_reads = correct_reads/sum(y_pred) #reads correctly classified (true positives) divided by reads correctly classified (true positives) + reads incorrectly classified (false positives), i.e. number of reads classified
    recall_reads = correct_reads/sum(y_true) #reads correctly classified (true positives) divided by reads correctly classified (true positives) + reads not classified (false negatives), i.e. number of reads in truth sample
    if precision_reads == 0 or recall_reads == 0: f1_score_reads = 0
    else: f1_score_reads = 2*((precision_reads*recall_reads)/(precision_reads+recall_reads))
    
    precision_taxa = correct_taxa/sum([1 for y in y_pred if y > 0])
    recall_taxa = correct_taxa/sum([1 for y in y_true if y > 0])
    if precision_taxa == 0 or recall_taxa == 0: f1_score_taxa = 0
    else: f1_score_taxa = 2*((precision_taxa*recall_taxa)/(precision_taxa+recall_taxa))
        
    return prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads


def calc_all(sample_df):
    sn = list(sample_df.columns)[1]
    if len(sample_df.index) == 1:
        for metric in metrics:
            append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, 0)
        return
    sample_df.to_csv(direc_temp+sn+'.csv')
    fn = 'calculations/'+sn.split('-')[1]
    calculated_aupr = False
    for metric in metrics:
        sample_df = pd.read_csv(direc_temp+sn+'.csv', index_col=0, header=0)
        sample_df.index = sample_df.index.map(str)
        if metrics[metric][1] == 'alpha':
            if metrics[metric][2] != 'faith_pd':
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values)))[0]
            else:
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values), otu_ids=sample_df.index.values, tree=tree, validate=False))[0]
        elif metrics[metric][1] == 'beta':
            if metrics[metric][3] == 'clr':
                sample_df[sample_df == 0] = 1
                for col in sample_df.columns:
                    sample_df.loc[:, col] = clr(sample_df.loc[:, col].values)
                X = sample_df.transpose().iloc[0:].values
            elif metrics[metric][3] == 'rclr':
                X = sample_df.iloc[0:].values
                rclr_sample = rclr(X)
                rclr_sample = pd.DataFrame(rclr_sample, columns=sample_df.columns, index=sample_df.index.values).fillna(value=0)
                X = rclr_sample.transpose().iloc[0:].values
            elif metrics[metric][3] == 'ra':
                sample_df = sample_df.divide(sample_df.sum(axis=0), axis=1).multiply(100)
                X = sample_df.transpose().iloc[0:].values
            else:
                X = sample_df.transpose().iloc[0:].values
                
            if 'unifrac' not in metric:
                similarities = np.nan_to_num(distance.cdist(X, X, metrics[metric][2])) 
            else:
                sample_df.index = sample_df.index.map(str)
                similarities = beta_diversity(metrics[metric][2], X, sample_df.columns, tree=tree, otu_ids=sample_df.index.values, validate=False)
            val = similarities[0][1]
        else:
            if not calculated_aupr:
                prop_classified, precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads = calc_aupr(sample_df)
                list_vals = [prop_classified, precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads]
                metric_names = ['Proportion classified', 'Precision taxa', 'Recall taxa', 'F1 score taxa', 'Precision reads', 'Recall reads', 'F1 score reads']
                for a in range(len(list_vals)):
                    append_text(sn.split('-')[1]+'_'+metrics[metric_names[a]][0], sn, list_vals[a])
                calculated_aupr = True
                continue
            else:
                continue
        append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, val)
    os.remove(direc_temp+sn+'.csv')
    return
    

for db in db_files:
    metrics = {"Number of taxa":['number_of_taxa', 'alpha', 'observed_otus']}
    print('\n\n\n', db, '\n\n\n')
    genus = False
    if 'genus' in db: genus = True
    db_name = db.replace('_combined_genus_rename.csv', '').replace('_combined_rename.csv', '')
    if genus:
      if os.path.exists(direc+'analysis/'+db_name+'_calculations_genus.csv'):
        print('Already got this one')
        continue
    elif os.path.exists(direc+'analysis/'+db_name+'_calculations_species.csv'):
      print('Already got this one')
      continue
    for metric in metrics:
      #if not os.path.exists(direc_save+db_name+'_'+metrics[metric][0]+'.txt'):
          new_file(db_name+'_'+metrics[metric][0], 'Sample name', metric)
    db_tests = pd.read_csv(direc_db+db, index_col=0, header=0)
    db_tests.index = db_tests.index.map(str)
    all_running = []
    count_all = 1
    count_samples = 0
    for sample in db_tests.columns:
        count_samples += 1
        if genus:
          truth_sample_df = pd.DataFrame(truth_genus.loc[:, sample.split('-')[0]])
        else:
          truth_sample_df = pd.DataFrame(truth_species.loc[:, sample.split('-')[0]])
        truth_sample_df = truth_sample_df[truth_sample_df.max(axis=1) > 0]
        test_sample_df = pd.DataFrame(db_tests.loc[:,sample])
        test_sample_df = test_sample_df[test_sample_df.max(axis=1) > 0]
        sample_df = pd.concat([truth_sample_df, test_sample_df]).fillna(value=0)
        sample_df = sample_df.groupby(by=sample_df.index, axis=0).sum()
        all_running.append(sample_df)
        if len(all_running) == n_proc or count_samples == len(list(db_tests.columns)):
            print('Getting distances for '+str(n_proc), count_all)
            count_all += 1
            if using_multiprocessing:
                if __name__ == "__main__":
                    manager = Manager()
                    with manager.Pool(processes=n_proc) as pool:
                        pool.map(calc_all, all_running)
            else:
                for df in all_running:
                    calc_all(df)
            all_running = []
    all_dfs = []
    metrics = {'Proportion classified':['proportion_classified', 'basic'],
            'Precision reads':['precision_reads', 'basic'], 
            'Precision taxa':['precision_taxa', 'basic'], 
            'Recall reads':['recall_reads', 'basic'], 
            'Recall taxa':['recall_taxa', 'basic'], 
            'F1 score reads':['f1_score_reads', 'basic'], 
            'F1 score taxa':['f1_score_taxa', 'basic'], 
            'L1 distance':['l1_distance', 'beta', 'cityblock', 'none'],
            'Aitchisons distance':['aitchisons_distance', 'beta', 'euclidean', 'clr'], 
            'Robust Aitchisons distance':['robust_aitchisons_distance', 'beta', 'euclidean', 'rclr'],
            'Bray-Curtis dissimilarity raw':['bray_curtis_dissimilarity_raw', 'beta', 'braycurtis', 'none'],
            'Bray-Curtis dissimilarity relative abundance':['bray_curtis_dissimilarity_ra', 'beta', 'braycurtis', 'ra'],
            "Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e'],
            "Number of taxa":['number_of_taxa', 'alpha', 'observed_otus']}
    for metric in metrics:
        try:
          this_metric = pd.read_csv(direc_save+db_name+'_'+metrics[metric][0]+'.txt', index_col=0, header=0, sep='\t')
        except:
          if genus:
            this_metric = pd.read_csv(direc_save+db_name+'_'+metrics[metric][0]+'_genus.txt', index_col=0, header=0, sep='\t')
          else:
            this_metric = pd.read_csv(direc_save+db_name+'_'+metrics[metric][0]+'_species.txt', index_col=0, header=0, sep='\t')
        all_dfs.append(this_metric)
    calculations = pd.concat(all_dfs).fillna(value=0)
    calculations = calculations.groupby(by=calculations.index, axis=0).sum()
    calculations['Mean F1 score'] = calculations.loc[:, ['F1 score taxa', 'F1 score reads']].mean(axis=1)
    if genus:
      calculations.to_csv(direc+'analysis/'+db_name+'_calculations_genus.csv')
    else:
      calculations.to_csv(direc+'analysis/'+db_name+'_calculations_species.csv')
    for metric in metrics:
      if genus:
        os.system('mv '+direc_save+db_name+'_'+metrics[metric][0]+'.txt '+direc_save+db_name+'_'+metrics[metric][0]+'_genus.txt')
      else:
        os.system('mv '+direc_save+db_name+'_'+metrics[metric][0]+'.txt '+direc_save+db_name+'_'+metrics[metric][0]+'_species.txt')
```

Calculate alpha diversity of truth samples:
```{python, eval=FALSE}
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
import pandas as pd

direc = '/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/'
direc_db = direc+'database_classifications/'
truth = pd.read_csv(direc_db+'truth_samples_species_rename.csv', index_col=0, header=0)
truth.index = truth.index.map(str)

metrics = {"Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e'],
            "Number of taxa":['observed_otus', 'alpha', 'observed_otus']}

all_calculations = []
for sample in truth.columns:
    calculations = []
    for metric in metrics:
      val = list(alpha_diversity(metrics[metric][2], list(truth.loc[:, sample].values)))[0]
      calculations.append(val)
    all_calculations.append(calculations)

calcs = pd.DataFrame(all_calculations, columns=[metric for metric in metrics], index=truth.columns).fillna(value=0)
calcs.to_csv(direc+'analysis/truth_species_calculations.csv')
```

## Calculate all metrics with truth profiles

Unfortunately multiprocessing doesn't work in R so this needs to be set to false if run here (not really recommended because there are thousands of samples to calculate these metrics for). I ran it as a standalone python script.

```{python, eval=FALSE}
import pandas as pd
import os
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from sklearn.metrics import precision_recall_fscore_support
from skbio import read
from skbio.tree import TreeNode
from skbio.stats.composition import clr
from deicode.preprocessing import rclr
import numpy as np
from scipy.spatial import distance
from sklearn.metrics import auc
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager
import pickle

using_multiprocessing = True
n_proc=12

direc = '/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/'
direc_db = direc+'database_classifications/'
direc_save = direc+'analysis/calculations/'
direc_temp = direc+'temporary/'
db_files = ['kraken2_refseqV205_combined_rename.csv', 'kraken2_refseqV205_100GB_combined_rename.csv', 'kraken2_refseqV205_500GB_combined_rename.csv', 'kraken2_chocophlan_combined_rename.csv', 'kraken2_GTDBr202RefSeqV205_combined_rename.csv', 'kraken2_minikraken_combined_rename.csv', 'kraken2_refseqV208_nt_combined_rename.csv', 'kraken2_standard_0521_combined_rename.csv',  'MetaPhlAn_reads_combined_rename.csv']
db_files = ['kraken2_refseqV205_100GB_combined_rename.csv']
#db_files = ['MetaPhlAn_reads_combined_rename.csv']

truth = pd.read_csv(direc_db+'truth_profiles_species_rename.csv', index_col=0, header=0)
#fix that everything was multiplied by 100
# truth = truth/100
# truth = truth.astype(int)
# truth.to_csv(direc_db+'truth_samples_species_rename.csv')
truth.index = truth.index.map(str)
samples = list(truth.columns)

with open(direc_db+'reads_in_samples.dict', 'rb') as f:
    reads_in_samples = pickle.load(f)

metrics = {'Proportion classified':['proportion_classified', 'basic'],
            'Precision reads':['precision_reads', 'basic'], 
            'Precision taxa':['precision_taxa', 'basic'], 
            'Recall reads':['recall_reads', 'basic'], 
            'Recall taxa':['recall_taxa', 'basic'], 
            'F1 score reads':['f1_score_reads', 'basic'], 
            'F1 score taxa':['f1_score_taxa', 'basic'], 
            'L1 distance':['l1_distance', 'beta', 'cityblock', 'none'],
            'Aitchisons distance':['aitchisons_distance', 'beta', 'euclidean', 'clr'], 
            'Robust Aitchisons distance':['robust_aitchisons_distance', 'beta', 'euclidean', 'rclr'],
            'Bray-Curtis dissimilarity raw':['bray_curtis_dissimilarity_raw', 'beta', 'braycurtis', 'none'],
            'Bray-Curtis dissimilarity relative abundance':['bray_curtis_dissimilarity_ra', 'beta', 'braycurtis', 'ra'],
            "Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e'],
            "Number of taxa":['number_of_taxa', 'alpha', 'observed_otus']}

#for each of these metrics, the first value is what to call the file name, the second is the type of measure (basic, alpha, beta), third is the name within the alpha/beta diversity functions, and fourth is the type of normalisation to perform prior to calculations
#print(get_beta_diversity_metrics())
#print(get_alpha_diversity_metrics())

def append_text(fn, sn, text):
    with open(direc_save+fn+'.txt', 'a') as f:
        f.write(sn+'\t'+str(text)+'\n')
    return

def new_file(fn, cn1, cn2):
    with open(direc_save+fn+'.txt', 'w') as f:
        f.write(cn1+'\t'+cn2+'\n')
    return

def calc_aupr(sample_df):
    sn = sample_df.columns[1]
    pc = sample_df.sum(axis=0).values
    #if the number of reads classified is zero, set all of the metrics to be zero and return
    if pc[1] == 0: 
        prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads = 0, 0, 0, 0, 0, 0, 0
        return prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads
    else: prop_classified = pc[1]/pc[0]
    #otherwise, loop through the taxa in the truth sample and look at whether the classification is accurate - add 1 to correct taxa if it is, if the number of reads classified is higher than the truth sample then only add the number of reads in the truth sample to the total number of correct reads, otherwise add the number of reads predicted to it
    y_true, y_pred = sample_df.iloc[:, 0].values, sample_df.iloc[:, 1].values
    correct_reads, correct_taxa = 0, 0
    for v in range(len(y_true)):
        if y_true[v] > 0 and y_pred[v] > 0:
            if y_pred[v] >= y_true[v]:
                correct_reads += y_true[v]
            else:
                correct_reads += y_pred[v]
            if y_pred[v] > 0 and y_true[v] > 0: 
                correct_taxa += 1
    #calculate precision and recall
    precision_reads = correct_reads/sum(y_pred) #reads correctly classified (true positives) divided by reads correctly classified (true positives) + reads incorrectly classified (false positives), i.e. number of reads classified
    recall_reads = correct_reads/sum(y_true) #reads correctly classified (true positives) divided by reads correctly classified (true positives) + reads not classified (false negatives), i.e. number of reads in truth sample
    if precision_reads == 0 or recall_reads == 0: f1_score_reads = 0
    else: f1_score_reads = 2*((precision_reads*recall_reads)/(precision_reads+recall_reads))
    
    precision_taxa = correct_taxa/sum([1 for y in y_pred if y > 0])
    recall_taxa = correct_taxa/sum([1 for y in y_true if y > 0])
    if precision_taxa == 0 or recall_taxa == 0: f1_score_taxa = 0
    else: f1_score_taxa = 2*((precision_taxa*recall_taxa)/(precision_taxa+recall_taxa))
        
    return prop_classified, precision_taxa, recall_taxa, f1_score_taxa, precision_reads, recall_reads, f1_score_reads


def calc_all(sample_df):
    sn = list(sample_df.columns)[1]
    if len(sample_df.index) == 1:
        for metric in metrics:
            append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, 0)
        return
    sample_df.to_csv(direc_temp+sn+'.csv')
    fn = 'calculations/'+sn.split('-')[1]
    calculated_aupr = False
    for metric in metrics:
        sample_df = pd.read_csv(direc_temp+sn+'.csv', index_col=0, header=0)
        sample_df.index = sample_df.index.map(str)
        if metrics[metric][1] == 'alpha':
            if metrics[metric][2] != 'faith_pd':
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values)))[0]
            else:
                val = list(alpha_diversity(metrics[metric][2], list(sample_df.loc[:, sn].values), otu_ids=sample_df.index.values, tree=tree, validate=False))[0]
        elif metrics[metric][1] == 'beta':
            if metrics[metric][3] == 'clr':
                sample_df[sample_df == 0] = 1
                for col in sample_df.columns:
                    sample_df.loc[:, col] = clr(sample_df.loc[:, col].values)
                X = sample_df.transpose().iloc[0:].values
            elif metrics[metric][3] == 'rclr':
                X = sample_df.iloc[0:].values
                rclr_sample = rclr(X)
                rclr_sample = pd.DataFrame(rclr_sample, columns=sample_df.columns, index=sample_df.index.values).fillna(value=0)
                X = rclr_sample.transpose().iloc[0:].values
            elif metrics[metric][3] == 'ra':
                sample_df = sample_df.divide(sample_df.sum(axis=0), axis=1).multiply(100)
                X = sample_df.transpose().iloc[0:].values
            else:
                X = sample_df.transpose().iloc[0:].values
                
            if 'unifrac' not in metric:
                similarities = np.nan_to_num(distance.cdist(X, X, metrics[metric][2])) 
            else:
                sample_df.index = sample_df.index.map(str)
                similarities = beta_diversity(metrics[metric][2], X, sample_df.columns, tree=tree, otu_ids=sample_df.index.values, validate=False)
            val = similarities[0][1]
        else:
            if not calculated_aupr:
                prop_classified, precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads = calc_aupr(sample_df)
                list_vals = [prop_classified, precision, recall, f1_score, precision_reads, recall_reads, f1_score_reads]
                metric_names = ['Proportion classified', 'Precision taxa', 'Recall taxa', 'F1 score taxa', 'Precision reads', 'Recall reads', 'F1 score reads']
                for a in range(len(list_vals)):
                    append_text(sn.split('-')[1]+'_'+metrics[metric_names[a]][0], sn, list_vals[a])
                calculated_aupr = True
                continue
            else:
                continue
        append_text(sn.split('-')[1]+'_'+metrics[metric][0], sn, val)
    os.remove(direc_temp+sn+'.csv')
    return
    

for db in db_files:
    print('\n\n\n', db, '\n\n\n')
    db_name = db.replace('_combined_rename.csv', '').replace('_reads', '')
    if os.path.exists(direc+'analysis/'+db_name+'_calculations.csv'):
      print('Already got this one')
      continue
    for metric in metrics:
      new_file(db_name+'_'+metrics[metric][0], 'Sample name', metric)
    db_tests = pd.read_csv(direc_db+db, index_col=0, header=0)
    db_tests.index = db_tests.index.map(str)
    all_running = []
    count_all = 1
    count_samples = 0
    for sample in db_tests.columns:
        count_samples += 1
        truth_sample_df = pd.DataFrame(truth.loc[:, sample.split('-')[0]])
        truth_sample_df = truth_sample_df[truth_sample_df.max(axis=1) > 0]
        test_sample_df = pd.DataFrame(db_tests.loc[:,sample])
        test_sample_df = test_sample_df[test_sample_df.max(axis=1) > 0]
        sample_df = pd.concat([truth_sample_df, test_sample_df]).fillna(value=0)
        sample_df = sample_df.groupby(by=sample_df.index, axis=0).sum()
        all_running.append(sample_df)
        if len(all_running) == n_proc or count_samples == len(list(db_tests.columns)):
            print('Getting distances for '+str(n_proc), count_all)
            count_all += 1
            if using_multiprocessing:
                if __name__ == "__main__":
                    manager = Manager()
                    with manager.Pool(processes=n_proc) as pool:
                        pool.map(calc_all, all_running)
            else:
                for df in all_running:
                    calc_all(df)
            all_running = []
    for metric in ['Proportion classified']:
      new_file(db_name+'_'+metrics[metric][0], 'Sample name', metric)
    db_tests = pd.read_csv(direc_db+db, index_col=0, header=0)
    db_tests.index = db_tests.index.map(str)
    for sample in db_tests.columns:
      sample_sum = pd.DataFrame(db_tests.loc[:, sample]).sum(axis=0).values[0]
      sample_prop = sample_sum/reads_in_samples[sample.split('-')[0]]
      append_text(sample.split('-')[1]+'_'+metrics['Proportion classified'][0], sample, sample_prop)
    all_dfs = []
    for metric in metrics:
        this_metric = pd.read_csv(direc_save+db_name+'_'+metrics[metric][0]+'.txt', index_col=0, header=0, sep='\t')
        all_dfs.append(this_metric)
    calculations = pd.concat(all_dfs).fillna(value=0)
    calculations = calculations.groupby(by=calculations.index, axis=0).sum()
    calculations['Mean F1 score'] = calculations.loc[:, ['F1 score taxa', 'F1 score reads']].mean(axis=1)
    calculations['Mean Precision'] = calculations.loc[:, ['Precision taxa', 'Precision reads']].mean(axis=1)
    calculations['Mean Recall'] = calculations.loc[:, ['Recall taxa', 'Recall reads']].mean(axis=1)
    calculations.to_csv(direc+'analysis/'+db_name+'_calculations.csv')
    
# #redo proportion classified with numbers of reads in samples, not in truth samples
# for db in db_files:
#     print('\n\n\n', db, '\n\n\n')
#     db_name = db.replace('_combined_rename.csv', '').replace('_reads', '')
#     print(db_name)
#     for metric in ['Proportion classified']:
#       new_file(db_name+'_'+metrics[metric][0], 'Sample name', metric)
#     db_tests = pd.read_csv(direc_db+db, index_col=0, header=0)
#     db_tests.index = db_tests.index.map(str)
#     for sample in db_tests.columns:
#       sample_sum = pd.DataFrame(db_tests.loc[:, sample]).sum(axis=0).values[0]
#       sample_prop = sample_sum/reads_in_samples[sample.split('-')[0]]
#       append_text(sample.split('-')[1]+'_'+metrics['Proportion classified'][0], sample, sample_prop)
#     all_dfs = []
#     for metric in metrics:
#         this_metric = pd.read_csv(direc_save+db_name+'_'+metrics[metric][0]+'.txt', index_col=0, header=0, sep='\t')
#         all_dfs.append(this_metric)
#     calculations = pd.concat(all_dfs).fillna(value=0)
#     calculations = calculations.groupby(by=calculations.index, axis=0).sum()
#     calculations['Mean F1 score'] = calculations.loc[:, ['F1 score taxa', 'F1 score reads']].mean(axis=1)
#     calculations.to_csv(direc+'analysis/'+db_name+'_calculations_prop_class.csv')
```

Calculate alpha diversity of truth samples:
```{python, eval=FALSE}
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
import pandas as pd

direc = '/home/robyn/simulated_samples/CAMI2/kraken_confidence_testing_mock/'
direc_db = direc+'database_classifications/'
truth = pd.read_csv(direc_db+'truth_profiles_species_rename.csv', index_col=0, header=0)
truth.index = truth.index.map(str)

metrics = {"Simpson's diversity":['simpsons_diversity', 'alpha', 'simpson'],
            'Shannon diversity':['shannon_diversity', 'alpha', 'shannon'],
            'Chao1 richness':['chao1_richness', 'alpha', 'chao1'],
            "McIntosh's evenness":['mcintosh_evenness', 'alpha', 'mcintosh_e'],
            "Pielou evenness":['pielou_evenness', 'alpha', 'pielou_e'],
            "Simpson's evenness":['simpson_evenness', 'alpha', 'simpson_e'],
            "Number of taxa":['observed_otus', 'alpha', 'observed_otus']}

all_calculations = []
for sample in truth.columns:
    calculations = []
    for metric in metrics:
      val = list(alpha_diversity(metrics[metric][2], list(truth.loc[:, sample].values)))[0]
      calculations.append(val)
    all_calculations.append(calculations)

calcs = pd.DataFrame(all_calculations, columns=[metric for metric in metrics], index=truth.columns).fillna(value=0)
calcs.to_csv(direc+'analysis/truth_profile_calculations.csv')
```

## Kraken RefSeq Complete V205 index runs

```{bash, eval=FALSE}
#done
sudo cp -a /home/shared/Kraken2_RefSeqCompleteV205/ /scratch/ramdisk/
mkdir index
mkdir index/kraken2_outraw
mkdir index/kraken2_kreport

parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/marine* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/




parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/plant* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/




parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/strain* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/

parallel -j 2 --progress 'kraken2 --use-names --threads 24 --db {3} --memory-mapping {1} --output index/kraken2_outraw/{1/.}.{2}.kraken --report index/kraken2_kreport/{1/.}.{2}.kreport --confidence {2}' ::: all_samples/mouse* ::: 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 ::: /scratch/ramdisk/Kraken2_RefSeqCompleteV205/

gzip kraken2_outraw/strain_sample_10*
gzip kraken2_outraw/strain_sample_3*
gzip kraken2_outraw/strain_sample_4*
```

Get the summary:
```{python, eval=FALSE}
import os
import time
import pickle
import numpy as np
import pandas as pd
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

with open('/home/robyn/simulated_samples/CAMI2/taxonomy/taxidlineage.dict', 'rb') as f:
    taxidlineage = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/merged.dict', 'rb') as f:
    merged = pickle.load(f)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/deleted.list', 'rb') as f:
    deleted = pickle.load(f)
deleted = set(deleted)
    
with open('/home/robyn/simulated_samples/CAMI2/taxonomy/gtdb_to_ncbi_taxid_all_levels.dict', 'rb') as f:
    all_levels_gtdb_to_ncbi = pickle.load(f)
    
columns = ['Sample', 'Median Index', 'Mean Index', 'Number of reads', 'Number of correctly classified reads', 'Number of reads classified at a lower level by Kraken', 'Number of reads classified at a higher level by Kraken', 'Number of reads classified wrong by Kraken', 'Unclassified reads', 'Median Index of reads classified at a higher level by Kraken', 'Mean Index of reads classified at a higher level by Kraken', 'Median Index of reads classified wrong by Kraken', 'Mean Index of reads classified wrong by Kraken']
    
def get_file(f):
  f = f.split('/')[-1]
  print(f)
  new_fn = f.replace('.kraken', '')
  if os.path.exists('summary_summary_outraw/'+new_fn.replace('.gz', '')+'.csv'): 
    print('This file already exists: summary_summary_outraw/'+new_fn.replace('.gz', '')+'.csv')
    return
  if '.gz' in f:
    os.system('gunzip '+folder+f)
    f = f.replace('.gz', '')
    print('unzipped '+f)
  this_file = pd.read_csv('summary_outraw/'+f, index_col=0, header=0, sep='\t')
  unclassified = list(this_file.loc[:, 'Index'].values).count('U')
  this_file[this_file['Index'] == 'U'] = 9
  this_file[this_file['Index'] == 'CAMI U'] = 0
  this_file.Index = this_file.Index.fillna(value=9)
  this_file.Index = this_file.Index.map(int)
  this_file[this_file['Index'] > 9] = 9
  this_sample = [new_fn, np.median(list(this_file.loc[:, 'Index'].values)), np.mean(list(this_file.loc[:, 'Index'].values)), this_file.shape[0], list(this_file.loc[:, 'Index'].values).count(0), list(this_file.loc[:, 'Notes on index'].values).count('kcll'), list(this_file.loc[:, 'Notes on index'].values).count('kchl'), list(this_file.loc[:, 'Notes on index'].values).count('kw'), unclassified]
  this_file_kchl = pd.DataFrame(this_file)[this_file['Notes on index'] == 'kchl']
  this_sample.append(np.median(list(this_file_kchl.loc[:, 'Index'].values)))
  this_sample.append(np.mean(list(this_file_kchl.loc[:, 'Index'].values)))
  this_file_kw = pd.DataFrame(this_file)[this_file['Notes on index'] == 'kw']
  this_sample.append(np.median(list(this_file_kw.loc[:, 'Index'].values)))
  this_sample.append(np.mean(list(this_file_kw.loc[:, 'Index'].values)))
  this_sample_df = pd.DataFrame(this_sample, index=columns).transpose().set_index('Sample')
  this_sample_df.to_csv('summary_summary_outraw/'+new_fn+'.csv')
  os.system('gzip summary_outraw/'+f)
  return
    
def get_single_file(f):
    start_time = time.time()
    try:
      folder = f.rsplit('/', 1)[0]+'/'
      f = f.rsplit('/', 1)[1]
      prefix = folder.split('/')[-2]
      new_fn = save_folder+prefix+'_'+f.replace('.gz', '')
      if os.path.exists(new_fn) or os.path.exists(new_fn+'.gz'):
        os.system('gzip '+folder+f)
        get_file(new_fn)
        print(f, time.time()-start_time)
        return
      if '.gz' in f:
        os.system('gunzip '+folder+f)
        f = f.replace('.gz', '')
      truth_fn = truth_samples+f.replace('.kraken.gz', '')
      truth_fn = truth_fn.split('.')[0]+'.tsv'
      all_index = []
      kraken_higher_level = []
      kraken_wrong_higher = []
      truth_dict = {}
      for row in open(truth_fn, 'r'):
        row = row.split('\t')
        truth_dict[row[0]] = [row[1], row[2]]
      #unique_tax = set([])
      #print(f, time.time()-start_time)
      this_file = []
      total = 0
      count = 0
      for row in open(folder+f, 'r'):
        total += 1
        try:
          if total % 10000000 == 0: print(f, total, time.time()-start_time)
          row = row.split('\t')
          if len(row) < 3:
            count += 1
            continue
          if row[0] not in ['C', 'U']:
            count += 1
            continue
          if row[1] not in truth_dict:
            count += 1
            continue
          truth = truth_dict[row[1]]
          truth_tid, truth_otu = truth[1], truth[0]
          index = None
          if row[0] == 'U':
            row = row[1]+'\tU'
            index = 'U'
          else:
            tax = row[2].split('taxid ')[1].replace(')', '')
            if 'GTDB' in folder:
              tax = str(all_levels_gtdb_to_ncbi[tax])
            if tax == truth_tid:
              index = 0
            elif tax == '1' or tax == '0':
              index = 'U'
            elif truth_tid == '32644':
              index = 'CAMI U'
            else:
              if tax in merged: 
                tax = merged[tax]
              elif tax in deleted: 
                index = 'NA'
              if truth_tid in merged: 
                truth_tid = merged[truth_tid]
              elif truth_tid in deleted: 
                index = 'NA'
              if index == None:
                kraken_lineage = taxidlineage[tax]
                truth_lineage = taxidlineage[truth_tid]
                if truth_tid in kraken_lineage:
                  index = str(0)+'\tkcll'
                else:
                  if tax in truth_lineage:
                    t_reverse = truth_lineage[:]
                    t_reverse.reverse()
                    index = str(t_reverse.index(tax)+1)+'\tkchl' #kraken classified at higher level that was this many levels away
                    kraken_higher_level.append(index)
                  else:
                    min_index = 0
                    for a in range(min(len(kraken_lineage), len(truth_lineage))):
                      if kraken_lineage[a] == truth_lineage[a]:
                        min_index = truth_lineage[a]
                    t_reverse = truth_lineage[:]
                    t_reverse.reverse()
                    if min_index != 0:
                      index = str(t_reverse.index(min_index)+1)+'\tkw' #kraken wrong, classified correctly at higher level which was this many levels away
                      kraken_wrong_higher.append(index)
            row = row[1]+'\t'+tax
          if index == None: 
            index = 'U'
          else: index = str(index)
          this_file.append(row+'\t'+truth[0]+'\t'+truth[1]+'\t'+index+'\n')
          all_index.append(index)
        except:
          count += 1
      with open(new_fn, 'w') as fi:
        wr = fi.write('Sequence ID\tKraken taxid\tCAMI OTU\tCAMI taxid\tIndex\tNotes on index\n')
        for row in this_file:
          wr = fi.write(row)
      if '.gz' not in f:
        os.system('gzip '+folder+f)
      get_file(new_fn)
    except:
      print('Had a problem with '+f)
    print(f, time.time()-start_time)
    return

folders = ['/home/robyn/simulated_samples/CAMI2/index/kraken2_outraw/']
save_folder = '/home/robyn/simulated_samples/CAMI2/index/summary_outraw/'
truth_samples = '/home/robyn/simulated_samples/CAMI2/truth_samples/'

for fol in folders:
  #this_folder = '/home/storage/robyn/kraken_confidence_comparison_all/CAMI2/kraken2_outraw/'+fol
  this_folder = fol
  files = sorted(os.listdir(this_folder))
  files = [f for f in files]
  files = [this_folder+f for f in files if '.gz' not in f]
  print('\n\n'+this_folder)
  # for f in files:
  #   get_single_file(f)
  if __name__ == "__main__":
    manager = Manager()
    with manager.Pool(processes=24) as pool:
      pm = pool.map(get_single_file, files)
```


Get summary of summaries:
```{python, eval=FALSE}
import os
import numpy as np
import pandas as pd
import time
from multiprocessing import Pool
from multiprocessing import freeze_support
from multiprocessing import Process, Manager

folder = 'summary_outraw/'
all_files = os.listdir(folder)
all_files = [f for f in all_files if 'marine' in f]

columns = ['Sample', 'Median Index', 'Mean Index', 'Number of reads', 'Number of correctly classified reads', 'Number of reads classified at a lower level by Kraken', 'Number of reads classified at a higher level by Kraken', 'Number of reads classified wrong by Kraken', 'Unclassified reads', 'Median Index of reads classified at a higher level by Kraken', 'Mean Index of reads classified at a higher level by Kraken', 'Median Index of reads classified wrong by Kraken', 'Mean Index of reads classified wrong by Kraken']

def get_file(f):
  start_time = time.time()
  f = f.split('/')[-1]
  print(f)
  new_fn = f.replace('.kraken', '').replace('.gz', '')
  if os.path.exists('summary_summary_outraw_no_unclassified/'+new_fn.replace('.gz', '')+'.csv'): 
    print('This file already exists: summary_summary_outraw_no_unclassified/'+new_fn.replace('.gz', '')+'.csv')
    return
  if '.gz' in f:
    os.system('gunzip '+folder+f)
    f = f.replace('.gz', '')
    print('unzipped '+f)
  this_file = pd.read_csv('summary_outraw/'+f, index_col=0, header=0, sep='\t')
  unclassified = list(this_file.loc[:, 'Index'].values).count('U')
  #this_file[this_file['Index'] == 'U'] = 9
  this_file = this_file.drop(this_file[this_file['Index'] == 'U'].index)
  this_file[this_file['Index'] == 'CAMI U'] = 0
  this_file.Index = this_file.Index.fillna(value=9)
  this_file.Index = this_file.Index.map(int)
  this_file[this_file['Index'] > 9] = 9
  this_sample = [new_fn, np.median(list(this_file.loc[:, 'Index'].values)), np.mean(list(this_file.loc[:, 'Index'].values)), this_file.shape[0], list(this_file.loc[:, 'Index'].values).count(0), list(this_file.loc[:, 'Notes on index'].values).count('kcll'), list(this_file.loc[:, 'Notes on index'].values).count('kchl'), list(this_file.loc[:, 'Notes on index'].values).count('kw'), unclassified]
  this_file_kchl = pd.DataFrame(this_file)[this_file['Notes on index'] == 'kchl']
  this_sample.append(np.median(list(this_file_kchl.loc[:, 'Index'].values)))
  this_sample.append(np.mean(list(this_file_kchl.loc[:, 'Index'].values)))
  this_file_kw = pd.DataFrame(this_file)[this_file['Notes on index'] == 'kw']
  this_sample.append(np.median(list(this_file_kw.loc[:, 'Index'].values)))
  this_sample.append(np.mean(list(this_file_kw.loc[:, 'Index'].values)))
  this_sample_df = pd.DataFrame(this_sample, index=columns).transpose().set_index('Sample')
  this_sample_df.to_csv('summary_summary_outraw_no_unclassified/'+new_fn+'.csv')
  os.system('gzip summary_outraw/'+f)
  print(f, time.time()-start_time)
  return

if __name__ == "__main__":
  manager = Manager()
  with manager.Pool(processes=24) as pool:
    pm = pool.map(get_file, all_files)

# for f in all_files:
#   get_file(f)
```

Also get the 0.00 confidence from those run previously:
```{python, eval=FALSE}
import os

redo_folder = 'redo/summary_summary_outraw/'
files = os.listdir(redo_folder)
files = [f for f in files if 'refseqV205' in f and 'GB' not in f]
for f in files:
  new_fn = f.split('-')[0]+'-0.00.csv'
  os.system('cp '+redo_folder+f+' index/summary_summary_outraw/'+new_fn)
```

Rename:
```{python, eval=FALSE}
import os

folder = 'summary_summary_outraw/'
files = os.listdir(folder)
files = [f for f in files if 'kraken2_outraw' in f]
for f in files:
  new_fn = f.replace('kraken2_outraw_', '').replace('.csv', '').split('.', 1)
  new_fn = new_fn[0]+'-'+new_fn[1]+'.csv'
  os.system('cp '+folder+f+' '+folder+new_fn)
```

And combine all:
```{python, eval=FALSE}
import os
import pandas as pd

summary_files = os.listdir('summary_summary_outraw_no_unclassified/')
summary_files = [f for f in summary_files]
all_files = []
for f in summary_files:
  print(f)
  this_file = pd.read_csv('summary_summary_outraw_no_unclassified/'+f, index_col=0, header=0)
  if isinstance(all_files, list):
    all_files = pd.DataFrame(this_file)
  else:
    all_files = pd.concat([all_files, this_file])
    all_files = all_files.groupby(by=all_files.index, axis=0).sum().fillna(value=0)

rename = {}
for row in all_files.index.values:
  new_name = str(row)
  if 'kraken2_outraw' in row:
    rename[row] = new_name.replace('kraken2_outraw_', '').replace('.', '-', 1)
  elif 'kraken2_refseqV205' in row:
    rename[row] = new_name.replace('kraken2_refseqV205', '0.00')
  elif 'RefSeqCompleteV205' in row:
    rename[row] = new_name.replace('RefSeqCompleteV205_', '')+'-0.00'
    
all_files = all_files.rename(index=rename)

all_files.to_csv('summary_outraw_confidence_no_unclassified.csv')
```
